
---
# Source: nsf-init/templates/nsf-init/nsf-init-configmap.yaml
apiVersion: v1
data:
  nsf-init.py: "#! /bin/env python\n# -*- coding:utf-8 -*-\n'''\n功能描述：\n提供三个功能块\n1、获取token\n2、初始化apigw\n'''\n\n# 1、 获取token\nimport requests\nimport json\nimport time\nimport sys\n\n# config\nimport configparser\n\nconf = configparser.ConfigParser()\nconf.read(\"/tmp/init.cfg\")\n\n# 用户登录信息，运维管理员才能创建网关，如admin\nqingzhou_default_user = conf.get(\"global\", \"AdminName\")\nqingzhou_default_password = conf.get(\"global\", \"AdminPassword\")\nnsf_environment = conf.get(\"nsf\", \"nsf_environment\")\nnsf_ak = conf.get(\"nsf\", \"nsf_ak\")\nnsf_sk = conf.get(\"nsf\", \"nsf_sk\")\n\n# 租户名称\ntenantName = conf.get(\"platform\", \"TanantName\")\n# 项目名称\nprojectName = conf.get(\"platform\", \"ProjectName\")\n\n# 登录平台\n# 平台user-auth服务地址\nuserAuthHost = conf.get(\"platform\", \"UserAuthUrl\")\nlogin_url = \"/authority?Action=Login&Version=2018-08-09\"\ndescribePermissionScope_url = \"/authority?Action=DescribePermissionScope&Version=2018-08-09&PermissionScopeEnName=%s&PermissionScopeId=\"\n\ns = requests.Session()\n\n# 登录平台\ndef usr_login(s, username, password):\n    login_body = {}\n    login_body[\"AccountId\"] = username\n    login_body[\"AccountPassword\"] = password\n    login_body[\"LoginType\"] = \"normal\"\n\n    result = s.post(userAuthHost+login_url, data=json.dumps(login_body))\n    if result.status_code != 200:\n        print(\"3/7: get token Failure\")\n        sys.exit(1)\n    token = result.json()['Token']\n    return token\n\n\n# 根据scope名称和标识获取scope详情，这里是根据租户或项目名称获取scopeId\ndef describePermissionScope(s, scopeName):\n    describePermissionScope_addr = userAuthHost + \\\n        describePermissionScope_url % (scopeName)\n    headers = {\n    \"x-auth-accountid\":\"admin\"\n    }\n    result = s.get(describePermissionScope_addr, headers=headers)\n    if result.status_code != 200:\n        print(\"1/7 or 2/7: get scope id Failure\")\n        sys.exit(1)\n    return result.json()\n\n\ndef getScopeId(s, scopeName):\n    result = describePermissionScope(s, scopeName)\n    return result['Id']\n\ndef meta_is_ready():\n    url = \"http://nsf-meta.qa-yanlian.qingzhou.com/health\"\n    while True:\n        result = s.get(url)\n        if result.status_code == 200:\n            return True\n        else:\n            time.sleep(3)\n\ndef meta_query(nsf_environment, project_id):\n    url = \"http://nsf-meta.qa-yanlian.qingzhou.com/api/metadata?Action=GetEnvInfoByEnvName&Version=2018-11-1&EnvName=%s\" % (nsf_environment)\n    headers = {\n    \"Content-Type\":\"application/json\",\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectid\":str(project_id),\n    }\n    result = s.get(url, headers=headers)\n    result_dict = json.loads(result.text)\n    if not result_dict.get(\"Result\"):\n        return True\n    if result_dict[\"Result\"][\"EnvName\"] == nsf_environment:\n        print(\"function: meta_query; %s already exists\" % (nsf_environment))\n        print(result.json())\n        return False\n    else:\n        return True\n\n\ndef init_nsf_meta(project_id, nsf_environment):\n    url = \"http://nsf-meta.qa-yanlian.qingzhou.com/api/metadata?Version=2018-11-1&Action=CreateOrUpdateEnvInfo\"\n    headers = {\n    \"Content-Type\":\"application/json\",\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectid\":str(project_id),\n    }\n    data={\n    \"EnvConfig\":[{\n            \"Address\":\"http://sm-api-plane.qa-yanlian.qingzhou.com\",\n            \"Name\":\"apiPlaneUrl\"\n        },{\n            \"Address\":\"http://nsf-registry.qa-yanlian.qingzhou.com\",\n            \"Name\":\"NSFRegistry\"\n        },{\n            \"Address\":\"http://platform-service-auth.qa-yanlian.qingzhou.com\",\n            \"Name\":\"ServiceAuth\"\n        },{\n            \"Address\":\"http://nsf-server.qa-yanlian.qingzhou.com\",\n            \"Name\":\"NSFServer\"\n        },{\n            \"Address\":\"zookeeper://zookeeper.apigw-demo.svc.cluster.local:2181\",\n            \"Name\":\"NSFZookeeper\"\n        }],\n    \"EnvName\":nsf_environment,\n    \"OwnerId\":[],\n    \"Desc\":\"\"\n    }\n    result = s.post(url, data=json.dumps(data), headers=headers)\n    return result\n\ndef sm_query(nsf_environment, project_id):\n    url = \"http://nsf-meta.qa-yanlian.qingzhou.com/api/metadata?Action=GetMeshInfoList&Version=2018-11-1\"\n    headers = {\n    \"Content-Type\":\"application/json\",\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectid\":str(project_id),\n    }\n    result = s.get(url, headers=headers)\n    result_dict = json.loads(result.text)\n    for env in result_dict[\"Result\"]:\n        if env[\"EnvName\"] == nsf_environment:\n            print(\"function: sm_query; %s already exists\" % (nsf_environment))\n            print(result.json())\n            return False\n    return True\n\ndef init_sm(project_id):\n    url = \"http://nsf-meta.qa-yanlian.qingzhou.com/api/metadata?Version=2018-11-1&Action=CreateOrUpdateMeshInfo\"\n    headers = {\n    \"Content-Type\":\"application/json\",\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectid\":str(project_id),\n    }\n    data = {\n      \"Name\": \"ServiceMesh-prod\",\n      \"EnvName\": \"prod\",\n      \"IstioVersion\": \"1.3.5\",\n      \"ExternalAccess\": \"1\"\n    }\n    result = s.post(url, data=json.dumps(data), headers=headers)\n    return result\n\ndef init_server():\n    url = \"http://nsf-server.qa-yanlian.qingzhou.com/api/service?Action=SetServiceCreateOption&Version=2018-05-31&IsOpen=true\"\n    headers = {\n    \"x-auth-accountid\":\"admin\",    \n    \"cache-control\":\"no-cache\"\n    }\n    result = s.get(url, headers=headers)\n    return result\n\ndef server_is_ready():\n    url = \"http://nsf-server.qa-yanlian.qingzhou.com/api/health\"\n    while True:\n        result = s.get(url)\n        if result.status_code == 200:\n            return True\n        else:\n            time.sleep(3)\n\ndef ak_sk_query(nsf_environment, project_id):\n    url = \"http://nsf-server.qa-yanlian.qingzhou.com/api/project?Action=DescribeProjectCredential&Version=2018-07-26&ProjectId=%s\" % (project_id)\n    headers = {\n    \"Content-Type\":\"application/json\",\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectid\":str(project_id),\n    \"x-nsf-env\": nsf_environment\n    }\n    result = s.get(url, headers=headers)\n    result_dict = json.loads(result.text)\n    if not \"CredentialList\" in result_dict.keys():\n        return True\n    for ak_sk in result_dict[\"CredentialList\"][\"CredentialList\"]:\n        if ak_sk[\"AccessKey\"] == nsf_ak and ak_sk[\"AccessSecret\"] == nsf_sk:\n            print(\"function: ak_sk_query; ak_sk already exists\")\n            print(result.json())\n            return False\n    return True\n\ndef init_ak_sk(project_id, nsf_environment):\n    url = \"http://nsf-server.qa-yanlian.qingzhou.com/api/project?Action=CreateProjectCredential&Version=2018-07-26&ProjectId=%s&GenerateType=manual&AccessKey=%s&AccessSecret=%s\" % (project_id,nsf_ak,nsf_sk)\n    headers = {\n    \"x-auth-accountid\":\"admin\",\n    \"x-auth-projectId\":str(project_id),\n    \"x-nsf-env\":nsf_environment\n    }\n    result = s.get(url, headers=headers)\n    return result\n\ndef nsf_init_workflow():\n    print(\"######################################\")\n    print(\"1/7: get tenant id\")\n    print(\"2/7: get project id\")\n    print(\"3/7: get token\")\n    print(\"4/7: init nsf-meta\")\n    print(\"5/7: init servicemesh\")\n    print(\"6/7: init nsf-server\")\n    print(\"7/7: init ak-sk\")\n    print(\"######################################\")\n\nif __name__ == '__main__':\n    nsf_init_workflow()\n\n    x_auth_tenantId = getScopeId(s, tenantName)\n    print(\"1/7: get tenant id Success  && tenant id: %s\" % (x_auth_tenantId))\n\n    x_auth_projectId = getScopeId(s, projectName)\n    print(\"2/7: get project id Success  && project id: %s\" % (x_auth_projectId))\n\n    x_auth_token = usr_login(s, qingzhou_default_user,\n                         qingzhou_default_password)\n    print(\"3/7: get token Success  && token: %s\" % (x_auth_token))\n\n    if(meta_is_ready() and meta_query(nsf_environment, x_auth_projectId)):\n        init_meta_result = init_nsf_meta(x_auth_projectId, nsf_environment)\n        if init_meta_result.status_code == 200:\n            print(\"4/7: init nsf-meta Success && result: %s\" % (init_meta_result.json()))\n        else:\n            print(\"4/7: init nsf-meta Failure && result: %s\" % (init_meta_result.json()))\n            sys.exit(1)\n    else:\n        print(\"4/7: init nsf-meta Success && nsf-meta already init\")\n\n    if(meta_is_ready() and sm_query(nsf_environment, x_auth_projectId)):\n        init_sm_result = init_sm(x_auth_projectId)\n        if init_sm_result.status_code == 200:\n            print(\"5/7: init servicemesh Success && result: %s\" % (init_sm_result.json()))\n        else:\n            print(\"5/7: init servicemesh Failure && result: %s\" % (init_sm_result.json()))\n            sys.exit(1)\n    else:\n        print(\"5/7: init servicemesh Success && servicemesh already init\")\n\n    if(server_is_ready()):\n        init_server_result = init_server()\n        if init_server_result.status_code == 200:\n            print(\"6/7: init nsf-server Success && result: %s\" % (init_server_result.json()))\n        else:\n            print(\"6/7: init nsf-server Failure && result: %s\" % (init_server_result.json()))\n            sys.exit(1)\n\n    if(server_is_ready() and False and ak_sk_query(nsf_environment, x_auth_projectId)):\n        init_ak_sk_result = init_ak_sk(x_auth_projectId, nsf_environment)\n        if init_ak_sk_result.status_code == 200:\n            print(\"7/7: init ak-sk Success && result: %s\" % (init_ak_sk_result.json()))\n        else:\n            print(\"7/7: init ak-sk Failure && result: %s\" % (init_ak_sk_result.json()))\n            sys.exit(1)\n    else:\n        print(\"7/7: init ak-sk Success && ak-sk already init or skipped\")\n"
  init.cfg: |
    [global]
    AdminName = admin
    AdminPassword = admin123456

    [platform]
    TanantName = tenant1
    ProjectName = project1
    UserAuthUrl = http://platform-user-auth.qa-yanlian.qingzhou.com
    [nsf]
    nsf_environment = prod
    nsf_ak = 3edf7f7d70434b1b9520b54693132591
    nsf_sk = 6e2b23bbdac0412aa924b598d88d2ffe
  Pipfile: |
    [[source]]
    name = "pypi"
    url = "https://pypi.tuna.tsinghua.edu.cn/simple"
    verify_ssl = true

    [dev-packages]

    [packages]
    configparser = "*"
    requests = "*"
kind: ConfigMap
metadata:
  name: nsf-init-configmap
  namespace: skiff-nsf
---
# Source: nsf-init/templates/nsf-init/nsf-init-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: nsf-init
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
      imagePullSecrets:
        - name: qingzhou-secret
      containers:
        - name: job-done
          image: hub.c.163.com/qingzhou/skiff-tools:v1.4amd64-v1.6arm64-multi
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - "cd /tmp && python3 /tmp/nsf-init.py"
          volumeMounts:
            - mountPath: /tmp/nsf-init.py
              name: nsf-init-configmap
              subPath: nsf-init.py
            - mountPath: /tmp/init.cfg
              name: nsf-init-configmap
              subPath: init.cfg
            - mountPath: /tmp/Pipfile
              name: nsf-init-configmap
              subPath: Pipfile
          resources:
            limits:
              cpu: "2"
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
      volumes:
        - name: nsf-init-configmap
          configMap:
            name: nsf-init-configmap
      dnsPolicy: ClusterFirstWithHostNet
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
      restartPolicy: Never
  backoffLimit: 4
---

---
# Source: nsf-meta/templates/base/nsf-meta/nsf-menu-permission-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    skiff-owner: platform-user-auth
    PermissionType: menu
    skiff-service-module: NSF
  name: nsf-menu-permission
  namespace: skiff-platform
data:
  root: "description:\n  menus:\n    code: \"菜单标识,string类型,不能为空\"\n    name: \"菜单名称,string类型,不能为空\"\n    sort: \"顺序,int类型,默认为0\"\n    type: \"菜单类型(内部-inner/外部-outer),string类型,非必填,默认为inner\"\n    path: 菜单路径\n    lables: \"map结构,菜单标签\"\n    roles: \"该权限分配的默认角色,多个以,分隔,不能为空,支持system_admin(平台管理员),system_normal(平台普通用户),tenant_admin(租\\\n      户管理员),tenant_normal(租户普通用户),project_admin(项目管理员),project_normal(项目普通用户),system_audit(安\\\n      全审计员),security_manager(安全管理员),managers_manager(运维管理员)\"\n    menus: \"子菜单配置,数据结构同上级数据结构,支持多层嵌套\"\nmenus:\n- code: NSF\n  name: 微服务\n  sort: 60\n  path: /nsf\n  labels:\n    product: \"true\"\n    categoryValue: 微服务\n    categoryKey: Microservice\n  roles: \"project_admin,system_admin,tenant_normal,system_audit,tenant_admin,managers_manager,system_normal,security_manager,project_normal\"\n  menus:\n  - code: OverviewNSF\n    name: 概览\n    sort: 0\n    path: /overview\n    roles: \"project_admin,security_manager,tenant_normal,project_normal,system_admin,managers_manager,tenant_admin,system_audit,system_normal\"\n  - code: ServiceTopo\n    name: 服务拓扑\n    sort: 10\n    path: /dualtopo\n    roles: \"tenant_admin,project_admin,system_audit,system_normal,security_manager,tenant_normal,system_admin,project_normal,managers_manager\"\n  - code: ServiceManage\n    name: 服务管理\n    sort: 20\n    path: /service\n    roles: \"project_normal,project_admin,tenant_admin,security_manager,system_audit,system_normal,managers_manager,tenant_normal,system_admin\"\n  - code: ServiceInstance\n    name: 服务实例\n    sort: 30\n    path: /dualinstance\n    roles: \"system_admin,tenant_normal,project_admin,project_normal,security_manager,managers_manager,tenant_admin,system_normal,system_audit\"\n  - code: FlowColor\n    name: 流量染色\n    sort: 40\n    path: /flow\n    roles: \"system_normal,managers_manager,system_admin,tenant_normal,system_audit,project_normal,project_admin,security_manager,tenant_admin\"\n  \n  - code: GlobalConfig\n    name: 全局配置\n    sort: 50\n    path: /globalconfig\n    roles: \"security_manager,system_admin,tenant_admin,project_normal,project_admin,system_audit,system_normal,managers_manager,tenant_normal\"\n  \n  - code: Access\n    name: 快速接入\n    sort: 60\n    path: /access\n    roles: \"system_admin,tenant_normal,system_audit,project_admin,managers_manager,project_normal,security_manager,system_normal,tenant_admin\"\n  \n  - code: OpsMgr\n    name: 运维管理\n    sort: 80\n    path: /\n    roles: system_admin\n    menus:\n    \n    \n    \n    - code: MonitorCtrl\n      name: 控制面推送监控\n      sort: 25\n      path: /system/monitor/control\n      roles: system_admin\n    - code: DebuggingMgr\n      name: 排障管理\n      sort: 30\n      path: /system/observable\n      roles: system_admin\n"
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-meta-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-meta-config
  namespace: skiff-nsf
data:
  jdbc.properties: |2
    #DB
    spring.datasource.dbcp2.initial-size=32
    spring.datasource.dbcp2.max-idle=64
    spring.datasource.dbcp2.max-total=200
    spring.datasource.dbcp2.min-idle=32
    spring.datasource.dbcp2.validationQuery=select now()
    spring.datasource.dbcp2.testWhileIdle=false
    spring.datasource.dbcp2.testOnBorrow=true
    spring.datasource.dbcp2.timeBetweenEvictionRunsMillis=-1
    spring.datasource.dbcp2.numTestsPerEvictionRun=3
    spring.datasource.dbcp2.minEvictableIdleTimeMillis=3600000

    spring.datasource.driver-class-name=com.mysql.jdbc.Driver
    spring.datasource.password=tOmkipoejd832k
    spring.datasource.type=org.apache.commons.dbcp2.BasicDataSource
    spring.datasource.url=jdbc:mysql://192.168.19.103:3306/nsf_meta?&autoReconnect=true&connectTimeout=5000&socketTimeout=50000&generateSimpleParameterMetadata=true&characterEncoding=UTF-8
    spring.datasource.username=qzmysql



    spring.redis.sentinel.master=ctrl-redis-26387
    spring.redis.password=dfd2gdD8
    spring.redis.sentinel.nodes=ctrl-redis-sentinel-0.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-1.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-2.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487
  local.properties: |
    userAuthUrl=http://platform-user-auth.test251-qingzhou.com
    userAuditUrl=http://platform-audit.test251-qingzhou.com
    isServiceSyncOpen=false
  disconf.properties: |
    disconf.enable.remote.conf=false
    disconf.conf_server_host=127.0.0.1:20000
    disconf.version=1_0_0_0
    disconf.app=meta
    disconf.env=prod
    disconf.ignore=
    disconf.conf_server_url_retry_times=1
    disconf.conf_server_url_retry_sleep_seconds=1
    disconf.user_define_download_dir=./disconf/download2
    disconf.enable_local_download_dir_in_class_path=true
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-meta-function-permission.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    skiff-owner: platform-user-auth
    PermissionType: function
    skiff-service-module: platform
  name: nsf-meta-function-permission
  namespace: skiff-platform
data:
  root: |
    serviceModuleName: 平台
    description:
      resources:
        code: "资源类型,string类型,不能为空"
        name: "资源名称,string类型,不能为空"
        operations:
          code: "操作类型,string类型,不能为空"
          name: "操作名称,string类型,不能为空"
          readWriteType: "读写操作类型(read/rewrite),string类型, 非必填 , 默认read"
          hideConfig: "是否隐藏页面配置能力,boolean类型, 非必填, 默认否"
          roles: "该权限分配的默认角色,多个以,分隔,不能为空,支持system_admin(平台管理员),system_normal(平台普通用户),tenant_admin(租\
            户管理员),tenant_normal(租户普通用户),project_admin(项目管理员),project_normal(项目普通用户),system_audit(安\
            全审计员),security_manager(安全管理员),managers_manager(运维管理员)"
    resources:
    - name: 服务目录
      code: serviceDirectory
      operations:
      - name: 删除服务
        code: deleteService
        roles: "system_admin,tenant_admin,project_admin,project_normal"
      - name: 添加服务
        code: createService
        roles: "system_admin,tenant_admin,project_admin,project_normal"
      - name: 查看服务
        code: listService
        roles: "system_admin,tenant_admin,project_admin,project_normal"
      - name: 修改服务
        code: updateService
        roles: "system_admin,tenant_admin,project_admin,project_normal"
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-meta-menu-permission.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    skiff-owner: platform-user-auth
    PermissionType: menu
    skiff-service-module: PLATFORM
  name: nsf-meta-menu-permission
  namespace: skiff-platform
data:
  root: |
    description:
      menus:
        code: "菜单标识,string类型,不能为空"
        name: "菜单名称,string类型,不能为空"
        sort: "顺序,int类型,默认为0"
        type: "菜单类型(内部-inner/外部-outer),string类型,非必填,默认为inner"
        path: 菜单路径
        lables: "map结构,菜单标签"
        roles: "该权限分配的默认角色,多个以,分隔,不能为空,支持system_admin(平台管理员),system_normal(平台普通用户),tenant_admin(租\
          户管理员),tenant_normal(租户普通用户),project_admin(项目管理员),project_normal(项目普通用户),system_audit(安\
          全审计员),security_manager(安全管理员),managers_manager(运维管理员)"
        menus: "子菜单配置,数据结构同上级数据结构,支持多层嵌套"
    menus:
    - code: PLATFORM
      name: 企业平台
      sort: 140
      path: /#/permission
      labels:
        product: "true"
      roles: "security_manager,system_normal,managers_manager,system_admin,tenant_admin,system_audit,project_admin"
      menus:
      - code: SERVICE_CATALOG
        name: 服务目录
        sort: 90
        path: /permission/platformManage/serviceCatalog
        roles: "system_admin,system_audit,managers_manager,project_admin,security_manager,tenant_admin"
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-permission-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    skiff-owner: platform-user-auth
    PermissionType: function
    skiff-service-module: nsf
  name: nsf-function-permission
  namespace: skiff-platform
data:
  root: |
    serviceModuleName: 微服务
    description:
      resources:
        code: "资源类型,string类型,不能为空"
        name: "资源名称,string类型,不能为空"
        operations:
          code: "操作类型,string类型,不能为空"
          name: "操作名称,string类型,不能为空"
          readWriteType: "读写操作类型(read/rewrite),string类型, 非必填 , 默认read"
          hideConfig: "是否隐藏页面配置能力,boolean类型, 非必填, 默认否"
          roles: "该权限分配的默认角色,多个以,分隔,不能为空,支持system_admin(平台管理员),system_normal(平台普通用户),tenant_admin(租\
            户管理员),tenant_normal(租户普通用户),project_admin(项目管理员),project_normal(项目普通用户),system_audit(安\
            全审计员),security_manager(安全管理员),managers_manager(运维管理员)"
    resources:
    - name: 服务
      code: service
      operations:
      - name: 查看服务监控
        code: monitor
        roles: "system_admin,system_normal,tenant_admin,tenant_normal,project_admin,project_normal,system_audit,security_manager,managers_manager"
      - name: 查看服务列表
        code: list
        roles: "system_admin,system_normal,tenant_admin,tenant_normal,project_admin,project_normal,system_audit,security_manager,managers_manager"
      - name: 服务管理
        code: manage
        roles: "system_admin,tenant_admin,project_admin"
    - name: 实例
      code: instance
      operations:
      - name: 查看服务实例
        code: list
        roles: "system_admin,system_normal,tenant_admin,tenant_normal,project_admin,project_normal,system_audit,security_manager,managers_manager"
      - name: 服务实例管理
        code: manage
        roles: "system_admin,tenant_admin,project_admin"
    - name: 治理规则
      code: governance
      operations:
      - name: 查看治理规则
        code: list
        roles: "system_admin,system_normal,tenant_admin,tenant_normal,project_admin,project_normal,system_audit,security_manager,managers_manager"
      - name: 管理治理规则
        code: manage
        roles: "system_admin,tenant_admin,project_admin"

    - name: 服务配置
      code: config
      operations:
      - name: 查看配置
        code: list
        roles: "system_admin,system_normal,tenant_admin,tenant_normal,project_admin,project_normal,system_audit,security_manager,managers_manager"
      - name: 配置管理
        code: manage
        roles: "system_admin,tenant_admin,project_admin"
---
# Source: nsf-meta/templates/base/nsf-meta/prom-alert-comfigmap.yaml
# bash charts/nsf-meta/files/alert-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-metric-config
  namespace: skiff-nsf
data:
  root: |-
    metrics:
    # 21GA、22GA在页面提示上有微小差别: 21GA为服务引擎=Agent/Sidecar, 22GA为指标类型=方法治标/流量指标

    - type: 指标类型
      name: 方法指标
      metrics:
      - type: 监听维度
        name: 服务
        inputtype: single-compareForm
        metrics:
        - name: 调用数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的调用数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1000
        - name: 调用成功数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的调用成功数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_success:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1001
        - name: 调用失败数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的调用失败数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_normal_exception:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1002
        - name: 超时次数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的超时次数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_timeout:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1003
        - name: Thread限流数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的Thread限流数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_thread_rejected:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1004
        - name: 熔断数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的熔断数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_short_circuited:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1005
        - name: QPS限流数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的QPS限流数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:service:count_rate_limited:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1006
        - name: 平均时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的平均时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:service:duration_avg:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1007
        - name: 中位数时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的中位数时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:service:duration_500:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1008
        - name: P90时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的P90时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:service:duration_900:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1009
        - name: P99时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的P99时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:service:duration_990:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1010
        - name: P995时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的P995时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:service:duration_995:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1011
        - name: 失败率
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.service }}的失败率已#operator#value%, 当前值{{ $value }}%
          type: system
          template: >-
            (method:service:fail_ratio:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 100 $operator $value)
          unit: "%"
          id: 1012
      - type: 监听维度
        name: 实例
        inputtype: single-compareForm
        metrics:
        - name: 调用数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的调用数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1100
        - name: 调用成功数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的调用成功数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_success:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1101
        - name: 调用失败数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的调用失败数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_normal_exception:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1102
        - name: 超时次数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的超时次数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_timeout:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1103
        - name: Thread限流数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的Thread限流数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_thread_rejected:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1104
        - name: 熔断数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的熔断数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_short_circuited:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1105
        - name: QPS限流数
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的QPS限流数已#operator#value个, 当前值{{ $value }}个
          type: system
          template: >-
            (method:instance:count_rate_limited:minute{env_id="$envCode",project="$projectId",service$service,version$version} $operator $value)
          unit: "个"
          id: 1106
        - name: 平均时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的平均时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:instance:duration_avg:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1107
        - name: 中位数时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的中位数时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:instance:duration_500:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1108
        - name: P90时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的P90时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:instance:duration_900:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1109
        - name: P99时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的P99时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:instance:duration_990:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1110
        - name: P995时延
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的P995时延已#operator#value毫秒, 当前值{{ $value }}毫秒
          type: system
          template: >-
            (method:instance:duration_995:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 1000 $operator $value)
          unit: "毫秒"
          id: 1111
        - name: 失败率
          annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的实例{{ $labels.agent }}的失败率已#operator#value%, 当前值{{ $value }}%
          type: system
          template: >-
            (method:instance:fail_ratio:minute{env_id="$envCode",project="$projectId",service$service,version$version} * 100 $operator $value)
          unit: "%"
          id: 1112
    - type: 指标类型
      name: 流量指标
      metrics:
      - type: 协议
        name: http
        metrics:
        - type: 监听维度
          name: 服务
          inputtype: single-compareForm
          metrics:
          - name: QPS
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入QPS已#operator#value次/秒, 当前值{{ $value }}次/秒
            type: system
            template: >-
              (servicemesh_service:inbound_request_rate{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "次/秒"
            id: 2000
          - name: 失败率
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入失败率已#operator#value%, 当前值{{ $value }}%
            type: system
            template: >-
              (servicemesh_service:inbound_request_error_percentage{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "%"
            id: 2006
          - name: 平均时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入平均时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_avgRT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2018
          - name: P50时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入P50时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_50RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2016
          - name: P90时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入P90时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_90RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2008
          - name: P99时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的http入P99时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_99RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2012
        - type: 监听维度
          name: 服务版本
          inputtype: single-compareForm
          metrics:
          - name: QPS
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入QPS已#operator#value次/秒, 当前值{{ $value }}次/秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_request_rate{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "次/秒"
            id: 2100
          - name: 失败率
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入失败率已#operator#value%, 当前值{{ $value }}%
            type: system
            template: >-
              (servicemesh_service_version:inbound_request_error_percentage{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "%"
            id: 2106
          - name: 平均时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入平均时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_avgRT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2118
          - name: P50时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入P50时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_50RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2116
          - name: P90时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入P90时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_90RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2108
          - name: P99时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的http入P99时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_99RT_seconds{request_protocol="http",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2112
      - type: 协议
        name: dubbo
        metrics:
        - type: 监听维度
          name: 服务
          inputtype: single-compareForm
          metrics:
          - name: QPS
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入QPS已#operator#value次/秒, 当前值{{ $value }}次/秒
            type: system
            template: >-
              (servicemesh_service:inbound_request_rate{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "次/秒"
            id: 2400
          - name: 失败率
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入失败率已#operator#value%, 当前值{{ $value }}%
            type: system
            template: >-
              (servicemesh_service:inbound_request_error_percentage{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "%"
            id: 2406
          - name: 平均时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入平均时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_avgRT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2418
          - name: P50时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入P50时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_50RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2416
          - name: P90时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入P90时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_90RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2408
          - name: P99时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}的dubbo入P99时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service:inbound_response_99RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,} $operator $value)
            unit: "秒"
            id: 2412
        - type: 监听维度
          name: 服务版本
          inputtype: single-compareForm
          metrics:
          - name: QPS
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入QPS已#operator#value次/秒, 当前值{{ $value }}次/秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_request_rate{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "次/秒"
            id: 2500
          - name: 失败率
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入失败率已#operator#value%, 当前值{{ $value }}%
            type: system
            template: >-
              (servicemesh_service_version:inbound_request_error_percentage{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "%"
            id: 2506
          - name: 平均时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入平均时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_avgRT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2518
          - name: P50时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入P50时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_50RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2516
          - name: P90时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入P90时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_90RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2508
          - name: P99时延
            annotation: 租户[[tenant]]项目[[project]]环境[#envCode]您的服务{{ $labels.destination_app }}版本{{ $labels.destination_version }}的dubbo入P99时延已#operator#value秒, 当前值{{ $value }}秒
            type: system
            template: >-
              (servicemesh_service_version:inbound_response_99RT_seconds{request_protocol="dubbo",env_id="$envCode",destination_project="$projectCode",destination_app$service,destination_version$version,} $operator $value)
            unit: "秒"
            id: 2512
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-meta-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-meta
  namespace: skiff-nsf
spec:
  type: ClusterIP
  selector:
    nce-app: nsf-meta
  ports:
    - name: nsf-meta
      port: 80
      protocol: TCP
      targetPort: 8899
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-meta-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    nce-app: nsf-meta
  name: nsf-meta
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      nce-app: nsf-meta
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        nce-app: nsf-meta
        component: nsf-meta
        module: nsf
        version: v2.4
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "nce-app"
                    operator: In
                    values:
                      - nsf-meta
              topologyKey: "kubernetes.io/hostname"
      containers:
        - name: tomcat
          env:
            - name: LOG_STDOUT
              value: "false"
            - name: NCE_PORT
              value: "8899"
            - name: TZ
              value: Asia/Shanghai
            - name: NCE_JAVA_OPTS
              value: "-DsidecarDefaultVersion=v2.20.0-rc2-0b4389b-Ansm-2.9.0-rc1"
          image: "harbor.cloud.netease.com/qztest/nsf-meta:ga-v2.10.2-23b89741"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "100m"
              memory: "1Gi"
          livenessProbe:
            httpGet:
              path: /health
              port: 8899
              scheme: HTTP
            initialDelaySeconds: 60
            timeoutSeconds: 15
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 8899
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /usr/local/tomcat/webapps/ROOT/WEB-INF/classes/local.properties
              subPath: local.properties
              name: meta-conf
            - mountPath: /usr/local/tomcat/webapps/ROOT/WEB-INF/classes/disconf.properties
              subPath: disconf.properties
              name: disconf-conf
            - mountPath: /usr/local/tomcat/webapps/ROOT/WEB-INF/classes/jdbc.properties
              subPath: jdbc.properties
              name: db-conf
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      restartPolicy: Always
      volumes:
        - hostPath:
            path: /data/log/nsf-meta
            type: ""
          name: log
        - configMap:
            name: nsf-meta-config
            items:
              - key: jdbc.properties
                path: jdbc.properties
          name: db-conf
        - configMap:
            name: nsf-meta-config
            items:
              - key: disconf.properties
                path: disconf.properties
          name: disconf-conf
        - configMap:
            name: nsf-meta-config
            items:
              - key: local.properties
                path: local.properties
          name: meta-conf
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-meta/templates/base/nsf-meta/naf-meta-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-meta
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 500m
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: nsf-meta.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-meta
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-server
    component: nsf-server
    module: nsf
    scope: component-monitoring
  name: nsf-meta
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-meta
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-meta
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-meta",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-meta",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-server
    component: nsf-server
    module: nsf
    scope: component-monitoring
  name: nsf-server
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-server
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-server
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-server",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-server",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-registry
    component: nsf-registry
    module: nsf
    scope: component-monitoring
  name: nsf-registry
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-registry
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-registry
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-registry",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-registry",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: istiod
    component: istiod
    module: nsf
    scope: component-monitoring
  name: istiod
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      istio: istiod
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: istiod
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_istio="istiod",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_istio="istiod",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-turbine
    component: nsf-turbine
    module: nsf
    scope: component-monitoring
  name: nsf-turbine
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-turbine
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-turbine
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-turbine",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-turbine",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-config-admin
    component: nsf-config-admin
    module: nsf
    scope: component-monitoring
  name: nsf-config-admin
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-config-admin
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-config-admin
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-admin",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-admin",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-config-portal
    component: nsf-config-portal
    module: nsf
    scope: component-monitoring
  name: nsf-config-portal
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-config-portal
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-config-portal
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-portal",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-portal",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/nsf-meta/nsf-dashboards.yaml
apiVersion: monitoring.kubecube.io/v1
kind: Dashboard
metadata:
  labels:
    app: nsf-config-service
    component: nsf-config-service
    module: nsf
    scope: component-monitoring
  name: nsf-config-service
  namespace: monitoring
spec:
  podSelector:
    matchLabels:
      nce-app: nsf-config-service
  rows:
    - name: CPU 使用(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{namespace="$namespace", pod="$pod"}) by (container) != 0
            title: CPU 使用量
    - name: 内存使用量(容器维度)
      panels:
        - graph:
            datasource: Prometheus
            targets:
              - prometheus:
                  legend: '{{container}}'
                  query: sum(container_memory_working_set_bytes{namespace="$namespace", pod="$pod", container!="", container!="POD", image!=""}) by (container)
            title: 内存使用量
            axes:
              left:
                unit: bytes
  title: nsf-config-service
  variables:
    - query:
        datasource: prometheus
        label: 空间
        name: namespace
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-service",cluster="$cluster"}, namespace)
    - query:
        datasource: prometheus
        label: Pod
        name: pod
        request: label_values(kube_pod_labels{label_nce_app="nsf-config-service",cluster="$cluster", namespace="$namespace"}, pod)
---
# Source: nsf-meta/templates/base/image-pull-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: harbor-qingzhou
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "1"
data:
  .dockerconfigjson: eyJhdXRocyI6IHsiaGFyYm9yLmNsb3VkLm5ldGVhc2UuY29tIjogeyJ1c2VybmFtZSI6ICJza2lmZiIsInBhc3N3b3JkIjogIkpERWF3MjNAamZkVyM3IiwgImF1dGgiOiAiYzJ0cFptWTZTa1JGWVhjeU0wQnFabVJYSXpjPSJ9fX0=
type: kubernetes.io/dockerconfigjson
---
# Source: nsf-meta/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-meta-createdb
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-meta-createdb.sql: |-
    CREATE DATABASE  IF NOT EXISTS nsf_meta DEFAULT CHARACTER SET utf8;
---
# Source: nsf-meta/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-meta-sql
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-meta-sql.sql: |-
    SET NAMES utf8;
    use nsf_meta;
    SET FOREIGN_KEY_CHECKS = 0;
    --
    -- Table structure for table `meta_env`
    --

    CREATE TABLE IF NOT EXISTS `meta_env` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `env_name` varchar(128) NOT NULL COMMENT '环境名',
      `desc` varchar(256) DEFAULT NULL COMMENT '描述信息',
      `owner` text COMMENT '负责人',
      `env_config` text NOT NULL COMMENT '组件地址信息',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=34 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_grpc_message`
    --

    CREATE TABLE IF NOT EXISTS `meta_grpc_message` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `service_id` int(11) NOT NULL,
      `service_name` varchar(255) NOT NULL,
      `package_name` varchar(255) NOT NULL,
      `java_package_name` varchar(512) DEFAULT NULL,
      `model_name` varchar(255) NOT NULL,
      `description` varchar(255) DEFAULT NULL,
      `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
      `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=47 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_grpc_message_field`
    --

    CREATE TABLE IF NOT EXISTS `meta_grpc_message_field` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `message_id` int(11) NOT NULL,
      `field_type` varchar(255) NOT NULL,
      `field_name` varchar(255) NOT NULL,
      `label` varchar(45) NOT NULL,
      `service_id` int(11) NOT NULL,
      `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=671 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_grpc_method`
    --

    CREATE TABLE IF NOT EXISTS `meta_grpc_method` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `service_id` int(11) NOT NULL,
      `package_name` varchar(255) NOT NULL,
      `service_name` varchar(255) NOT NULL,
      `method_name` varchar(255) NOT NULL,
      `proto_file_id` int(11) NOT NULL,
      `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
      `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=100 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_service`
    --

    CREATE TABLE IF NOT EXISTS `meta_service` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `project_id` int(11) NOT NULL COMMENT '项目Id',
      `name` varchar(255) NOT NULL COMMENT '服务名',
      `create_time` bigint(20) DEFAULT NULL COMMENT '创建时间',
      `owner` varchar(45) DEFAULT NULL COMMENT '服务负责人',
      `desc` varchar(45) DEFAULT NULL COMMENT '描述信息',
      `owner_email` varchar(45) DEFAULT NULL COMMENT '服务负责人邮箱',
      `owner_phone` varchar(45) DEFAULT NULL COMMENT '服务负责人电话',
      `service_type` int(2) NOT NULL,
      `is_alert` tinyint(4) DEFAULT '0' COMMENT '是否告警',
      `update_time` bigint(20) DEFAULT NULL COMMENT '更新时间',
      `model_type` int(2) DEFAULT NULL COMMENT '服务模型',
      `deploy_type` int(2) DEFAULT '1' COMMENT '部署类型, k8s,vm',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=35092 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_service_env`
    --

    CREATE TABLE IF NOT EXISTS `meta_service_env` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `service_id` int(11) NOT NULL COMMENT '服务Id',
      `env_name` varchar(45) NOT NULL COMMENT '环境名',
      `project_id` int(11) NOT NULL COMMENT '项目Id',
      `access_type` varchar(45) DEFAULT NULL COMMENT '服务访问类型',
      `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      `env_id` int(11) NOT NULL,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=142033 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_service_proto`
    --

    CREATE TABLE IF NOT EXISTS `meta_service_proto` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `service_id` int(11) NOT NULL,
      `service_proto` text,
      `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
      `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      `service_name` varchar(255) NOT NULL,
      `file_name` varchar(255) NOT NULL,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=255 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_tag`
    --

    CREATE TABLE IF NOT EXISTS `meta_tag` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `tag_key` varchar(256) NOT NULL COMMENT '标签key值',
      `tag_value` varchar(256) DEFAULT NULL COMMENT '标签value',
      `project_id` int(11) NOT NULL COMMENT '项目Id',
      `tag_type` varchar(45) NOT NULL COMMENT '标签类型',
      `env_name` varchar(255) NOT NULL,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=3258 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `meta_tag_service_relation`
    --

    CREATE TABLE IF NOT EXISTS `meta_tag_service_relation` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `service_id` int(11) NOT NULL COMMENT '服务Id',
      `tag_id` int(11) NOT NULL COMMENT '标签Id',
      `tag_type` varchar(45) DEFAULT NULL COMMENT '标签类型',
      `project_id` int(11) NOT NULL COMMENT '项目Id',
      `env_name` varchar(255) NOT NULL,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=196354 DEFAULT CHARSET=utf8mb4;

    --
    -- Table structure for table `nce_gateway_api`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_api` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL,
      `api_name` varchar(255) NOT NULL COMMENT 'api名称',
      `api_path` varchar(255) NOT NULL COMMENT 'api路径',
      `api_method` varchar(255) NOT NULL COMMENT '方法',
      `description` text,
      `type` varchar(255) NOT NULL COMMENT '风格,Action | Restful',
      `service_id` bigint(20) NOT NULL COMMENT '服务id',
      `status` varchar(255) NOT NULL DEFAULT '0' COMMENT 'API状态，0:待发布 1:已发布 2:已下线',
      `regex` varchar(255) DEFAULT NULL,
      `document_status_id` bigint(20) DEFAULT '0' COMMENT 'API文档状态id',
      `request_example_value` text,
      `response_example_value` text,
      `alias_name` varchar(128) DEFAULT NULL COMMENT 'api英文标识，用于SDK生成',
      `project_id` bigint(11) DEFAULT NULL COMMENT '基于项目隔离，项目id',
      `sync_status` tinyint(2) DEFAULT '0' COMMENT '同步状态 0-本地数据 1-同步 2-失步',
      `ext_api_id` bigint(20) DEFAULT NULL COMMENT '外部apiId',
      `swagger_sync` tinyint(2) DEFAULT '0' COMMENT 'swagger同步状态 0-本地数据 1-同步 2-失步',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=153 DEFAULT CHARSET=utf8 COMMENT='API信息表';

    --
    -- Table structure for table `nce_gateway_api_document_status`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_api_document_status` (
      `id` bigint(20) NOT NULL AUTO_INCREMENT,
      `status` varchar(255) NOT NULL COMMENT 'API文档状态',
      PRIMARY KEY (`id`,`status`)
    ) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8 COMMENT='API文档状态表';

    --
    -- Table structure for table `nce_gateway_api_model`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_api_model` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(20) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL COMMENT '修改时间',
      `model_name` varchar(255) NOT NULL COMMENT '模型名称',
      `description` varchar(255) DEFAULT NULL COMMENT '描述',
      `type` tinyint(11) DEFAULT NULL COMMENT '数据模型的类型',
      `format` tinyint(11) DEFAULT NULL COMMENT '数据模型的类别',
      `service_id` bigint(20) NOT NULL COMMENT '服务Id',
      `swagger_sync` tinyint(2) DEFAULT '0' COMMENT 'swagger同步状态 0-本地数据 1-同步 2-失步',
      `project_id` bigint(20) DEFAULT NULL,
      PRIMARY KEY (`id`),
      KEY `index_model_id` (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=56 DEFAULT CHARSET=utf8 COMMENT='数据模型(自定义类型)表';

    --
    -- Table structure for table `nce_gateway_api_status_code`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_api_status_code` (
      `id` bigint(20) NOT NULL AUTO_INCREMENT,
      `create_date` bigint(20) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL COMMENT '修改时间',
      `error_code` varchar(255) DEFAULT NULL,
      `message` varchar(255) DEFAULT NULL,
      `status_code` bigint(20) DEFAULT NULL COMMENT 'http status code',
      `object_id` bigint(20) DEFAULT NULL,
      `type` varchar(255) NOT NULL,
      `description` text COMMENT '描述',
      PRIMARY KEY (`id`),
      KEY `index_api_id` (`object_id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=112 DEFAULT CHARSET=utf8;

    --
    -- Table structure for table `nce_gateway_body_param`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_body_param` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL,
      `api_id` bigint(11) NOT NULL COMMENT 'api id',
      `param_name` varchar(255) NOT NULL COMMENT '参数名称',
      `required` varchar(20) NOT NULL DEFAULT '0' COMMENT '是否必输项, 1表示必须输入，0表示非必须',
      `def_value` varchar(255) DEFAULT NULL COMMENT '默认值',
      `description` varchar(255) DEFAULT NULL COMMENT '描述',
      `type` varchar(255) NOT NULL COMMENT '区分REQUEST|RESPONSE',
      `param_type_id` bigint(20) DEFAULT NULL,
      `array_data_type_id` bigint(20) DEFAULT NULL,
      `association_type` varchar(63) DEFAULT 'NORMAL' COMMENT '关联类型 NORMAL/DUBBO',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=324 DEFAULT CHARSET=utf8 COMMENT='Body和其包含的参数间的对应关系';

    --
    -- Table structure for table `nce_gateway_dubbo_param`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_dubbo_param` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
      `api_id` bigint(11) NOT NULL COMMENT 'api id',
      `param_name` varchar(255) NOT NULL COMMENT '参数名称',
      `required` varchar(20) NOT NULL DEFAULT '0' COMMENT '是否必输项, 1表示必须输入，0表示非必须',
      `def_value` varchar(255) DEFAULT NULL COMMENT '默认值',
      `description` varchar(255) DEFAULT NULL COMMENT '描述',
      `dubbo_type` varchar(255) NOT NULL COMMENT '区分DubboInterface|DubboMethod|DubboVersion|DubboGroup|DubboParam|DubboResponse',
      `param_type_id` bigint(20) DEFAULT NULL,
      `array_data_type_id` bigint(20) DEFAULT NULL,
      `param_sort` tinyint(4) NOT NULL DEFAULT '0' COMMENT '参数序号',
      `param_alias` varchar(127) DEFAULT NULL COMMENT '参数别名',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8 COMMENT='dubbo参数间的对应关系';

    --
    -- Table structure for table `nce_gateway_header_param`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_header_param` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL,
      `api_id` bigint(20) NOT NULL COMMENT 'api id',
      `param_name` varchar(255) NOT NULL COMMENT '参数名称,包含自定义参数以及原生的Header提供的类型,如content-type',
      `param_value` varchar(255) DEFAULT NULL COMMENT '参数值',
      `description` varchar(255) DEFAULT NULL COMMENT '描述',
      `type` varchar(255) NOT NULL COMMENT '区分REQUEST|RESPONSE',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=130 DEFAULT CHARSET=utf8 COMMENT='Header和其包含的参数间的对应关系';

    --
    -- Table structure for table `nce_gateway_model_param`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_model_param` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL,
      `model_id` varchar(255) NOT NULL COMMENT '模型名称',
      `param_name` varchar(255) NOT NULL COMMENT '参数名称',
      `param_type_id` bigint(11) NOT NULL COMMENT '模型中的参数Id,包含基本类型如String等和自定义类型',
      `array_data_type_id` bigint(20) DEFAULT NULL,
      `object_id` bigint(20) DEFAULT NULL,
      `def_value` varchar(255) DEFAULT NULL COMMENT '默认值',
      `description` varchar(255) DEFAULT NULL COMMENT '描述',
      `required` varchar(20) NOT NULL DEFAULT '0',
      PRIMARY KEY (`id`),
      KEY `index_model_param_id` (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8 COMMENT='数据模型和其包含的参数之间的对应关系';

    --
    -- Table structure for table `nce_gateway_operation_log`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_operation_log` (
      `id` bigint(20) NOT NULL AUTO_INCREMENT,
      `create_date` bigint(20) DEFAULT NULL COMMENT '创建时间',
      `email` varchar(255) DEFAULT NULL COMMENT '邮箱',
      `object_id` bigint(20) DEFAULT NULL COMMENT '对象Id',
      `operation` text COMMENT '具体记录',
      `type` varchar(255) DEFAULT NULL COMMENT '对象类型',
      PRIMARY KEY (`id`),
      KEY `index_object_id` (`object_id`,`type`)
    ) ENGINE=InnoDB AUTO_INCREMENT=521 DEFAULT CHARSET=utf8;

    --
    -- Table structure for table `nce_gateway_param_object`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_param_object` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '修改时间',
      `object_value` varchar(1024) DEFAULT NULL COMMENT '匿名类型取值，json字符串',
      PRIMARY KEY (`id`),
      KEY `index_param_object_id` (`id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='参数类型表';

    --
    -- Table structure for table `nce_gateway_param_type`
    --

    CREATE TABLE IF NOT EXISTS `nce_gateway_param_type` (
      `id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
      `create_date` bigint(11) DEFAULT NULL COMMENT '创建时间',
      `modify_date` bigint(20) DEFAULT NULL,
      `param_type` varchar(255) NOT NULL COMMENT '参数类型,基本类型|自定义类型',
      `location` varchar(255) NOT NULL COMMENT '位置，取值为HEADER|BODY',
      `model_id` bigint(20) DEFAULT '0',
      PRIMARY KEY (`id`,`param_type`)
    ) ENGINE=InnoDB AUTO_INCREMENT=438 DEFAULT CHARSET=utf8 COMMENT='参数类型表';

    --
    -- Table structure for table `nsf_meta_dubbo_api`
    --

    CREATE TABLE IF NOT EXISTS `nsf_meta_dubbo_api` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `api_name` varchar(255) NOT NULL,
      `api_method` varchar(255) NOT NULL,
      `service_id` int(11) NOT NULL,
      `description` varchar(255) DEFAULT NULL,
      `dubbo_group` varchar(255) DEFAULT NULL,
      `version` varchar(255) DEFAULT NULL,
      `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
      `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='dubbo api 信息';

    --
    -- Table structure for table `nsf_sidecar_info`
    --

    CREATE TABLE IF NOT EXISTS `nsf_sidecar_info` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `file_name` varchar(255) NOT NULL,
      `upload_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
      `sidecar_version` varchar(255) NOT NULL,
      `is_default` int(2) NOT NULL DEFAULT '0',
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8mb4 COMMENT='sidecar 文件信息';

    --
    -- Table structure for table `service_mesh_info`
    --

    CREATE TABLE IF NOT EXISTS `service_mesh_info` (
      `id` int(4) NOT NULL AUTO_INCREMENT,
      `mesh_name` varchar(255) NOT NULL,
      `env_name` varchar(255) NOT NULL,
      `istio_version` varchar(255) NOT NULL,
      `external_access` varchar(4) NOT NULL DEFAULT '1',
      `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
      PRIMARY KEY (`id`)
    ) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8;

    --
    -- Initial data for API data model.
    --

    alter table `meta_service` modify column `desc` varchar(100) comment '描述信息';

    BEGIN;
    INSERT INTO `nce_gateway_param_type` VALUES (1, 1515548961293, 20180110030623, 'String', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (2, 1515548961293, 20180110030709, 'Content-Type', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (3, 1515548961293, 20180110031122, 'Accept-Language', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (4, 1515548961293, 20180110033838, 'Array', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (5, 1515548961293, 20180110033911, 'Boolean', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (6, 1515548961293, 20180110033931, 'File', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (7, 1515548961293, 20180110033946, 'Number', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (8, 1515548961293, 20180110033959, 'Object', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (9, 1515548961293, 20180110034024, 'Variable', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (10, 1515548961293, 20180110034151, 'Accept-Charset', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (11, 1515548961293, 20180110034201, 'Accept', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (12, 1515548961293, 20180110034237, 'Accept-Encoding', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (13, 1515548961293, 20180110034303, 'Accept-Datetime', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (14, 1515548961293, 20180110034318, 'Authorization', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (15, 1515548961293, 20180110034338, 'Cache-Control', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (16, 1515548961293, 20180110034353, 'Connection', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (17, 1515548961293, 20180110034405, 'Cookie', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (18, 1515548961293, 20180110034416, 'Content-Disposition', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (19, 1515548961293, 20180110034427, 'Content-Length', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (20, 1515548961293, 20180110034435, 'Content-MD5', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (21, 1515548961293, 20180110034452, 'Date', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (22, 1515548961293, 20180110034459, 'Expect', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (23, 1515548961293, 20180110034506, 'From', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (24, 1515548961293, 20180110034518, 'Host', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (25, 1515548961293, 20180110034525, 'If-Match', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (26, 1515548961293, 20180110034527, 'If-Modified-Since', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (27, 1515548961293, 20180110034535, 'If-None-Match', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (28, 1515548961293, 20180110034541, 'If-Range', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (29, 1515548961293, 20180110034548, 'If-Unmodified-Since', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (30, 1515548961293, 20180110034555, 'Max-Forwards', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (31, 1515548961293, 20180110034601, 'Origin', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (32, 1515548961293, 20180110034607, 'Pragma', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (33, 1515548961293, 20180110034614, 'Proxy-Authorization', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (34, 1515548961293, 20180110034619, 'Range', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (35, 1515548961293, 20180110034624, 'Referer', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (36, 1515548961293, 20180110034632, 'TE', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (37, 1515548961293, 20180110034638, 'User-Agent', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (38, 1515548961293, 20180110034645, 'Upgrade', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (39, 1515548961293, 20180110034657, 'Via', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (40, 1515548961293, 20180110034701, 'Warning', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (41, 1515548961293, 20180110034709, 'X-Requested-With', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (42, 1515548961293, 20180110034714, 'DNT', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (43, 1515548961293, 20180110034720, 'X-Forwarded-For', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (44, 1515548961293, 20180110034727, 'X-Forwarded-Host', 'HEADER', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (327, 1515548961291, 20180910102527, 'Int', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (328, 1515548961291, 20180910102527, 'Long', 'BODY', 0);
    INSERT INTO `nce_gateway_param_type` VALUES (329, 1515548961291, 20180910102527, 'Double', 'BODY', 0);
    COMMIT;

    BEGIN;
    INSERT INTO `nce_gateway_api_document_status` VALUES (1, '开发中');
    INSERT INTO `nce_gateway_api_document_status` VALUES (2, '联调中');
    INSERT INTO `nce_gateway_api_document_status` VALUES (3, '提测');
    INSERT INTO `nce_gateway_api_document_status` VALUES (4, '已上线');
    COMMIT;

    alter table `meta_service` add column alias_name varchar(63) comment '别名';
    alter table `meta_service` add column language int(11) not null default 0 comment '语言：java，NodeJs，C++，C，Python，go';
    alter table `meta_service` add column reference_count int(11) not null default 0 comment 'meta的引用计数';

    create table `meta_service_binding_log` (
        `id` bigint(11) not null AUTO_INCREMENT COMMENT '主键',
        `create_time` bigint(11) default null COMMENT '创建时间',
        `service_id` bigint(11) not null COMMENT '服务元数据Id',
        `project_id` bigint(11) default null COMMENT '服务元数据所属项目Id',
        `publish_type` varchar(32) default null COMMENT '服务元数据绑定发布来源类型',
        PRIMARY KEY (`id`)
    );

    #mysql
    create unique index uk_projectIdName on meta_service(name,project_id);
    create unique index uk_projectIdEnvNameTag on meta_tag(tag_key(128),tag_value(256),project_id,env_name(64),tag_type);
    create unique index uk_serviceIdTagId on meta_tag_service_relation(service_id,tag_id,env_name);
    create unique index uk_serviceIdEnvId on meta_service_env(service_id,env_id);

    CREATE TABLE `nsf_sidecar_image_info` (
    `id` int NOT NULL AUTO_INCREMENT,
    `upload_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
    `image_tag` varchar(255) NOT NULL,
    `is_available` tinyint(1) NOT NULL DEFAULT '1',
    `is_global_default` tinyint(1) NOT NULL DEFAULT '0',
    PRIMARY KEY (`id`),
    UNIQUE KEY `image_tag` (`image_tag`)
    ) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4  COMMENT='sidecar冷升级版本信息';
---
# Source: nsf-meta/templates/pre-install-hooks/hooks-jobs.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-pre-install-hook
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook-weight": "2"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      containers:
        - name: job-done
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.2-20221206-multi
          command: ['sh', '-c', 'echo "all jobs completed"']
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
      volumes:
        - name: nsf-meta-createdb
          configMap:
            name: nsf-meta-createdb
        - name: nsf-meta-sql
          configMap:
            name: nsf-meta-sql
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: nsf-meta-createdb
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.2-20221206-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_meta.service_mesh_info;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-meta-createdb.sql"
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          volumeMounts:
            - mountPath: /tmp
              name: nsf-meta-createdb
        - name: nsf-meta-sql
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.2-20221206-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_meta.service_mesh_info;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-meta-sql.sql"
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          volumeMounts:
            - mountPath: /tmp
              name: nsf-meta-sql
      restartPolicy: Never
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
  backoffLimit: 4
---

---
# Source: nsf-server/charts/powerful/templates/cr.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: powerful
---
# Source: nsf-server/charts/nsf-agent-injecter-csr/templates/agent-csr-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: webhook-cert-sa
  namespace: skiff-nsf
---
# Source: nsf-server/charts/powerful/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: powerful-operator
  namespace: skiff-nsf
  labels:
    release: release-name
---
# Source: nsf-server/templates/base/role.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: nsf-server
  name: nsf-server-service-account
  namespace: skiff-nsf
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-portal-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-portal-config
  namespace: skiff-nsf
data:
  application-qzliantiao.properties: |2
    spring.datasource.url=jdbc:mysql://192.168.19.103:3306/nsf_portal?characterEncoding=utf8&useSSL=false
    spring.datasource.username=qzmysql
    spring.datasource.password=tOmkipoejd832k


    spring.redis.sentinel.master=ctrl-redis-26387
    spring.redis.password=dfd2gdD8
    spring.redis.sentinel.nodes=ctrl-redis-sentinel-0.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-1.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-2.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487
    spring.redis.timeout=2000
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-service-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-service-config
  namespace: skiff-nsf
data:
  application-qzliantiao.properties: |2
    spring.datasource.url=jdbc:mysql://192.168.19.103:3306/nsf_config?characterEncoding=utf8&useSSL=false
    spring.datasource.username=qzmysql
    spring.datasource.password=tOmkipoejd832k
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-turbine-config
  namespace: skiff-nsf
data:
  nsf-jdbc.properties: |
    nsf.registry.auth.enable=true
    nsf.registry.auth.server=http://platform-service-auth.test251-qingzhou.com
    nsf.registry.auth.ak=0c73d5595b834eb5b5fe30b5ac9e419b
    nsf.registry.auth.sk=e7f15f9387cc403fb30965f1805ee56f
    redis.enabled=true
    etcd.enabled=false
    configDataSource=redis
    # etcdUrl=http://10.246.250.65:6379,http://10.246.250.66:6379,http://10.246.250.67:6379
    turbine.envs=prod

    spring.data.redis.sentinel.master=ctrl-redis-26387
    spring.data.redis.password=dfd2gdD8
    spring.data.redis.sentinel.nodes=ctrl-redis-sentinel-0.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-1.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-2.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487
---
# Source: nsf-server/charts/powerful/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: powerful-operator
  namespace: skiff-nsf
  labels:
    release: release-name
data:
  values.yaml: |-
    apps: []
---
# Source: nsf-server/templates/base/nsf-server-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-server-config
  namespace: skiff-nsf
data:
  nsf.properties: |
    #etcd地址（需修改为实际地址）
    etcdUrl=http://10.246.250.65:6379,http://10.246.250.66:6379,http://10.246.250.67:6379
    #是否开启etcd watch.多nsf-server实例必须开启.演示单节点可设置为false，不依赖ETCD
    watchConfig=true
    # 数据同步方式，可选值（etcd，redis）
    configDataSource=redis
    #监控聚合地址
    turbineClusterUrl=http://nsf-turbine.skiff-nsf.svc.cluster.local:8001/turbine.stream?cluster=%s
    #服务拓扑缓存时间(秒)
    topoCacheTimeSeconds=10
    #配置中心portal VIP
    portalUrl=http://nsf-config-portal.test251-qingzhou.com
    authUrl=http://platform-service-auth.test251-qingzhou.com
    #是否开启认证
    isAuthentication=false
    #是否开启运维管理-系统管理
    isSysMgr=false
    # jwk set 瘦身开关
    jwkSetLean=false
    # 外部服务管理方，可选（Platform平台暂不支持；Server微服务）
    manageOuterService=Server
    prometheusUrl=http://thanos.test251-qingzhou.com
    #alertRuleUrl=http://
    alertRuleUrl=
    userAuthUrl=http://platform-user-auth.test251-qingzhou.com
    userAuditUrl=http://platform-audit.test251-qingzhou.com
    #是否开启配置中心
    isNsfConfigOpen=true
    #是否开启审计
    isAuditOpen=true
    heartbeat=45000
    environment=prod
    turbine=http://nsf-turbine.test251-qingzhou.com
    zookeeperUrl=zookeeper.apigw-demo.svc.cluster.local:2181
    registryUrl=http://nsf-registry-0.test251-qingzhou.com/eureka/,http://nsf-registry-1.test251-qingzhou.com/eureka/
    nacosRegistryUrl=http://nsf-nacos.test251-qingzhou.com

    metaServerUrl=http://nsf-meta.test251-qingzhou.com/
    nsf.agent.downloadUrl=http://console.test251-qingzhou.com/download/nsf/
    serverUrl=http://nsf-server.test251-qingzhou.com
    gportalUrl=http://apigw-gportal.test251-qingzhou.com
    configServiceUrl=http://nsf-config-service.test251-qingzhou.com
    arthusTunnelServer=nsf-turbine.test251-qingzhou.com
    importK8sService=true
    autoCreateServiceApp=true
    defaultRegistryType=eureka
    #取实际环境对应的项目标识,缺省值:project1
    defaultProjectCode=project1
    entranceTrafficMarkEnvoyfilterMetadataIstioIoRev=stable
    enableIstioRevision=true
    istioRevision=stable
    slimeUrl=slime.istio-system:8081
    sidecarDefaultVersion=v2.18.0-0d8fa66-Ansm-2.8.0-rc1
  nsf-config.yaml: |
    nsf:
      monitor:
        components:
          - name: "nsf-server"
            kind: "Deployment"
            namespace: "skiff-nsf"
          - name: "nsf-meta"
            kind: "Deployment"
            namespace: "skiff-nsf"
          - name: "nsf-api-plane"
            kind: "Deployment"
            namespace: "istio-system"
          - name: "slime"
            kind: "Deployment"
            namespace: "istio-system"
          - name: "istiod-qz112"
            kind: "Deployment"
            namespace: "istio-system"
        metrics:
          - key: "PILOT_POD_PUSH_TIMES"
            value: "sum(increase(pilot_xds_pushes{<pod>, <type>, <env_id>}[<interval>s]))"
          - key: "PILOT_POD_CONN_COUNT"
            value: "sum(pilot_xds{<pod>, version=\"\", <env_id>})"
          - key: "PILOT_POD_PUSH_DELAY"
            value: "sum(increase(pilot_xds_send_time_sum{<pod>, <env_id>}[<interval>s])) / sum(increase(pilot_xds_send_time_count{<pod>, <env_id>}[<interval>s]))"
          - key: "PILOT_POD_PUSH_REJECT_TIMES"
            value: "100 * sum(increase(pilot_total_xds_rejects{<pod>, <env_id>}[<interval>s])) / sum(increase(pilot_xds_pushes{<pod>, <env_id>}[<interval>s]))"
          - key: "PILOT_POD_PUSH_TIMEOUT_TIMES"
            value: "100 * sum(increase(pilot_xds_write_timeout{<pod>, <env_id>}[<interval>s])) / sum(increase(pilot_xds_pushes{<pod>, <env_id>}[<interval>s]))"
          - key: "PILOT_POD_PUSH_DELAY_50"
            value: "histogram_quantile(0.5, sum(rate(pilot_xds_send_time_bucket{<pod>, <env_id>}[<interval>s])) by (le))"
          - key: "PILOT_POD_PUSH_DELAY_90"
            value: "histogram_quantile(0.9, sum(rate(pilot_xds_send_time_bucket{<pod>, <env_id>}[<interval>s])) by (le))"
          - key: "PILOT_POD_PUSH_DELAY_99"
            value: "histogram_quantile(0.99, sum(rate(pilot_xds_send_time_bucket{<pod>, <env_id>}[<interval>s])) by (le))"
      cluster:
        clusterMappings:
          - clusterId: "default"
            clusterName: "dev02-huatai-ctrl"
  nsf-jdbc.properties: |
    spring.datasource.dbcp2.initial-size=32
    spring.datasource.dbcp2.max-idle=64
    spring.datasource.dbcp2.max-total=64
    spring.datasource.dbcp2.min-idle=32
    spring.datasource.dbcp2.validationQuery=select now()
    spring.datasource.dbcp2.testWhileIdle=false
    spring.datasource.dbcp2.testOnBorrow=true
    spring.datasource.dbcp2.timeBetweenEvictionRunsMillis=-1
    spring.datasource.dbcp2.numTestsPerEvictionRun=3
    spring.datasource.dbcp2.minEvictableIdleTimeMillis=3600000

    spring.datasource.driver-class-name=com.mysql.jdbc.Driver
    spring.datasource.password=tOmkipoejd832k
    spring.datasource.type=org.apache.commons.dbcp2.BasicDataSource
    spring.datasource.url=jdbc:mysql://192.168.19.103:3306/nsf_server?&autoReconnect=true&connectTimeout=5000&socketTimeout=50000&generateSimpleParameterMetadata=true&characterEncoding=UTF-8
    spring.datasource.username=qzmysql



    grpc.server.port=8980
    grpc.server.address=0.0.0.0
    #nsf-registry地址
    eureka.client.serviceUrl.defaultZone=http://nsf-registry-0.test251-qingzhou.com/eureka/,http://nsf-registry-1.test251-qingzhou.com/eureka/

    ## redis配置
    spring.redis.sentinel.master=ctrl-redis-26387
    spring.redis.password=dfd2gdD8
    spring.redis.sentinel.nodes=ctrl-redis-sentinel-0.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-1.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487,ctrl-redis-sentinel-2.ctrl-redis-sentinel.skiff-platform.svc.cluster.local.:26487

    tracetioServiceName=slime.istio-system:8081
    istiodName=istiod-qz112
  disconf.properties: |
    disconf.enable.remote.conf=false
    disconf.conf_server_host=127.0.0.1:20000
    disconf.version=1_0_0_0
    disconf.app=NCE
    disconf.env=online_production
    disconf.ignore=
    disconf.conf_server_url_retry_times=1
    disconf.conf_server_url_retry_sleep_seconds=1
    disconf.user_define_download_dir=./disconf/download2
    disconf.enable_local_download_dir_in_class_path=true
  k8s.yaml: |-
    k8s:
      clusters:
        # 单集群可不配相关信息
        default:
          k8s-api-server: ""
          cert-data: ""
          key-data: ""
---
# Source: nsf-server/templates/post-install-hooks/post-install-job.yaml
apiVersion: v1
data:
  auth.yaml: |
    ## 依赖的远程仓库地址
    harbor.cloud.netease.com:
      ## 仓库用户名，如果不需要用户名可以随便填写
      username: skiff
      ## 仓库密码，如果不需要可以随便填写
      password: JDEaw23@jfdW#7
      ## 是否需要安全验证，如果未使用https则设置为true，反之为false
      insecure: true
    ## 依赖的远程仓库地址
    harbor.cloud.netease.com:
      ## 仓库用户名，如果不需要用户名可以随便填写
      username: skiff
      ## 仓库密码，如果不需要可以随便填写
      password: JDEaw23@jfdW#7
      ## 是否需要安全验证，如果未使用https则设置为true，反之为false
      insecure: true
  image_list: |
    skiff-agent:nsf-agent-ga-v2.10.2
kind: ConfigMap
metadata:
  name: sync-agent-image-config
  namespace: skiff-nsf
---
# Source: nsf-server/charts/nsf-agent-injecter-csr/templates/agent-csr-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: webhook-cert-cluster-role-nsf
rules:
  - apiGroups: ["admissionregistration.k8s.io"]
    resources: ["mutatingwebhookconfigurations"]
    verbs: ["get", "create", "patch"]
  - apiGroups: ["certificates.k8s.io"]
    resources: ["certificatesigningrequests"]
    verbs: ["create", "get", "delete"]
  - apiGroups: ["certificates.k8s.io"]
    resources: ["certificatesigningrequests/approval"]
    verbs: ["update"]
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["create", "get", "patch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["certificates.k8s.io"]
    resourceNames: ["kubernetes.io/kubelet-serving"]
    resources: ["signers"]
    verbs: ["approve"]
---
# Source: nsf-server/charts/powerful/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: powerful-operator
  labels:
    release: release-name
rules:
  - apiGroups:
      - '*'
    resources:
      - '*'
    verbs:
      - '*'
  - apiGroups:
      - ""
    resources:
      - pods
      - services
      - services/finalizers
      - endpoints
      - persistentvolumeclaims
      - events
      - configmaps
      - secrets
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
  - apiGroups:
      - apps
    resources:
      - deployments
      - daemonsets
      - replicasets
      - statefulsets
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - configmaps
      - secrets
    verbs:
      - '*'
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
    verbs:
      - get
      - create
  - apiGroups:
      - apps
    resourceNames:
      - powerful-operator
    resources:
      - deployments/finalizers
    verbs:
      - update
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
  - apiGroups:
      - apps
    resources:
      - replicasets
      - deployments
    verbs:
      - get
  - apiGroups:
      - skiff.netease.com
    resources:
      - '*'
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
---
# Source: nsf-server/charts/nsf-agent-injecter-csr/templates/agent-csr-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: webhook-cert-cluster-role-nsf-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: webhook-cert-cluster-role-nsf
subjects:
  - kind: ServiceAccount
    name: webhook-cert-sa
    namespace: skiff-nsf
---
# Source: nsf-server/charts/powerful/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: powerful-operator-skiff-nsf
  labels:
    release: release-name
subjects:
  - kind: ServiceAccount
    name: powerful-operator
    namespace: skiff-nsf
roleRef:
  kind: ClusterRole
  name: powerful-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: nsf-server/templates/base/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: nsf-server
  name: nsf-server-skiff-nsf
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: nsf-server-service-account
    namespace: skiff-nsf
---
# Source: nsf-server/charts/nsf-agent-injecter/templates/agent-inject-deploy.yaml
kind: Service
apiVersion: v1
metadata:
  name: agent-injecter-svc
  namespace: skiff-nsf
spec:
  selector:
    app: agent-injecter
  ports:
    - name: agent-injecter-server
      port: 443
      protocol: TCP
      targetPort: 443
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-admin-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nsf-config-admin
  namespace: skiff-nsf
  labels:
    nce-app: nsf-config-admin
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 10770
  selector:
    nce-app: nsf-config-admin
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-portal-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-config-portal
  namespace: skiff-nsf
spec:
  type: ClusterIP
  selector:
    nce-app: nsf-config-portal
  ports:
    - port: 80
      targetPort: 10790
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-config-service
  namespace: skiff-nsf
spec:
  type: ClusterIP
  selector:
    nce-app: nsf-config-service
  ports:
    - port: 80
      targetPort: 10780
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-turbine
  namespace: skiff-nsf
spec:
  clusterIP: None
  selector:
    nce-app: nsf-turbine
  ports:
    - name: http
      port: 80
      targetPort: 8001
    - name: ws
      port: 7777
      targetPort: 7777
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-turbine-0
  namespace: skiff-nsf
spec:
  clusterIP: None
  selector:
    nce-app: nsf-turbine
    statefulset.kubernetes.io/pod-name: nsf-turbine-0
  ports:
    - name: http
      port: 80
      targetPort: 8001
    - name: ws
      port: 7777
      targetPort: 7777
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-turbine-1
  namespace: skiff-nsf
spec:
  clusterIP: None
  selector:
    nce-app: nsf-turbine
    statefulset.kubernetes.io/pod-name: nsf-turbine-1
  ports:
    - name: http
      port: 80
      targetPort: 8001
    - name: ws
      port: 7777
      targetPort: 7777
---
# Source: nsf-server/charts/powerful/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: powerful-operator
  labels:
    release: release-name
  namespace: skiff-nsf
spec:
  selector:
    name: powerful-operator
  ports:
    - name: http
      port: 80
      targetPort: 8080
  type: ClusterIP
---
# Source: nsf-server/templates/base/nsf-server-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: nsf-server
  namespace: skiff-nsf
spec:
  type: ClusterIP
  selector:
    nce-app: nsf-server
  ports:
    - name: nsf-server
      port: 80
      targetPort: 8866
    - name: grpc-nsf-server
      port: 8980
      targetPort: 8980
---
# Source: nsf-server/charts/nsf-agent-injecter/templates/agent-inject-deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: agent-injecter
  name: agent-injecter
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agent-injecter
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: agent-injecter
    spec:
      containers:
        - name: agent-inject
          image: "harbor.cloud.netease.com/qztest/agent-injecter:v3.4"
          command:
            - /usr/local/bin/agent-injecter
            - --certFile=/etc/webhook/certs/tls.crt
            - --keyFile=/etc/webhook/certs/tls.key
            - --hostPath=/etc/nsf/agent
            - --nsfLabelRegion=default_region
            - --nsfLabelZone=default_az
            - --nsfLabelCluster=default
            - --image=harbor.cloud.netease.com/library/skiff-agent:nsf-agent-ga-v2.10.2
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "1"
              memory: "1Gi"
          volumeMounts:
            - name: webhook-certs
              mountPath: /etc/webhook/certs
              readOnly: true
      dnsPolicy: ClusterFirstWithHostNet
      imagePullSecrets:
        - name: harbor-qingzhou
      restartPolicy: Always
      volumes:
        - name: webhook-certs
          secret:
            secretName: agent-injecter-certs
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-admin-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nsf-config-admin
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      nce-app: nsf-config-admin
  template:
    metadata:
      labels:
        nce-app: nsf-config-admin
        component: nsf-config-admin
        module: nsf
        version: v2.4
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "nce-app"
                    operator: In
                    values:
                      - nsf-config-admin
              topologyKey: "kubernetes.io/hostname"
      containers:
        - env:
            - name: NCE_JAVA_OPTS
              value: "-Dspring.profiles.active=qzliantiao -Dnsf.registry.auth.enable=true -Dnsf.registry.auth.server=http://platform-service-auth.test251-qingzhou.com -Dnsf.registry.auth.ak=0c73d5595b834eb5b5fe30b5ac9e419b -Dnsf.registry.auth.sk=e7f15f9387cc403fb30965f1805ee56f"
            - name: NCE_PORT
              value: "10770"
            - name: TZ
              value: Asia/Shanghai
          image: "harbor.cloud.netease.com/qztest/nsf-config-admin:v2.5-nsf-3e4fe889"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "100m"
              memory: "256Mi"
          livenessProbe:
            httpGet:
              path: /health
              port: 10770
              scheme: HTTP
            initialDelaySeconds: 60
            timeoutSeconds: 15
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 10770
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          name: tomcat
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /apollo-adminservice/config/application-qzliantiao.properties
              subPath: application-qzliantiao.properties
              name: conf
      volumes:
        - hostPath:
            path: /data/log/nsf-config-admin
          name: log
        - configMap:
            name: nsf-config-service-config
            items:
              - key: application-qzliantiao.properties
                path: application-qzliantiao.properties
          name: conf
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-portal-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    nce-app: nsf-config-portal
  name: nsf-config-portal
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      nce-app: nsf-config-portal
  template:
    metadata:
      labels:
        nce-app: nsf-config-portal
        component: nsf-config-portal
        module: nsf
        version: v2.4
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "nce-app"
                    operator: In
                    values:
                      - nsf-config-portal
              topologyKey: "kubernetes.io/hostname"
      containers:
        - env:
            - name: NCE_JAVA_OPTS
              value: "-Dspring.profiles.active=qzliantiao -Ddev_meta=http://nsf-config-service.skiff-nsf.svc.cluster.local -Dnsf.registry.auth.enable=true -Dnsf.registry.auth.server=http://platform-service-auth.test251-qingzhou.com -Dnsf.registry.auth.ak=0c73d5595b834eb5b5fe30b5ac9e419b -Dnsf.registry.auth.sk=e7f15f9387cc403fb30965f1805ee56f -Dapi.connectTimeout=800 -Dspring.resources.add-mappings=false"
            - name: NCE_PORT
              value: "10790"
            - name: TZ
              value: Asia/Shanghai
          image: "harbor.cloud.netease.com/qztest/nsf-config-portal:v2.5-nsf-3e4fe889"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "100m"
              memory: "256Mi"
          livenessProbe:
            httpGet:
              path: /healthz
              port: 10790
              scheme: HTTP
            initialDelaySeconds: 30
            timeoutSeconds: 15
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /healthz
              port: 10790
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          name: tomcat
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /apollo-portal/config/application-qzliantiao.properties
              subPath: application-qzliantiao.properties
              name: conf
      volumes:
        - hostPath:
            path: /data/log/nsf-config-portal
          name: log
        - configMap:
            name: nsf-config-portal-config
            items:
              - key: application-qzliantiao.properties
                path: application-qzliantiao.properties
          name: conf
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    nce-app: nsf-config-service
  name: nsf-config-service
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      nce-app: nsf-config-service
  template:
    metadata:
      labels:
        nce-app: nsf-config-service
        component: nsf-config-service
        module: nsf
        version: v2.4
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "nce-app"
                    operator: In
                    values:
                      - nsf-config-service
              topologyKey: "kubernetes.io/hostname"
      containers:
        - env:
            - name: NCE_JAVA_OPTS
              value: "-Dspring.profiles.active=qzliantiao -Dnsf.registry.auth.enable=true -Dnsf.registry.auth.server=http://platform-service-auth.test251-qingzhou.com -Dnsf.registry.auth.ak=0c73d5595b834eb5b5fe30b5ac9e419b -Dnsf.registry.auth.sk=e7f15f9387cc403fb30965f1805ee56f -Deureka.instance.homePageUrl=http://nsf-config-service.test251-qingzhou.com -Dlong.polling.timeout=58"
            - name: NCE_PORT
              value: "10780"
            - name: TZ
              value: Asia/Shanghai
          image: "harbor.cloud.netease.com/qztest/nsf-config-service:v2.5-nsf-3e4fe889"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "4Gi"
            requests:
              cpu: "100m"
              memory: "256Mi"
          livenessProbe:
            httpGet:
              path: /health
              port: 10780
              scheme: HTTP
            initialDelaySeconds: 60
            timeoutSeconds: 15
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 10780
              scheme: HTTP
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          name: tomcat
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /apollo-configservice/config/application-qzliantiao.properties
              subPath: application-qzliantiao.properties
              name: conf
      volumes:
        - hostPath:
            path: /data/log/nsf-config-service
          name: log
        - configMap:
            name: nsf-config-service-config
            items:
              - key: application-qzliantiao.properties
                path: application-qzliantiao.properties
          name: conf
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-server/charts/powerful/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    release: release-name
  name: powerful-operator
  namespace: skiff-nsf
spec:
  replicas: 1
  selector:
    matchLabels:
      name: powerful-operator
  template:
    metadata:
      labels:
        name: powerful-operator
    spec:
      serviceAccountName: powerful-operator
      imagePullSecrets:
        - name: harbor-qingzhou
        - name: qingzhou-secret
      containers:
        - name: powerful-operator
          image: "harbor.cloud.netease.com/qztest/istio/powerful-bundle:v1.5.10"
          imagePullPolicy: Always
          env:
            - name: WATCH_NAMESPACE
              value: ""
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPERATOR_NAME
              value: "powerful-operator"
          args:
            - operator
            - --deletion-crds=networking.istio.io/v1alpha3:VirtualService,networking.istio.io/v1alpha3:DestinationRule,networking.istio.io/v1alpha3:Sidecar,networking.istio.io/v1alpha3:VersionManager,networking.istio.io/v1alpha3:PluginManager,networking.istio.io/v1alpha3:GatewayPlugin,networking.istio.io/v1alpha3:EnvoyPlugin,networking.istio.io/v1alpha3:ServiceEntry,rbac.istio.io/v1alpha1:ServiceRole,rbac.istio.io/v1alpha1:ServiceRoleBinding,authentication.istio.io/v1alpha1:Policy,microservice.netease.com/v1alpha1:SmartLimiter,microservice.netease.com/v1alpha1:ServiceFence
          volumeMounts:
            - name: powerful
              mountPath: /opt/helm/helm-charts/powerful/values-overlay.yaml
              subPath: values.yaml
          resources:
            limits:
              cpu: "1"
              memory: "512Mi"
            requests:
              cpu: "1"
              memory: "512Mi"
      volumes:
        - name: powerful
          configMap:
            name: powerful-operator
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
---
# Source: nsf-server/templates/base/nsf-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    nce-app: nsf-server
  name: nsf-server
  namespace: skiff-nsf
spec:
  replicas: 2
  selector:
    matchLabels:
      nce-app: nsf-server
  template:
    metadata:
      labels:
        nce-app: nsf-server
        component: nsf-server
        module: nsf
        version: v2.7
    spec:
      serviceAccountName: nsf-server-service-account
      imagePullSecrets:
        - name: harbor-qingzhou
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: "nce-app"
                    operator: In
                    values:
                      - nsf-server
              topologyKey: "kubernetes.io/hostname"
      containers:
        - name: tomcat
          env:
            - name: LOG_STDOUT
              value: "false"
            - name: SKIFF_LOGFILE
              value: "/usr/local/tomcat/logs/catalina*.log|day|3"
            - name: NCE_PORT
              value: "8866"
            - name: NCE_JAVA_OPTS
              value: "-Xverify:none -XX:TieredStopAtLevel=1 -Dresource.checker.enabled=false -Dnsf.registry.auth.enable=true -Dnsf.registry.auth.server=http://platform-service-auth.test251-qingzhou.com -Dnsf.registry.auth.ak=0c73d5595b834eb5b5fe30b5ac9e419b -Dnsf.registry.auth.sk=e7f15f9387cc403fb30965f1805ee56f -Dgrpc.server.port=8980  -DistioTurbineUrl=http://nsf-turbine.test251-qingzhou.com"
            - name: TZ
              value: Asia/Shanghai
          image: "harbor.cloud.netease.com/qztest/nsf-server:dev-yy-container-197959fc-dev"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "2"
              memory: "4Gi"
            requests:
              cpu: "100m"
              memory: "1Gi"
          livenessProbe:
            httpGet:
              path: /api/health
              port: 8866
              scheme: HTTP
            initialDelaySeconds: 60
            timeoutSeconds: 15
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 10
          readinessProbe:
            httpGet:
              path: /actuator/health
              port: 8866
              scheme: HTTP
            initialDelaySeconds: 60
            timeoutSeconds: 15
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 10
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /root/nsf-config.yaml
              name: nsf-yaml-conf
              subPath: nsf-config.yaml
            - mountPath: /root/nsf.properties
              subPath: nsf.properties
              name: nsf-conf
            - mountPath: /root/disconf.properties
              subPath: disconf.properties
              name: disconf-conf
            - mountPath: /root/nsf-jdbc.properties
              subPath: nsf-jdbc.properties
              name: db-conf
            - mountPath: /root/k8s.yaml
              subPath: k8s.yaml
              name: k8s-conf
      volumes:
        - hostPath:
            path: "/data/log/nsf-server"
          name: log
        - configMap:
            name: nsf-server-config
            items:
              - key: nsf-jdbc.properties
                path: nsf-jdbc.properties
          name: db-conf
        - configMap:
            name: nsf-server-config
            items:
              - key: nsf-config.yaml
                path: nsf-config.yaml
          name: nsf-yaml-conf
        - configMap:
            name: nsf-server-config
            items:
              - key: disconf.properties
                path: disconf.properties
          name: disconf-conf
        - configMap:
            name: nsf-server-config
            items:
              - key: nsf.properties
                path: nsf.properties
          name: nsf-conf
        - configMap:
            name: nsf-server-config
            items:
              - key: k8s.yaml
                path: k8s.yaml
          name: k8s-conf
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-admin-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-config-admin
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: nsf-config-admin.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-config-admin
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-portal-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-config-portal
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: nsf-config-portal.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-config-portal
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-server/charts/nsf-config/templates/nsf-config-service-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-config-service
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: nsf-config-service.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-config-service
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-turbine
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.org/websocket-services: "nsf-turbine"
spec:
  rules:
    - host: nsf-turbine.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-turbine
                port:
                  number: 80
            pathType: ImplementationSpecific
          - backend:
              service:
                name: nsf-turbine
                port:
                  number: 7777
            pathType: ImplementationSpecific
            path: /ws
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-turbine-0
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.org/websocket-services: "nsf-turbine-0"
spec:
  rules:
    - host: nsf-turbine-0.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-turbine-0
                port:
                  number: 80
            pathType: ImplementationSpecific
          - backend:
              service:
                name: nsf-turbine-0
                port:
                  number: 7777
            pathType: ImplementationSpecific
            path: /ws
---
# Source: nsf-server/charts/nsf-turbine/templates/nsf-turbine-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-turbine-1
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.org/websocket-services: "nsf-turbine-1"
spec:
  rules:
    - host: nsf-turbine-1.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-turbine-1
                port:
                  number: 80
            pathType: ImplementationSpecific
          - backend:
              service:
                name: nsf-turbine-1
                port:
                  number: 7777
            pathType: ImplementationSpecific
            path: /ws
---
# Source: nsf-server/charts/powerful/templates/powerful-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: powerful
  namespace: powerful
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: 'powerful.test251-qingzhou.com'
      http:
        paths:
          - backend:
              service:
                name: powerful-cases
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-server/templates/base/nsf-server-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nsf-server
  namespace: skiff-nsf
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: nsf-server.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-server
                port:
                  number: 80
            pathType: ImplementationSpecific
---
# Source: nsf-server/charts/nsf-agent-injecter/templates/webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: agent-injecter
  namespace: skiff-nsf
webhooks:
  - admissionReviewVersions:
      - v1beta1
      - v1
    clientConfig:
      service:
        name: agent-injecter-svc
        namespace: skiff-nsf
        path: /inject
        port: 443
    failurePolicy: Ignore
    matchPolicy: Exact
    name: agent-injecter.netease.com
    objectSelector:
      matchExpressions:
        - key: agent-inject
          operator: In
          values:
            - enable
    reinvocationPolicy: Never
    rules:
      - apiGroups:
          - apps
          - ""
        apiVersions:
          - v1
        operations:
          - CREATE
          - UPDATE
        resources:
          - pods
        scope: '*'
    sideEffects: None
    timeoutSeconds: 30
---
# Source: nsf-server/templates/base/prom-monitors.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: envoy-stats
  namespace: skiff-nsf
  labels:
    skiff-owner: skiff-monitor
spec:
  jobLabel: deploy.istio.io/component
  namespaceSelector:
    any: true
  podMetricsEndpoints:
    - path: /stats/prometheus
      relabelings:
        - action: keep
          regex: .*-envoy-prom
          sourceLabels:
            - __meta_kubernetes_pod_container_port_name
        - sourceLabels:
            - __meta_kubernetes_pod_label_nsf_skiff_netease_com_namespace
          targetLabel: source_workload_namespace
        - sourceLabels:
            - __meta_kubernetes_pod_label_nsf_skiff_netease_com_app
          targetLabel: source_app
        - sourceLabels:
            - __meta_kubernetes_pod_label_nsf_skiff_netease_com_project
          targetLabel: source_project
        - sourceLabels:
            - __meta_kubernetes_pod_label_nsf_skiff_netease_com_version
          targetLabel: source_version
        - sourceLabels:
            - __meta_kubernetes_pod_label_nsf_skiff_netease_com_workload
          targetLabel: source_workload
        - sourceLabels:
            - __meta_kubernetes_pod_label_system_msha_region
          targetLabel: source_region
        - sourceLabels:
            - __meta_kubernetes_pod_label_system_msha_zone
          targetLabel: source_zone
        - sourceLabels:
            - __meta_kubernetes_pod_label_system_msha_cluster
          targetLabel: source_cluster
        - replacement: source
          targetLabel: reporter
        - replacement: unknown.unknown.svc.cluster.local
          targetLabel: destination_service
        - replacement: unknown
          targetLabel: destination_service_name
        - replacement: prod
          targetLabel: env_id
  selector:
    matchLabels:
      feature.istio.io/detailed-stats: enabled
---
# Source: nsf-server/templates/base/prom-monitors.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: istiod
  namespace: skiff-nsf
  labels:
    skiff-owner: skiff-monitor
spec:
  namespaceSelector:
    matchNames:
      - istio-system
  podMetricsEndpoints:
    - honorTimestamps: true
      path: /metrics
      port: http-monitoring
      relabelings:
        - replacement: prod
          targetLabel: env_id
  selector:
    matchLabels:
      istio: istiod
---
# Source: nsf-server/charts/powerful/templates/cr.yaml
apiVersion: zhranklin.io/v1alpha1
kind: Powerful
metadata:
  name: powerful
spec:
  apps:
    - Name: a-sidecar
      mode: sidecar
      protocol: http
    - Name: b-sidecar
      deploys:
        - version: v1
        - version: v2
        - version: v3
      mode: sidecar
      protocol: http
    - Name: c-sidecar
      mode: sidecar
      protocol: http
    - Name: a-dubbo-sidecar
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=b-dubbo-sidecar,c-dubbo-sidecar,a-dubbo-agent,b-dubbo-agent,c-dubbo-agent
      mode: sidecar
      protocol: dubbo
    - Name: b-dubbo-sidecar
      deploys:
        - version: v1
        - version: v2
        - version: v3
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=a-dubbo-sidecar,c-dubbo-sidecar,a-dubbo-agent,b-dubbo-agent,c-dubbo-agent
      mode: sidecar
      protocol: dubbo
    - Name: c-dubbo-sidecar
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=a-dubbo-sidecar,b-dubbo-sidecar,a-dubbo-agent,b-dubbo-agent,c-dubbo-agent
      mode: sidecar
      protocol: dubbo
    - Name: a-agent
      mode: agent
      protocol: http
    - Name: b-agent
      deploys:
        - version: v1
        - version: v2
        - javaOpts:
            colorJavaOpts: -Dnsf.application.mark=powerful-color
          version: v3
      mode: agent
      protocol: http
    - Name: c-agent
      mode: agent
      protocol: http
    - Name: a-dubbo-agent
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=b-dubbo-agent,c-dubbo-agent,a-dubbo-sidecar,b-dubbo-sidecar,c-dubbo-sidecar
      mode: agent
      protocol: dubbo
    - Name: b-dubbo-agent
      deploys:
        - javaOpts:
            versionJavaOpts: -Dnsf.application.version=v1
          version: v1
        - javaOpts:
            versionJavaOpts: -Dnsf.application.version=v2
          version: v2
        - javaOpts:
            colorJavaOpts: -Dnsf.application.mark=powerful-color -Dnsf.application.version=v3
          version: v3
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=a-dubbo-agent,c-dubbo-agent,a-dubbo-sidecar,b-dubbo-sidecar,c-dubbo-sidecar
      mode: agent
      protocol: dubbo
    - Name: c-dubbo-agent
      javaOpts:
        dubboDependsOn: -DdubboDependsOn=a-dubbo-agent,b-dubbo-agent,a-dubbo-sidecar,b-dubbo-sidecar,c-dubbo-sidecar
      mode: agent
      protocol: dubbo
  defaults:
    debug: true
    deployName: '{{- .name }}{{ if .mark }}-{{ .mark }}{{ end }}{{ if .version }}-{{ .version }}{{ end }}'
    env:
      APP: '{{ .name }}'
      DEPLOY: '{{ .name }}'
      JDK: "8"
      MARK: '{{ .mark }}'
      VERSION: '{{ if .version }}{{ .version }}{{ else }}<pfl_empty>{{ end }}'
    hub: harbor.cloud.netease.com/qztest/istio
    imagePullSecrets:
      harbor-qingzhou: eyJhdXRocyI6IHsiaGFyYm9yLmNsb3VkLm5ldGVhc2UuY29tIjogeyJ1c2VybmFtZSI6ICJza2lmZiIsInBhc3N3b3JkIjogIkpERWF3MjNAamZkVyM3IiwgImF1dGgiOiAiYzJ0cFptWTZTa1JGWVhjeU0wQnFabVJYSXpjPSJ9fX0=
    javaOpts:
      agent: '{{ if eq .mode "agent" }} -javaagent:/root/.nsf/agent/nsf-boot.jar -Dnsf.type={{ .protocol }} -Dnsf.nsfServer=http://nsf-server.skiff-nsf.svc.cluster.local -Dnsf.application.name={{ .name }} -Dnsf.application.projectCode={{ .nsfProject }} -Dnsf.application.envCode=prod -Dnsf.config.debug=true -Dnsf.log.level=DEBUG -Dnsf.manager.patterns[0].className=zhranklin.powerful.core.* {{ end }}'
      debug: '{{ if .debug }}-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005{{ end }}'
      dubbo: '{{ if eq .protocol "dubbo" }} -Dpowerful.dubbo.enabled=true -Dpowerful.dubbo.enabled=true -Dpowerful.dubbo.port=20880 -Dpowerful.dubbo.zk={{ .zk }} {{ end }}'
      dubboDependsOn: |-
        {{- if eq .protocol "dubbo" -}}
          {{- $thisMode := .mode -}}
          -DdubboDependsOn=
          {{- range $_, $app := .Values.apps -}}
            {{- $protocol := $app.protocol | default $.Values.defaults.protocol -}}
            {{- if and (eq $thisMode $app.mode) (eq $protocol "dubbo") -}}
              {{- $app.Name | default $app.name -}},
            {{- end -}}
          {{- end -}}
        {{- end -}}
    labels:
      agent-inject: '{{ if eq .mode "agent" }}enable{{ end }}'
      istio.io/rev: '{{ if eq .mode "sidecar" }}{{ .revision }}{{ end }}'
      nsf.skiff.netease.com/app: '{{ .name }}'
      nsf.skiff.netease.com/mark: '{{ if eq .version "v3"}}{{ if or (eq .name "b-sidecar") (eq .name "b-dubbo-sidecar") }}powerful-color{{ end }}{{ end }}'
      nsf.skiff.netease.com/project: '{{ .nsfProject }}'
      nsf.skiff.netease.com/version: '{{ if .version }}{{ .version }}{{ end }}'
    mode: none
    nsfProject: project1
    protocol: http
    revision: qz112
    serviceLabels:
      nsf.skiff.netease.com/app: '{{ if eq .mode "sidecar" }}{{ .name }}{{ end }}'
      nsf.skiff.netease.com/project: '{{ if eq .mode "sidecar" }}{{ .nsfProject }}{{ end }}'
      nsf.skiff.netease.com/protocol-dubbo: '{{ if and (eq .protocol "dubbo") (eq .mode "sidecar") }}true{{ end }}'
    zk: zookeeper://zookeeper.apigw-demo.svc.cluster.local:2181
---
# Source: nsf-server/templates/base/prom-rules-istio.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prometheus-rules-istio
  namespace: skiff-nsf
  labels:
    skiff-owner: skiff-monitor
spec:
  groups:
    - interval: 30s
      name: servicemesh.rules
      rules:
        # buckets of milliseconds: {0.5, 1, 5, 10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000, 30000, 60000, 300000, 600000, 1800000, 3600000, +Inf}
        # 2500
        # 250
        # 25
        # 1000, 5000, 10000, 30000, 60000, 300000, 600000, 1800000, 3600000
        # 100, 500
        # 10, 50
        # 1, 5
        # 0.5
        # +Inf
        - expr: |
            label_replace(
              sum without(le)(
                label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(
                  label_replace(istio_request_duration_milliseconds_bucket,
                    "le_old", "$1", "le", "^(.*)$"
                  ), "le_new", "2.5", "le", "^2500$"
                  ), "le_new", "0.25", "le", "^250$"
                  ), "le_new", "0.025", "le", "^25$"
                  ), "le_new", "$1", "le", "^([0-9]+)000$"
                  ), "le_new", "0.$1", "le", "^([1-9])00$"
                  ), "le_new", "0.0$1", "le", "^([1-9])0$"
                  ), "le_new", "0.00$1", "le", "^([1-9])$"
                  ), "le_new", "0.0005", "le", "^0\\.5$"
                  ), "le_new", "+Inf", "le", "^\\+Inf$"
                )
              ), "le", "$1", "le_new", "^(.*)$"
            )
          record: istio_request_duration_seconds_bucket
        - expr: |
            istio_request_duration_milliseconds_count
          record: istio_request_duration_seconds_count
        - expr: |
            istio_request_duration_milliseconds_sum / 1000
          record: istio_request_duration_seconds_sum
        - expr: |
            label_join(sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (irate(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_request_rate
        - expr: |
            label_join(sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (irate(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_request_rate
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total{response_code=~"4\\d{2}$"}[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_4xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total{response_code=~"4\\d{2}$"}[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_4xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total{response_code=~"5\\d{2}$"}[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_5xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total{response_code=~"5\\d{2}$"}[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_5xx_percentage
        - expr: label_join(100 * ( sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total{response_code=~"[45]\\d{2}$"}[5m])) or sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total{exception="true"}[5m])) ) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_request_error_percentage
        - expr: label_join(100 * ( sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total{response_code=~"[45]\\d{2}$"}[5m])) or sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total{exception="true"}[5m])) ) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_request_error_percentage
        - expr: |
            label_join(sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_request_duration_seconds_sum[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (increase(istio_request_duration_seconds_count[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_avgRT_seconds
        - expr: |
            label_join(sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_request_duration_seconds_sum[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (increase(istio_request_duration_seconds_count[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_avgRT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_50RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_50RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_90RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_90RT_seconds
        - expr: |
            label_join(histogram_quantile(0.95, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_95RT_seconds
        - expr: |
            label_join(histogram_quantile(0.95, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_95RT_seconds
        - expr: |
            label_join(histogram_quantile(0.99, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_response_99RT_seconds
        - expr: |
            label_join(histogram_quantile(0.99, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_response_99RT_seconds
        - expr: |
            label_join(sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace) (irate(istio_request_bytes_sum[5m])), "target", "|" , "destination_workload_namespace" , "destination_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:inbound_request_bytes_rate
        - expr: |
            label_join(sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace) (irate(istio_request_bytes_sum[5m])), "target", "|" , "source_workload_namespace" , "source_app")
          labels:
            modules: servicemesh
          record: servicemesh_service:outbound_request_bytes_rate
        - expr: |
            label_join(sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (irate(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_request_rate
        - expr: |
            label_join(sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (irate(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_request_rate
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total{response_code=~"4\\d{2}$"}[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_4xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total{response_code=~"4\\d{2}$"}[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_4xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total{response_code=~"5\\d{2}$"}[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_5xx_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total{response_code=~"5\\d{2}$"}[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_5xx_percentage
        - expr: label_join(100 * ( sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total{response_code=~"[45]\\d{2}$"}[5m])) or sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total{exception="true"}[5m])) ) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_requests_total[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_request_error_percentage
        - expr: label_join(100 * ( sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total{response_code=~"[45]\\d{2}$"}[5m])) or sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total{exception="true"}[5m])) ) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_requests_total[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_request_error_percentage
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_request_duration_seconds_sum[5m])) / sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (increase(istio_request_duration_seconds_count[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_avgRT_seconds
        - expr: |
            label_join(100 * sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_request_duration_seconds_sum[5m])) / sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (increase(istio_request_duration_seconds_count[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_avgRT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_50RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_50RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_90RT_seconds
        - expr: |
            label_join(histogram_quantile(0.9, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_90RT_seconds
        - expr: |
            label_join(histogram_quantile(0.95, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_95RT_seconds
        - expr: |
            label_join(histogram_quantile(0.95, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_95RT_seconds
        - expr: |
            label_join(histogram_quantile(0.99, sum by (env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_response_99RT_seconds
        - expr: |
            label_join(histogram_quantile(0.99, sum by (env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version,le)  (increase(istio_request_duration_seconds_bucket[5m]))), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_response_99RT_seconds
        - expr: |
            label_join(sum by(env_id, request_protocol, destination_project, destination_app, destination_workload_namespace, destination_version) (irate(istio_request_bytes_sum[5m])), "target", "|" , "destination_workload_namespace" , "destination_app", "destination_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:inbound_request_bytes_rate
        - expr: |
            label_join(sum by(env_id, request_protocol, source_project, source_app, source_workload_namespace, source_version) (irate(istio_request_bytes_sum[5m])), "target", "|" , "source_workload_namespace" , "source_app", "source_version")
          labels:
            modules: servicemesh
          record: servicemesh_service_version:outbound_request_bytes_rate
---
# Source: nsf-server/templates/base/prom-rules-nsf.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: prometheus-rules-nsf
  namespace: skiff-nsf
  labels:
    skiff-owner: skiff-monitor
spec:
  groups:
    - name: nsf.overview.group.rules
      rules:
        - expr: sum(request:ti:count) by (project, env_id, group, code)
          labels:
            job: nsf
            module: nsf
          record: request:group:count
        - expr: sum(request:ti:duration) by (project, env_id, group, code)
          labels:
            job: nsf
            module: nsf
          record: request:group:duration
        - expr: sum(request:instance:duration_bucket) by (project, env_id, group, le)
          labels:
            job: nsf
            module: nsf
          record: request:group:duration_bucket
        - expr: sum(method:method:count) by (project, env_id, group, type)
          labels:
            job: nsf
            module: nsf
          record: method:group:count
        - expr: sum(method:method:duration) by (project, env_id, group, type)
          labels:
            job: nsf
            module: nsf
          record: method:group:duration
        - expr: sum(method:instance:duration_bucket) by (project, env_id, group, le)
          labels:
            job: nsf
            module: nsf
          record: method:group:duration_bucket
    - interval: 5m
      name: nsf.overview.group_hourly.rules
      rules:
        - expr: sum(increase(request:ti:count[1h])) by (project, env_id, group, code)
          labels:
            job: nsf
            module: nsf
          record: request:group:count:1h
        - expr: sum(increase(request:ti:duration[1h])) by (project, env_id, group, code)
          labels:
            job: nsf
            module: nsf
          record: request:group:duration:1h
        - expr: sum(rate(request:instance:duration_bucket[1h])) by (project, env_id, group, le)
          labels:
            job: nsf
            module: nsf
          record: request:group:duration_bucket:1h
        - expr: sum(increase(method:method:count[1h])) by (project, env_id, group, type)
          labels:
            job: nsf
            module: nsf
          record: method:group:count:1h
        - expr: sum(increase(method:method:duration[1h])) by (project, env_id, group, type)
          labels:
            job: nsf
            module: nsf
          record: method:group:duration:1h
        - expr: sum(rate(method:instance:duration_bucket[1h])) by (project, env_id, group, le)
          labels:
            job: nsf
            module: nsf
          record: method:group:duration_bucket:1h
    - name: nsf.overview.service.rules
      rules:
        - expr: sum(method:method:count) by (project, env_id, group, service, type)
          labels:
            job: nsf
            module: nsf
          record: method:service:count
        - expr: sum(method:method:duration) by (project, env_id, group, service, type)
          labels:
            job: nsf
            module: nsf
          record: method:service:duration
        - expr: sum(method:instance:duration_bucket) by (project, env_id, group, service, le)
          labels:
            job: nsf
            module: nsf
          record: method:service:duration_bucket
    - name: nsf.monitor.service.rules
      rules:
        - expr: sum(rate(method:method:count[150s])) by (project, env_id, group, service, type)
          labels:
            job: nsf
            module: nsf
          record: method:service:count_rate
        - expr: sum(rate(method:method:duration[150s])) by (project, env_id, group, service, type)
          labels:
            job: nsf
            module: nsf
          record: method:service:duration_rate
    - name: nsf.monitor.instance.rules
      rules:
        - expr: sum(rate(method:method:count[150s])) by (project, env_id, group, service, version, agent, type)
          labels:
            job: nsf
            module: nsf
          record: method:instance:count_rate
        - expr: sum(rate(method:method:duration[150s])) by (project, env_id, group, service, version, agent, type)
          labels:
            job: nsf
            module: nsf
          record: method:instance:duration_rate
    - interval: 30s
      name: general.rules
      rules:
        - expr: sum by(project) (instance:env:count)
          record: instance:count
        - expr: sum by(project) (service:env:count)
          record: service:count
        - expr: sum by(project) (method:group:count_success:today) / sum by(project) (method:group:count:today) * 100
          record: method:success:percentage
        - expr: sum by(project) (method:group:count_normal_exception:today) / sum by(project) (method:group:count:today) * 100
          record: method:normal_exception:percentage
        - expr: sum by(project) (method:group:count_timeout:today) / sum by(project) (method:group:count:today) * 100
          record: method:timeout:percentage
        - expr: sum by(project) (method:group:count_thread_rejected:today) / sum by(project) (method:group:count:today) * 100
          record: method:rejected:percentage
        - expr: sum by(project) (method:group:count_rate_limited:today) / sum by(project) (method:group:count:today) * 100
          record: method:rate_limited:percentage
        - expr: sum by(project) (method:group:count_short_circuited:today) / sum by(project) (method:group:count:today) * 100
          record: method:short_circuited:percentage
---
# Source: nsf-server/templates/base/image-pull-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: harbor-qingzhou
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "1"
data:
  .dockerconfigjson: eyJhdXRocyI6IHsiaGFyYm9yLmNsb3VkLm5ldGVhc2UuY29tIjogeyJ1c2VybmFtZSI6ICJza2lmZiIsInBhc3N3b3JkIjogIkpERWF3MjNAamZkVyM3IiwgImF1dGgiOiAiYzJ0cFptWTZTa1JGWVhjeU0wQnFabVJYSXpjPSJ9fX0=
type: kubernetes.io/dockerconfigjson
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-portal-createdb
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-config-portal-createdb.sql: |-
    CREATE DATABASE  IF NOT EXISTS nsf_portal DEFAULT CHARACTER SET utf8;
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-portal
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-config-portal.sql: |-
    use nsf_portal;
    SET NAMES utf8;
    # Dump of table app
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `App` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',
      `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',
      `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',
      `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',
      `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId` (`AppId`(191)),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_Name` (`Name`(191))
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用表';



    # Dump of table appnamespace
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `AppNamespace` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `Name` varchar(128) NOT NULL DEFAULT '' COMMENT 'namespace名字，注意，需要全局唯一',
      `AppId` varchar(500) NOT NULL DEFAULT '' COMMENT 'app id',
      `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespace的format类型',
      `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace是否为公共',
      `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '注释',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_AppId` (`AppId`),
      KEY `Name_AppId` (`Name`,`AppId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用namespace定义';



    # Dump of table consumer
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Consumer` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',
      `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',
      `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',
      `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',
      `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId` (`AppId`(191)),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='开放API消费者';



    # Dump of table consumeraudit
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ConsumerAudit` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',
      `Uri` varchar(1024) NOT NULL DEFAULT '' COMMENT '访问的Uri',
      `Method` varchar(16) NOT NULL DEFAULT '' COMMENT '访问的Method',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_ConsumerId` (`ConsumerId`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer审计表';



    # Dump of table consumerrole
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ConsumerRole` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'Consumer Id',
      `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_RoleId` (`RoleId`),
      KEY `IX_ConsumerId_RoleId` (`ConsumerId`,`RoleId`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer和role的绑定表';



    # Dump of table consumertoken
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ConsumerToken` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `ConsumerId` int(11) unsigned DEFAULT NULL COMMENT 'ConsumerId',
      `Token` varchar(128) NOT NULL DEFAULT '' COMMENT 'token',
      `Expires` datetime NOT NULL DEFAULT '2099-01-01 00:00:00' COMMENT 'token失效时间',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      UNIQUE KEY `IX_Token` (`Token`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='consumer token表';

    # Dump of table favorite
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Favorite` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `UserId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '收藏的用户',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `Position` int(32) NOT NULL DEFAULT '10000' COMMENT '收藏顺序',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId` (`AppId`(191)),
      KEY `IX_UserId` (`UserId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB AUTO_INCREMENT=23 DEFAULT CHARSET=utf8mb4 COMMENT='应用收藏表';

    # Dump of table permission
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Permission` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `PermissionType` varchar(32) NOT NULL DEFAULT '' COMMENT '权限类型',
      `TargetId` varchar(256) NOT NULL DEFAULT '' COMMENT '权限对象类型',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_TargetId_PermissionType` (`TargetId`(191),`PermissionType`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='permission表';



    # Dump of table role
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Role` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `RoleName` varchar(256) NOT NULL DEFAULT '' COMMENT 'Role name',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_RoleName` (`RoleName`(191)),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='角色表';



    # Dump of table rolepermission
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `RolePermission` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',
      `PermissionId` int(10) unsigned DEFAULT NULL COMMENT 'Permission Id',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_RoleId` (`RoleId`),
      KEY `IX_PermissionId` (`PermissionId`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='角色和权限的绑定表';



    # Dump of table serverconfig
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ServerConfig` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT '配置项Key',
      `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '配置项值',
      `Comment` varchar(1024) DEFAULT '' COMMENT '注释',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_Key` (`Key`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置服务自身配置';



    # Dump of table userrole
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `UserRole` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `UserId` varchar(128) DEFAULT '' COMMENT '用户身份标识',
      `RoleId` int(10) unsigned DEFAULT NULL COMMENT 'Role Id',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_RoleId` (`RoleId`),
      KEY `IX_UserId_RoleId` (`UserId`,`RoleId`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户和role的绑定表';

    # Dump of table Users
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Users` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `Username` varchar(64) NOT NULL DEFAULT 'default' COMMENT '用户名',
      `Password` varchar(64) NOT NULL DEFAULT 'default' COMMENT '密码',
      `Email` varchar(64) NOT NULL DEFAULT 'default' COMMENT '邮箱地址',
      `Enabled` tinyint(4) DEFAULT NULL COMMENT '是否有效',
      PRIMARY KEY (`Id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户表';


    # Dump of table Authorities
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Authorities` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `Username` varchar(50) NOT NULL,
      `Authority` varchar(50) NOT NULL,
      PRIMARY KEY (`Id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;


    # Config
    # ------------------------------------------------------------
    INSERT INTO `ServerConfig` (`Key`, `Value`, `Comment`)
    VALUES
        ('apollo.portal.envs', 'dev', '可支持的环境列表'),
        ('organizations', '[{\"orgId\":\"QZ\",\"orgName\":\"轻舟\"}]', '部门列表'),
        ('superAdmin', 'apollo', 'Portal超级管理员'),
        ('api.readTimeout', '10000', 'http接口read timeout'),
        ('consumer.token.salt', 'someSalt', 'consumer token salt'),
        ('admin.createPrivateNamespace.switch', 'false', '是否允许项目管理员创建私有namespace');

    INSERT INTO `Users` (`Username`, `Password`, `Email`, `Enabled`)
    VALUES
      ('apollo', '$2a$10$7r20uS.BQ9uBpf3Baj3uQOZvMVvB1RN3PYoKE94gtz2.WAOuiiwXS', 'apollo@acme.com', 1);

    INSERT INTO `Authorities` (`Username`, `Authority`) VALUES ('apollo', 'ROLE_user');
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-service-createdb
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-config-service-createdb.sql: |-
    CREATE DATABASE  IF NOT EXISTS nsf_config DEFAULT CHARACTER SET utf8;
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-config-service
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-config-service.sql: |-
    use nsf_config;
    SET NAMES utf8;

    CREATE TABLE IF NOT EXISTS `App` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `Name` varchar(500) NOT NULL DEFAULT 'default' COMMENT '应用名',
      `OrgId` varchar(32) NOT NULL DEFAULT 'default' COMMENT '部门Id',
      `OrgName` varchar(64) NOT NULL DEFAULT 'default' COMMENT '部门名字',
      `OwnerName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerName',
      `OwnerEmail` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ownerEmail',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId` (`AppId`(191)),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_Name` (`Name`(191))
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用表';



    # Dump of table appnamespace
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `AppNamespace` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `Name` varchar(128) NOT NULL DEFAULT '' COMMENT 'namespace名字，注意，需要全局唯一',
      `AppId` varchar(500) NOT NULL DEFAULT '' COMMENT 'app id',
      `Format` varchar(32) NOT NULL DEFAULT 'properties' COMMENT 'namespace的format类型',
      `IsPublic` bit(1) NOT NULL DEFAULT b'0' COMMENT 'namespace是否为公共',
      `Comment` varchar(64) NOT NULL DEFAULT '' COMMENT '注释',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_AppId` (`AppId`),
      KEY `Name_AppId` (`Name`,`AppId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用namespace定义';



    # Dump of table audit
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Audit` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `EntityName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '表名',
      `EntityId` int(10) unsigned DEFAULT NULL COMMENT '记录ID',
      `OpName` varchar(50) NOT NULL DEFAULT 'default' COMMENT '操作类型',
      `Comment` varchar(500) DEFAULT NULL COMMENT '备注',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='日志审计表';



    # Dump of table cluster
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Cluster` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `Name` varchar(32) NOT NULL DEFAULT '' COMMENT '集群名字',
      `AppId` varchar(500) NOT NULL DEFAULT '' COMMENT 'App id',
      `ParentClusterId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '父cluster',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT '' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_AppId_Name` (`AppId`,`Name`),
      KEY `IX_ParentClusterId` (`ParentClusterId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='集群';



    # Dump of table commit
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Commit` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `ChangeSets` longtext NOT NULL COMMENT '修改变更集',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',
      `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',
      `Comment` varchar(500) DEFAULT NULL COMMENT '备注',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `AppId` (`AppId`(191)),
      KEY `ClusterName` (`ClusterName`(191)),
      KEY `NamespaceName` (`NamespaceName`(191))
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='commit 历史表';

    # Dump of table grayreleaserule
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `GrayReleaseRule` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',
      `NamespaceName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',
      `BranchName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'branch name',
      `Rules` varchar(2000) DEFAULT '[]' COMMENT '灰度规则',
      `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '灰度对应的release',
      `BranchStatus` tinyint(2) DEFAULT '1' COMMENT '灰度分支状态: 0:删除分支,1:正在使用的规则 2：全量发布',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='灰度规则表';


    # Dump of table instance
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Instance` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',
      `DataCenter` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'Data Center Name',
      `Ip` varchar(32) NOT NULL DEFAULT '' COMMENT 'instance ip',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      UNIQUE KEY `IX_UNIQUE_KEY` (`AppId`,`ClusterName`,`Ip`,`DataCenter`),
      KEY `IX_IP` (`Ip`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='使用配置的应用实例';



    # Dump of table instanceconfig
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `InstanceConfig` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `InstanceId` int(11) unsigned DEFAULT NULL COMMENT 'Instance Id',
      `ConfigAppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Config App Id',
      `ConfigClusterName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'Config Cluster Name',
      `ConfigNamespaceName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'Config Namespace Name',
      `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT '发布的Key',
      `ReleaseDeliveryTime` timestamp NULL DEFAULT NULL COMMENT '配置获取时间',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      UNIQUE KEY `IX_UNIQUE_KEY` (`InstanceId`,`ConfigAppId`,`ConfigNamespaceName`),
      KEY `IX_ReleaseKey` (`ReleaseKey`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_Valid_Namespace` (`ConfigAppId`,`ConfigClusterName`,`ConfigNamespaceName`,`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='应用实例的配置信息';



    # Dump of table item
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Item` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '集群NamespaceId',
      `Key` varchar(128) NOT NULL DEFAULT 'default' COMMENT '配置项Key',
      `Value` longtext NOT NULL COMMENT '配置项值',
      `Comment` varchar(1024) DEFAULT '' COMMENT '注释',
      `LineNum` int(10) unsigned DEFAULT '0' COMMENT '行号',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_GroupId` (`NamespaceId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置项目';



    # Dump of table namespace
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Namespace` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Cluster Name',
      `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'Namespace Name',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId_ClusterName_NamespaceName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_NamespaceName` (`NamespaceName`(191))
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='命名空间';



    # Dump of table namespacelock
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `NamespaceLock` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增id',
      `NamespaceId` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '集群NamespaceId',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT 'default' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      `IsDeleted` bit(1) DEFAULT b'0' COMMENT '软删除',
      PRIMARY KEY (`Id`),
      UNIQUE KEY `IX_NamespaceId` (`NamespaceId`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='namespace的编辑锁';



    # Dump of table release
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `Release` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `ReleaseKey` varchar(64) NOT NULL DEFAULT '' COMMENT '发布的Key',
      `Name` varchar(64) NOT NULL DEFAULT 'default' COMMENT '发布名字',
      `Comment` varchar(256) DEFAULT NULL COMMENT '发布说明',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',
      `NamespaceName` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',
      `Configurations` longtext NOT NULL COMMENT '发布配置',
      `IsAbandoned` bit(1) NOT NULL DEFAULT b'0' COMMENT '是否废弃',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `AppId_ClusterName_GroupName` (`AppId`(191),`ClusterName`(191),`NamespaceName`(191)),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_ReleaseKey` (`ReleaseKey`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布';


    # Dump of table releasehistory
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ReleaseHistory` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `AppId` varchar(500) NOT NULL DEFAULT 'default' COMMENT 'AppID',
      `ClusterName` varchar(64) NOT NULL DEFAULT 'default' COMMENT 'ClusterName',
      `NamespaceName` varchar(128) NOT NULL DEFAULT 'default' COMMENT 'namespaceName',
      `BranchName` varchar(32) NOT NULL DEFAULT 'default' COMMENT '发布分支名',
      `ReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '关联的Release Id',
      `PreviousReleaseId` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '前一次发布的ReleaseId',
      `Operation` tinyint(3) unsigned NOT NULL DEFAULT '0' COMMENT '发布类型，0: 普通发布，1: 回滚，2: 灰度发布，3: 灰度规则更新，4: 灰度合并回主分支发布，5: 主分支发布灰度自动发布，6: 主分支回滚灰度自动发布，7: 放弃灰度',
      `OperationContext` longtext NOT NULL COMMENT '发布上下文信息',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_Namespace` (`AppId`,`ClusterName`,`NamespaceName`,`BranchName`),
      KEY `IX_ReleaseId` (`ReleaseId`),
      KEY `IX_DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布历史';


    # Dump of table releasemessage
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ReleaseMessage` (
      `Id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增主键',
      `Message` varchar(1024) NOT NULL DEFAULT '' COMMENT '发布的消息内容',
      `DataChange_LastTime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`),
      KEY `IX_Message` (`Message`(191))
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='发布消息';



    # Dump of table serverconfig
    # ------------------------------------------------------------

    CREATE TABLE IF NOT EXISTS `ServerConfig` (
      `Id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '自增Id',
      `Key` varchar(64) NOT NULL DEFAULT 'default' COMMENT '配置项Key',
      `Cluster` varchar(32) NOT NULL DEFAULT 'default' COMMENT '配置对应的集群，default为不针对特定的集群',
      `Value` varchar(2048) NOT NULL DEFAULT 'default' COMMENT '配置项值',
      `Comment` varchar(1024) DEFAULT '' COMMENT '注释',
      `IsDeleted` bit(1) NOT NULL DEFAULT b'0' COMMENT '1: deleted, 0: normal',
      `DataChange_CreatedBy` varchar(32) NOT NULL DEFAULT 'default' COMMENT '创建人邮箱前缀',
      `DataChange_CreatedTime` timestamp NOT NULL DEFAULT '2000-01-01 00:00:00' COMMENT '创建时间',
      `DataChange_LastModifiedBy` varchar(32) DEFAULT '' COMMENT '最后修改人邮箱前缀',
      `DataChange_LastTime` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '最后修改时间',
      PRIMARY KEY (`Id`),
      KEY `IX_Key` (`Key`),
      KEY `DataChange_LastTime` (`DataChange_LastTime`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='配置服务自身配置';

    # Config
    # ------------------------------------------------------------
    INSERT INTO `ServerConfig` (`Key`, `Cluster`, `Value`, `Comment`)
    VALUES

        ('eureka.service.url', 'default', 'http://nsf-registry-0.test251-qingzhou.com/eureka/,http://nsf-registry-1.test251-qingzhou.com/eureka/', 'Eureka服务Url，多个service以英文逗号分隔'),

        ('namespace.lock.switch', 'default', 'false', '一次发布只能有一个人修改开关'),
        ('item.key.length.limit', 'default', '128', 'item key 最大长度限制'),
        ('item.value.length.limit', 'default', '20000', 'item value最大长度限制'),
        ('config-service.cache.enabled', 'default', 'false', 'ConfigService是否开启缓存，开启后能提高性能，但是会增大内存消耗！');
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-server-createdb
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-server-createdb.sql: |-
    CREATE DATABASE  IF NOT EXISTS nsf_server DEFAULT CHARACTER SET utf8;
---
# Source: nsf-server/templates/pre-install-hooks/sql-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nsf-server
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook-weight": "1"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
data:
  nsf-server.sql: "use nsf_server;\nSET NAMES utf8;\n\nSET FOREIGN_KEY_CHECKS = 0;\n\n--\n-- Table structure for table `nsf_api_interface`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_api_interface` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `name` varchar(128) DEFAULT '' COMMENT '接口名',\n  `create_time` bigint(11) DEFAULT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `version` varchar(64) DEFAULT NULL COMMENT '微服务版本',\n  `alive_flag` int(5) DEFAULT '1' COMMENT '存活标识. 1表示存活，0表示不确定，需要判断是否上报过',\n  `package_name` varchar(128) DEFAULT NULL COMMENT '接口所在包名',\n  `type` int(5) NOT NULL DEFAULT '0',\n  PRIMARY KEY (`id`),\n  KEY `serviceid_idx` (`service_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=463 DEFAULT CHARSET=utf8 COMMENT='Api接口表';\n\n--\n-- Table structure for table `nsf_api_method`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_api_method` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `interface_id` bigint(11) NOT NULL COMMENT '所在接口id',\n  `name` varchar(128) DEFAULT NULL COMMENT '方法名',\n  `create_time` bigint(11) DEFAULT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `package_name` varchar(128) DEFAULT NULL,\n  `interface_name` varchar(128) DEFAULT NULL COMMENT '所在接口名',\n  `version` varchar(64) DEFAULT NULL COMMENT '微服务版本',\n  `alive_flag` int(5) DEFAULT '1' COMMENT '存活标识. 1表示存活，0表示不确定，需要判断是否上报过',\n  PRIMARY KEY (`id`),\n  KEY `group_id_idx` (`interface_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=2525 DEFAULT CHARSET=utf8 COMMENT='Api方法表';\n\n--\n-- Table structure for table `nsf_call_info`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_call_info` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `relation_id` bigint(11) NOT NULL,\n  `source_service` varchar(255) NOT NULL,\n  `target_service` varchar(255) NOT NULL,\n  `source_version` varchar(255) NOT NULL,\n  `target_version` varchar(255) NOT NULL,\n  `call_time` bigint(11) NOT NULL,\n  `source_id` bigint(11) NOT NULL,\n  `target_id` bigint(11) NOT NULL,\n  `project_id` bigint(11) NOT NULL,\n  `env_name` varchar(255) NOT NULL,\n  `call_color` varchar(255) DEFAULT NULL,\n  `source_region` varchar(128) DEFAULT NULL,\n  `target_region` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `relation_idx` (`relation_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=5239 DEFAULT CHARSET=utf8mb4 COMMENT='调用信息表';\n\n--\n-- Table structure for table `nsf_call_relation`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_call_relation` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `source_service` varchar(128) DEFAULT NULL COMMENT '调用来源服务名',\n  `target_service` varchar(128) DEFAULT NULL COMMENT '被调用服务名',\n  `source_version` varchar(128) DEFAULT NULL COMMENT '调用来源服务版本',\n  `target_version` varchar(128) DEFAULT NULL COMMENT '被调用服务版本',\n  `call_time` bigint(11) DEFAULT NULL COMMENT '调用时间',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `source_id` bigint(11) DEFAULT NULL COMMENT '来源服务id',\n  `target_id` bigint(11) DEFAULT NULL COMMENT '调用服务id',\n  `service_group_id` bigint(11) DEFAULT NULL COMMENT '服务组id',\n  `project_id` bigint(11) DEFAULT NULL,\n  `env_name` varchar(255) DEFAULT NULL,\n  `source_region` varchar(128) DEFAULT NULL,\n  `target_region` varchar(128) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `idx_src` (`source_service`),\n  KEY `idx_tgt` (`target_service`)\n) ENGINE=InnoDB AUTO_INCREMENT=372 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_circuitbreaker_config`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_circuitbreaker_config` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL COMMENT '服务id',\n  `hystrix_key` varchar(64) NOT NULL COMMENT 'hystrix_key, 可能为command key，group key或class',\n  `type` varchar(64) NOT NULL COMMENT 'key的类型，取值为command|group|class之一',\n  `property_key` varchar(64) NOT NULL COMMENT 'hystrix配置项',\n  `hystrix_value` varchar(64) NOT NULL COMMENT '配置值',\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',\n  `api_model_id` bigint(11) NOT NULL COMMENT 'command或group id.取决于type值.',\n  `policy_id` bigint(11) DEFAULT NULL COMMENT '关联策略id',\n  `version` varchar(128) DEFAULT NULL COMMENT '服务版本号',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='Hystrix key配置表';\n\n--\n-- Table structure for table `nsf_container_info`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_container_info` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `instance_name` varchar(256) NOT NULL,\n  `load_info_key` varchar(255) NOT NULL,\n  `load_info_value` varchar(255) DEFAULT NULL,\n  `project_id` varchar(45) NOT NULL,\n  PRIMARY KEY (`id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=46 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;\n\n--\n-- Table structure for table `nsf_destination_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_destination_rule` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL,\n  `type` varchar(64) NOT NULL COMMENT '类型,base或者subset',\n  `service_id` bigint(11) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `publish_time` timestamp NULL DEFAULT NULL COMMENT '配置发布时间',\n  `content` varchar(20480) DEFAULT NULL COMMENT 'destinationrule具体内容',\n  `source` varchar(128) DEFAULT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  `protocol` int(2) NOT NULL,\n  PRIMARY KEY (`id`),\n  KEY `service_id_idx` (`service_id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=823 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_divide_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_divide_rule` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `service_version` varchar(128) NOT NULL,\n  `shunt_way` varchar(128) NOT NULL,\n  `modulus_threshold` int(11) DEFAULT NULL,\n  `parameter_type` varchar(128) DEFAULT NULL,\n  `parameter_name` varchar(128) DEFAULT NULL,\n  `list` varchar(256) DEFAULT NULL,\n  `is_regex` tinyint(4) DEFAULT NULL,\n  `status` int(11) DEFAULT NULL,\n  `target_service_id` bigint(11) NOT NULL,\n  `target_service_version` varchar(128) DEFAULT NULL,\n  `target_service_name` varchar(128) NOT NULL,\n  `weight` text,\n  `rule_name` varchar(256) DEFAULT NULL COMMENT '规则名称',\n  `target_type` varchar(45) DEFAULT NULL,\n  `target_tag` text,\n  `tag_weight` text,\n  `tags` text,\n  `divide_parameter` text COMMENT '分流参数,用于参数取模和名单分流两种情况',\n  `is_open` int(4) NOT NULL,\n  `interface_id` bigint(11) DEFAULT NULL COMMENT '接口id',\n  `method_id` bigint(11) DEFAULT NULL COMMENT '方法id',\n  `grpc_method_name` text,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=251 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_error_log`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_error_log` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `agentId` varchar(255) NOT NULL,\n  `first_time` bigint(32) NOT NULL,\n  `last_time` bigint(32) NOT NULL,\n  `instance_name` varchar(255) NOT NULL,\n  `error_type` varchar(255) NOT NULL,\n  `error_content` varchar(512) NOT NULL,\n  `env_name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`)\n  \n) ENGINE=InnoDB AUTO_INCREMENT=24161 DEFAULT CHARSET=utf8mb4 COMMENT='异常日志表';\n\n--\n-- Table structure for table `nsf_fail_policy`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_fail_policy` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `type` varchar(64) DEFAULT NULL COMMENT 'RPC或HTTP',\n  `scope_id` bigint(11) DEFAULT NULL COMMENT '降级服务范围.-1为全部',\n  `interface_id` bigint(11) DEFAULT NULL,\n  `method_id` bigint(11) DEFAULT NULL,\n  `range` text,\n  `rule_range` text,\n  `failway` varchar(11) DEFAULT NULL COMMENT 'AUDO为自动熔断，MANU为手动熔断',\n  `min_call_count` int(11) DEFAULT NULL COMMENT '打开熔断最小请求量',\n  `time_window` int(11) DEFAULT NULL COMMENT '打开熔断时间窗口ms',\n  `rt` int(11) DEFAULT NULL COMMENT '超时时间ms',\n  `sleep_time` int(11) DEFAULT NULL COMMENT '熔断恢复窗口',\n  `status` int(11) DEFAULT NULL COMMENT '规则状态，1为启用，0为停用',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `fail_percent` int(11) DEFAULT NULL COMMENT '错误率阈值.',\n  `version` varchar(128) DEFAULT NULL COMMENT '服务版本号',\n  `rule_name` varchar(256) NOT NULL,\n  `fall_back_type` varchar(45) DEFAULT NULL,\n  `fall_back_method` varchar(255) DEFAULT NULL,\n  `trigger_time` bigint(20) DEFAULT NULL COMMENT '最近触发时间',\n  `trigger_message` varchar(2048) DEFAULT NULL COMMENT '最近触发原因',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1084 DEFAULT CHARSET=utf8 COMMENT='降级策略';\n\n--\n-- Table structure for table `nsf_fault_tolerance_policy`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_fault_tolerance_policy` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `type` varchar(64) DEFAULT NULL COMMENT 'RPC or HTTP',\n  `interface_id` bigint(11) DEFAULT NULL,\n  `method_id` bigint(11) DEFAULT NULL,\n  `failway` varchar(64) DEFAULT NULL COMMENT '容错方式：failover,failfast,failback,diy',\n  `failback_retry_count` int(11) DEFAULT NULL COMMENT '同一服务重试次数',\n  `failover_retry_count` int(11) DEFAULT NULL COMMENT '新服务重试次数',\n  `status` int(11) DEFAULT NULL COMMENT '规则状态，1为启用，0为停用',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `version` varchar(128) DEFAULT NULL COMMENT '服务版本号',\n  `scope_id` bigint(11) DEFAULT NULL COMMENT '容错服务id，-1代表全部',\n  `scope_version_id` bigint(11) DEFAULT '-1',\n  `rule_name` varchar(256) NOT NULL,\n  `scope_name` varchar(64) DEFAULT NULL,\n  `grpc_method_name` text,\n  `http_path` varchar(512) DEFAULT NULL,\n  `standby_switch` varchar(512) DEFAULT NULL,\n  `trigger_time` bigint(20) DEFAULT NULL COMMENT '最近触发时间',\n  `trigger_message` varchar(2048) DEFAULT NULL COMMENT '最近触发原因',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1584 DEFAULT CHARSET=utf8 COMMENT='容错策略';\n\n--\n-- Table structure for table `nsf_instance`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_instance` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `agent_id` varchar(256) NOT NULL COMMENT 'agent唯一标识',\n  `name` varchar(1024) DEFAULT NULL COMMENT 'agent名称',\n  `ip` varchar(256) DEFAULT NULL COMMENT 'agent ip',\n  `port` int(11) DEFAULT NULL COMMENT 'agent端口',\n  `status` smallint(6) DEFAULT '0' COMMENT '最近状态. 1为在线，0为离线',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `last_online_time` bigint(11) DEFAULT NULL COMMENT '最近上线时间',\n  `version` varchar(128) DEFAULT '' COMMENT 'agent版本',\n  `service_id` bigint(11) NOT NULL COMMENT '所属服务id',\n  `create_time` bigint(20) DEFAULT NULL,\n  `registry_id` text COMMENT '服务实例注册到注册中心的id',\n  `git_branch` varchar(255) DEFAULT NULL,\n  `git_commit` varchar(255) DEFAULT NULL,\n  `agent_config` text,\n  `env_name` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `agent_unique` (`agent_id`),\n  KEY `agentid_idx` (`agent_id`(255)),\n  KEY `service_id_idx` (`service_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=11596 DEFAULT CHARSET=utf8 COMMENT='服务实例信息表';\n\n--\n-- Table structure for table `nsf_istio_version`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_istio_version` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `version` varchar(255) NOT NULL,\n  `istio_type` varchar(255) NOT NULL,\n  `description` varchar(255) NOT NULL,\n  `env_name` varchar(255) NOT NULL,\n  `active` tinyint(4) NOT NULL,\n  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8mb4 COMMENT='istio版本';\n\n--\n-- Table structure for table `nsf_label_info`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_label_info` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `label_key` varchar(256) NOT NULL COMMENT '标签key值',\n  `label_value` varchar(256) NOT NULL COMMENT '标签value',\n  `env_name` varchar(256) NOT NULL COMMENT '环境',\n  `project_id` int(11) NOT NULL COMMENT '项目id',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=102 DEFAULT CHARSET=utf8mb4 COMMENT='nsf label';\n\n--\n-- Table structure for table `nsf_label_service_relation`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_label_service_relation` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `label_id` int(11) NOT NULL COMMENT '标签id',\n  `service_id` int(11) NOT NULL COMMENT '服务id',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `nsf_label_service_relation_label_id_IDX` (`label_id`,`service_id`,`env_name`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=1531381 DEFAULT CHARSET=utf8mb4 COMMENT='服务标签关联表';\n\n--\n-- Table structure for table `nsf_load_balanced_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_load_balanced_rule` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `policy` varchar(128) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `concurrent_threshold` int(11) DEFAULT NULL,\n  `keep_alived` bigint(11) DEFAULT NULL,\n  `fail_times` int(11) DEFAULT NULL,\n  `service_version` varchar(128) NOT NULL,\n  `status` int(11) DEFAULT NULL,\n  `target_service_id` bigint(11) NOT NULL,\n  `target_service_name` varchar(128) DEFAULT NULL,\n  `target_service_version` varchar(255) DEFAULT NULL,\n  `rule_name` varchar(256) DEFAULT NULL,\n  `interface_id` bigint(11) DEFAULT NULL COMMENT '接口id',\n  `method_id` bigint(11) DEFAULT NULL COMMENT '方法id',\n  `is_open` int(4) NOT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=286 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_monitor_config`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_monitor_config` (\n  `id` int(4) NOT NULL AUTO_INCREMENT,\n  `service_id` int(11) NOT NULL,\n  `config_type` varchar(64) NOT NULL,\n  `name` varchar(64) NOT NULL,\n  `patterns` text,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `env_name` varchar(64) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=41 DEFAULT CHARSET=utf8mb4 COMMENT='监控过滤配置项';\n\n--\n-- Table structure for table `nsf_options`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_options` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `user_id` varchar(45) DEFAULT NULL,\n  `group_id` int(11) DEFAULT '-1',\n  `option_type` varchar(45) DEFAULT NULL,\n  `options` text,\n  `env_name` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=526 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_rate_limit_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_rate_limit_rule` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `type` varchar(128) NOT NULL COMMENT '策略类型，http/rpc',\n  `service_id` bigint(11) NOT NULL COMMENT '服务id',\n  `range` text NOT NULL,\n  `interface_id` bigint(11) DEFAULT NULL COMMENT '接口id，当type为http时，该字段无效，当该字段为0时，表示所有接口',\n  `method_id` bigint(11) DEFAULT NULL COMMENT '方法id，当该方法为0时，表示所有方法',\n  `rate_limit_object_id` bigint(11) NOT NULL COMMENT '被流控的对象id，当对全部对象流控时，该字段为0',\n  `rate_limit_dimension` varchar(128) NOT NULL COMMENT '流控维度，qps/thread',\n  `limit` bigint(11) NOT NULL COMMENT '流控阈值',\n  `slot` bigint(11) NOT NULL COMMENT '流控时间长度',\n  `unit` varchar(128) DEFAULT NULL COMMENT '时间单位',\n  `status` tinyint(1) NOT NULL COMMENT '该规则是否启用',\n  `create_time` bigint(20) NOT NULL,\n  `update_time` bigint(20) NOT NULL,\n  `version` varchar(128) DEFAULT NULL COMMENT '服务版本号',\n  `rule_name` varchar(256) NOT NULL,\n  `fall_back_type` varchar(45) DEFAULT NULL,\n  `queue_size` bigint(11) DEFAULT '0' COMMENT '限流队列长度',\n  `timeout` bigint(11) DEFAULT '0' COMMENT '限流队列超时时间',\n  `fall_back_method` varchar(255) DEFAULT NULL,\n  `trigger_time` bigint(20) DEFAULT NULL COMMENT '最近触发时间',\n  `trigger_message` varchar(2048) DEFAULT NULL COMMENT '最近触发原因',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1794 DEFAULT CHARSET=utf8 COMMENT='流控策略表';\n\n--\n-- Table structure for table `nsf_router_config`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_router_config` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `service_id` int(11) NOT NULL,\n  `target_service_id` int(11) NOT NULL,\n  `service_version` varchar(45) NOT NULL,\n  `desc` varchar(255) DEFAULT NULL,\n  `rule_name` varchar(255) NOT NULL,\n  `list_rule_id` int(11) DEFAULT '-1',\n  `divide_rule_id` int(45) DEFAULT '-1',\n  `loadbalance_rule_id` int(11) DEFAULT '-1',\n  `status` int(4) DEFAULT '0',\n  `target_service_name` varchar(64) NOT NULL,\n  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `env_name` varchar(100) DEFAULT NULL,\n  `type` int(2) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=285 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_router_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_router_rule` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,\n  `service_version` varchar(128) NOT NULL,\n  `status` int(11) DEFAULT NULL,\n  `priority` int(11) DEFAULT NULL,\n  `type` varchar(128) DEFAULT NULL,\n  `match_type` varchar(128) DEFAULT NULL,\n  `match_content` varchar(255) DEFAULT NULL,\n  `filter_type` varchar(128) DEFAULT NULL,\n  `filter_content` text,\n  `rule_name` varchar(256) DEFAULT NULL,\n  `range` text,\n  `match_tags` text,\n  `filter_tags` text,\n  `is_open` int(4) NOT NULL,\n  `target_service_id` int(11) NOT NULL,\n  `target_service_name` varchar(64) NOT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=237 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_service`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(256) CHARACTER SET utf8 NOT NULL,\n  `project_id` int(11) NOT NULL,\n  `owner` varchar(256) CHARACTER SET utf8 DEFAULT NULL,\n  `desc` varchar(256) CHARACTER SET utf8 DEFAULT NULL,\n  `create_time` bigint(20) DEFAULT NULL,\n  `owner_email` varchar(256) CHARACTER SET utf8 DEFAULT NULL,\n  `owner_phone` varchar(256) CHARACTER SET utf8 DEFAULT NULL,\n  `access_type` varchar(45) CHARACTER SET utf8 DEFAULT NULL,\n  `service_type` int(2) NOT NULL,\n  `update_time` bigint(20) DEFAULT NULL,\n  `meta_service_id` int(11) DEFAULT NULL,\n  `env_name` varchar(255) DEFAULT NULL,\n  `is_service_mesh_auth_on` int(1) DEFAULT NULL,\n  `service_mesh_default_policy` varchar(32) DEFAULT NULL,\n  `model_type` int(1) DEFAULT NULL COMMENT '服务模型',\n  `deploy_type` int(2) DEFAULT '1',\n  PRIMARY KEY (`id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=90597 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\n\n--\n-- Table structure for table `nsf_service_config`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_config` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `service_id` int(11) NOT NULL,\n  `config_type` varchar(45) NOT NULL,\n  `config_value` text,\n  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=181 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_service_discovery_binding`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_discovery_binding` (\n  `bd_id` bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `service_id` bigint(11) NOT NULL COMMENT '服务id',\n  `env_name` varchar(255) DEFAULT NULL COMMENT '环境名',\n  `kubernetes_service_name` varchar(255) DEFAULT NULL COMMENT 'k8s服务名',\n  `kubernetes_namespace` varchar(255) DEFAULT NULL COMMENT 'k8s namespace',\n  `sidecar_dubbo_active` tinyint(4) NOT NULL,\n  `agent_http_active` tinyint(4) NOT NULL,\n  `agent_dubbo_active` tinyint(4) NOT NULL,\n  `agent_grpc_active` tinyint(4) NOT NULL,\n  PRIMARY KEY (`bd_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=2590 DEFAULT CHARSET=utf8 COMMENT='服务发现绑定关系';\n\n--\n-- Table structure for table `nsf_service_group`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_group` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(256) NOT NULL DEFAULT '',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `project_id` bigint(11) DEFAULT NULL,\n  `create_time` bigint(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `name_projectId_index` (`name`,`project_id`) USING BTREE\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_service_mesh_circuit_breaker`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_mesh_circuit_breaker` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `source_service_id` int(11) DEFAULT NULL,\n  `target_service_id` int(11) DEFAULT NULL,\n  `rule_name` varchar(256) NOT NULL,\n  `router_rule_id` int(11) NOT NULL,\n  `enable_average_rt` tinyint(1) NOT NULL,\n  `average_rt_threshold` varchar(32) DEFAULT NULL,\n  `overflow_count` varchar(11) DEFAULT NULL,\n  `enable_request_error` tinyint(1) NOT NULL,\n  `request_error_ratio` varchar(32) DEFAULT NULL,\n  `min_trigger_count` varchar(32) DEFAULT NULL,\n  `time_window` varchar(32) NOT NULL,\n  `error_code` varchar(64) DEFAULT NULL,\n  `recover_time` varchar(32) NOT NULL,\n  `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `status` int(1) NOT NULL DEFAULT '0',\n  `source_service_name` varchar(256) DEFAULT NULL,\n  `target_service_name` varchar(256) DEFAULT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=76 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT='service mesh 服务熔断规则';\n\n--\n-- Table structure for table `nsf_service_mesh_downgrade`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_mesh_downgrade` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `rule_name` varchar(256) NOT NULL,\n  `router_rule_id` int(11) NOT NULL,\n  `source_service_id` int(11) DEFAULT NULL,\n  `target_service_id` int(11) NOT NULL,\n  `condition_type` varchar(64) NOT NULL,\n  `headers` varchar(512) DEFAULT NULL,\n  `error_code` varchar(256) DEFAULT NULL,\n  `response_type` varchar(64) NOT NULL,\n  `downgrade_interface` varchar(512) DEFAULT NULL,\n  `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `status` int(4) NOT NULL DEFAULT '0',\n  `cache_condition_code` varchar(256) DEFAULT NULL,\n  `cache_condition_header` varchar(256) DEFAULT NULL,\n  `cache_ttl` int(11) DEFAULT NULL,\n  `cache_key_query_params` varchar(256) DEFAULT NULL,\n  `cache_key_headers` varchar(256) DEFAULT NULL,\n  `source_service_name` varchar(256) DEFAULT NULL,\n  `target_service_name` varchar(256) DEFAULT NULL,\n  `is_local_cache` tinyint(1) DEFAULT '0',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=41 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_service_version`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_service_version` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `version` varchar(128) NOT NULL DEFAULT '',\n  `desc` varchar(128) DEFAULT '',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `service_id` bigint(11) NOT NULL COMMENT '版本所属服务id',\n  `create_time` timestamp NULL DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_servicemesh_auth_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_servicemesh_auth_rule` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `service_id` int(11) NOT NULL,\n  `match_type` varchar(50) NOT NULL,\n  `match_apis` mediumtext NOT NULL COMMENT '匹配的接口信息',\n  `match_conditions` mediumtext NOT NULL COMMENT '匹配的条件信息',\n  `create_time` bigint(20) DEFAULT NULL,\n  `update_time` bigint(20) DEFAULT NULL,\n  `rule_name` varchar(64) NOT NULL COMMENT '规则名称 不能重复',\n  `enabled` int(1) NOT NULL COMMENT '规则是否启用',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=31 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\n\n--\n-- Table structure for table `nsf_sm_consumer_route`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_sm_consumer_route` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL,\n  `consumer_service_id` bigint(11) NOT NULL,\n  `provider_service_id` bigint(11) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `status` int(11) DEFAULT '0',\n  `sm_virtual_service_id` bigint(11) NOT NULL,\n  `sm_circuit_breaker_id` bigint(11) DEFAULT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `consumer_service_id_env_idx` (`consumer_service_id`,`env_name`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=52 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_sm_rate_limit`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_sm_rate_limit` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL,\n  `service_id` bigint(11) NOT NULL,\n  `type` varchar(64) NOT NULL COMMENT '类型,local或者global',\n  `status` int(11) DEFAULT '0',\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `match` varchar(2048) DEFAULT NULL COMMENT '限流匹配具体内容',\n  `quota` varchar(2048) DEFAULT NULL COMMENT '具体配额',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=77 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_tag`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_tag` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `tag_key` varchar(256) NOT NULL,\n  `tag_value` varchar(256) DEFAULT NULL,\n  `application_id` int(11) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=108 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_tag_instance_relation`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_tag_instance_relation` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `agent_id` varchar(256) NOT NULL,\n  `tag_id` int(11) NOT NULL,\n  `instance_name` varchar(1024) DEFAULT NULL,\n  `tag_type` varchar(45) DEFAULT NULL,\n  `env_name` varchar(255) NOT NULL,\n  PRIMARY KEY (`id`),\n  KEY `instance_name_idx` (`instance_name`(128))\n) ENGINE=InnoDB AUTO_INCREMENT=1296379 DEFAULT CHARSET=utf8mb4;\n\n--\n-- Table structure for table `nsf_tm`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_tm` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL COMMENT '规则名',\n  `desc` varchar(256) DEFAULT NULL COMMENT '描述',\n  `color` varchar(32) NOT NULL COMMENT '颜色',\n  `project_id` bigint(11) NOT NULL COMMENT '规则所属项目id',\n  `active` tinyint(4) NOT NULL,\n  `env_name` varchar(255) DEFAULT NULL,\n  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=556 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_tm_match_rule`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_tm_match_rule` (\n  `rule_id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `traffic_mark_id` bigint(11) NOT NULL COMMENT '关联的traffic mark',\n  `type` varchar(32) NOT NULL COMMENT '类型, nsf或api网关',\n  `protocol` varchar(32) NOT NULL COMMENT '协议',\n  `service_name` varchar(512) DEFAULT NULL COMMENT '入口服务名',\n  `service_key` varchar(512) DEFAULT NULL COMMENT 'dubbo/grpc协议的方法名',\n  `param_type` varchar(512) DEFAULT NULL COMMENT '参数类型',\n  `param_name` varchar(512) DEFAULT NULL COMMENT '参数名',\n  `match_type` varchar(512) DEFAULT NULL COMMENT '匹配方式',\n  `match_value` varchar(512) DEFAULT NULL COMMENT '匹配值',\n  `gateway_instance` varchar(32) DEFAULT NULL COMMENT '网关实例',\n  `gateway_service_id` bigint(11) DEFAULT NULL COMMENT '网关服务id',\n  `gateway_rule_id` bigint(11) DEFAULT NULL COMMENT '网关规则id',\n  `active` tinyint(4) NOT NULL,\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  PRIMARY KEY (`rule_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=550 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_traffic_control_policy`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_traffic_control_policy` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `agent_id` varchar(128) NOT NULL COMMENT '策略所属agent',\n  `traffic_control_key` varchar(128) NOT NULL COMMENT '策略所绑定的apiKey',\n  `bursty` bigint(11) NOT NULL COMMENT '并发量大小，即桶大小',\n  `api_limit` bigint(11) NOT NULL COMMENT '一秒的流控阈值',\n  `create_time` bigint(20) NOT NULL,\n  `update_time` bigint(20) NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='流控策略表';\n\n--\n-- Table structure for table `nsf_virtual_service`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_virtual_service` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL,\n  `protocol` int(2) NOT NULL,\n  `service_id` bigint(11) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `content` varchar(20480) DEFAULT NULL COMMENT 'virtualservice具体内容',\n  `status` int(11) DEFAULT '0',\n  `priority` int(11) DEFAULT '50',\n  `consumer_service_id` bigint(11) DEFAULT '0',\n  `source` varchar(128) DEFAULT NULL,\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `service_id_idx` (`service_id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=299 DEFAULT CHARSET=utf8;\n\n--\n-- Table structure for table `nsf_virtual_service_dr_binding`\n--\n\nCREATE TABLE IF NOT EXISTS `nsf_virtual_service_dr_binding` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `service_id` bigint(11) NOT NULL,\n  `protocol` int(2) NOT NULL,\n  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `service_virtual_service_id` bigint(11) NOT NULL,\n  `service_destination_rule_id_list` varchar(255) COLLATE utf8_bin NOT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=15 DEFAULT CHARSET=utf8 COLLATE=utf8_bin;\n\n--\n-- Table structure for table `nsm_config`\n--\n\nCREATE TABLE IF NOT EXISTS `nsm_config` (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `name` varchar(255) NOT NULL COMMENT 'config name',\n  `type` varchar(255) NOT NULL COMMENT 'config type,1.PARAMDIVIDE 2.WEIGHTDIVIDE 3.LOADBALANCE 4.FAULTINJECT 5.CIRCUITBREAKER',\n  `service_id` bigint(11) NOT NULL COMMENT 'service id',\n  `hosts` text COMMENT 'istio中的hosts envoy中的domain',\n  `config` text NOT NULL COMMENT '具体的config配置，json格式',\n  `status` int(3) NOT NULL COMMENT 'config status (1开启，0关闭)',\n  `create_time` bigint(20) DEFAULT NULL COMMENT 'config创建时间',\n  `update_time` bigint(20) DEFAULT NULL COMMENT 'config最后一次更新时间',\n  PRIMARY KEY (`id`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=3177 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;\n\nALTER TABLE `nsf_api_interface` ADD COLUMN `agent_id` varchar(128) NOT NULL DEFAULT '-1' AFTER `service_id`;\nALTER TABLE `nsf_virtual_service` ADD COLUMN `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP;\n\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `group_id` VARCHAR(128) NULL DEFAULT '' AFTER `env_name`;\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `group_type` VARCHAR(128) NULL DEFAULT '' AFTER `group_id`;\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `host` VARCHAR(128) NULL DEFAULT '' AFTER `group_type`;\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `protocol` INT(11) NULL DEFAULT '1' AFTER `host`;\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP;\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `target_port` INT(4) NULL DEFAULT 0 AFTER `host`;\n\nALTER TABLE `nsf_service_discovery_binding` ADD COLUMN `agent_enabled` tinyint(4) DEFAULT 0 NOT NULL;\nUPDATE `nsf_service_discovery_binding` SET `agent_enabled` = 1 where `agent_http_active` = 1 OR `agent_dubbo_active` = 1 OR `agent_grpc_active` = 1;\n\nUPDATE `nsf_service` svc  INNER JOIN `nsf_service_discovery_binding` bd ON svc.id = bd.service_id\nSET svc.service_type = 4\nWHERE agent_grpc_active = 1;\n\nUPDATE `nsf_service` svc  INNER JOIN `nsf_service_discovery_binding` bd ON svc.id = bd.service_id\nSET svc.service_type = 2\nWHERE agent_dubbo_active = 1 OR sidecar_dubbo_active = 1;\n\nUPDATE `nsf_service` svc  INNER JOIN `nsf_service_discovery_binding` bd ON svc.id = bd.service_id\nSET svc.service_type = 1\nWHERE ISNULL(kubernetes_service_name) = 0 OR agent_http_active = 1;\n\nUPDATE `nsf_service` svc  INNER JOIN `nsf_service_discovery_binding` bd ON svc.id = bd.service_id\nSET svc.service_type = 3\nWHERE (ISNULL(kubernetes_service_name) = 0 OR agent_http_active = 1) AND (agent_dubbo_active = 1 OR sidecar_dubbo_active = 1);\n\nALTER TABLE `nsf_service_discovery_binding` DROP COLUMN `sidecar_dubbo_active`;\nALTER TABLE `nsf_service_discovery_binding` DROP COLUMN `agent_http_active`;\nALTER TABLE `nsf_service_discovery_binding` DROP COLUMN `agent_dubbo_active`;\nALTER TABLE `nsf_service_discovery_binding` DROP COLUMN `agent_grpc_active`;\n\nALTER TABLE `nsf_service_discovery_binding` ADD COLUMN `route_host` varchar(255) DEFAULT NULL COMMENT '路由host';\n\nalter table `nsf_rate_limit_rule` modify column `range` mediumtext not null;\n\nCREATE TABLE IF NOT EXISTS `nsf_mark_service_relation` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `mark_id` int(11) NOT NULL COMMENT '染色标识id',\n  `service_id` int(11) NOT NULL COMMENT '服务id',\n  `env_name` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `nsf_mark_service_relation_mark_id_IDX` (`mark_id`,`service_id`,`env_name`) USING BTREE\n) ENGINE=InnoDB AUTO_INCREMENT=8660302 DEFAULT CHARSET=utf8mb4 COMMENT='服务染色标识关联表';\n\nCREATE TABLE IF NOT EXISTS `nsf_tm_entrance_rule` (\n  `rule_id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `traffic_mark_id` bigint(11) NOT NULL COMMENT '关联的traffic mark',\n  `type` varchar(32) NOT NULL COMMENT '类型, nsf或api网关',\n  `protocol` varchar(32) NOT NULL COMMENT '协议',\n  `service_name` varchar(512) DEFAULT NULL COMMENT '入口服务名',\n  `match_content` varchar(20480) DEFAULT NULL COMMENT 'match具体内容',\n  `active` tinyint(4) NOT NULL,\n  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n  `rule_name` varchar(64) DEFAULT NULL COMMENT '规则名称',\n  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `project_id` bigint(11) DEFAULT NULL,\n  `env_name` varchar(255) DEFAULT NULL,\n  PRIMARY KEY (`rule_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=231 DEFAULT CHARSET=utf8;\n\nCREATE TABLE IF NOT EXISTS `nsf_service_auth` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `version` int(11) NOT NULL DEFAULT 1,\n  `create_time` timestamp NOT NULL DEFAULT current_timestamp,\n  `update_time` timestamp NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `service_id` int(11) NOT NULL COMMENT '服务id',\n  `auth_on` int(1) NOT NULL DEFAULT 0 COMMENT '鉴权开关，1=开启，0=关闭',\n  `identity_id` varchar(255) COMMENT '身份标识',\n  `jwk` mediumtext COMMENT '服务的公钥',\n  `jwt_sign` mediumtext COMMENT 'JWT签名',\n  `expired_time` int(11) DEFAULT 0 COMMENT 'jwt过期时间戳，0表示无限期',\n  `access_jwk_set` longtext COMMENT '允许访问的JWK公钥集合',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\n\nCREATE TABLE IF NOT EXISTS `nsf_service_auth_rule` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `version` int(11) NOT NULL DEFAULT 1,\n  `create_time` timestamp NOT NULL DEFAULT current_timestamp,\n  `update_time` timestamp NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `service_id` int(11) NOT NULL COMMENT '服务id',\n  `rule_name` varchar(64) NOT NULL DEFAULT '' COMMENT '规则名称 不能重复',\n  `enabled` int(1) NOT NULL DEFAULT 0 COMMENT '规则是否启用，1=启用，0=停用',\n  `match_protocol` varchar(64) NOT NULL DEFAULT '' COMMENT '匹配协议类型，可选：HTTP，DUBBO',\n  `match_type` varchar(64) NOT NULL DEFAULT '' COMMENT '鉴权策略，ACCESS=白名单；DENY=黑名单',\n  `match_apis` mediumtext COMMENT '匹配的接口信息',\n  `match_api_all` int(1) DEFAULT 0 COMMENT '是否匹配全部接口，默认0=否，1=是',\n  `match_services` mediumtext COMMENT '匹配的服务信息',\n  `match_service_all` int(1) DEFAULT 0 COMMENT '是否对全部服务生效，默认0=否，1=是',\n  `match_outer_services` mediumtext COMMENT '匹配的外部服务信息',\n  `match_outer_service_all` int(1) DEFAULT 0 COMMENT '是否对全部外部服务生效，默认0=否，1=是',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\ncreate unique index nsf_sar_service_name on nsf_service_auth_rule(service_id, rule_name);\n\nCREATE TABLE IF NOT EXISTS `nsf_event_info` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `version` int(11) NOT NULL DEFAULT 1,\n  `create_time` timestamp NOT NULL DEFAULT current_timestamp,\n  `update_time` timestamp NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `event_type` varchar(64) NOT NULL COMMENT '事件对象类型',\n  `event_action` varchar(64) NOT NULL COMMENT '事件行为',\n  `entity_id` int(11) COMMENT '事件对象id',\n  `event_status` varchar(64) NOT NULL COMMENT '事件流阶段，不同事件源类型可不一样',\n  `finished` int(1) DEFAULT 0 COMMENT '是否已完结，1=完结，0=未完结',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\n\nCREATE TABLE IF NOT EXISTS `nsf_event_info_ext` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `version` int(11) NOT NULL DEFAULT 1,\n  `create_time` timestamp NOT NULL DEFAULT current_timestamp,\n  `update_time` timestamp NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `event_info_id` varchar(64) NOT NULL COMMENT '主事件任务id',\n  `event_status` varchar(64) COMMENT '事件流阶段',\n  `event_data` mediumtext COMMENT '事件源数据',\n  `error_message` varchar(255) COMMENT '异常信息',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\ncreate unique index nsf_eie_info_status on nsf_event_info_ext(event_info_id, event_status);\n\nCREATE TABLE IF NOT EXISTS `nsf_outer_service` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `version` int(11) NOT NULL DEFAULT 1,\n  `create_time` timestamp NOT NULL DEFAULT current_timestamp,\n  `update_time` timestamp NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `app_name` varchar(64) NOT NULL COMMENT '外部服务名',\n  `name` varchar(64) COMMENT '单元',\n  `env_name` varchar(64) COMMENT '环境信息',\n  `identity_id` varchar(64) COMMENT '外部服务标识',\n  `certificate_type` varchar(64) default 'JWT' COMMENT '凭证类型（目前只有jwt）',\n  `public_key` mediumtext COMMENT '服务的公钥',\n  `sign` mediumtext COMMENT 'token签名信息',\n  `expired_time` int(11) DEFAULT 0 COMMENT 'jwt过期时间戳，0表示无限期',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\n\nALTER TABLE `nsf_service_discovery_binding` ADD COLUMN `agent_k8s_ns` varchar(100) DEFAULT NULL COMMENT 'agent k8sNs';\n\nALTER TABLE `nsf_sm_rate_limit` ADD COLUMN `uuid` varchar(128) DEFAULT '' AFTER `protocol`;\nALTER TABLE `nsf_tm_entrance_rule` ADD COLUMN `uuid` varchar(128) DEFAULT '' AFTER `env_name`;\nALTER TABLE `nsf_virtual_service` ADD COLUMN `uuid` varchar(128) DEFAULT '' AFTER `env_name`;\n\nalter table `nsf_instance` add column `cluster_id` varchar(63) default 'default' comment '集群标识';\nupdate `nsf_instance` set cluster_id = 'default' where 1 = 1;\n\nALTER TABLE `nsf_service` ADD COLUMN `rule_trigger_trace_info` MEDIUMTEXT DEFAULT NULL COMMENT '服务治理规则触发记录(json格式)';\n\n#mysql\ncreate unique index uk_projectIdName on nsf_service(name,meta_service_id,project_id,env_name);\ncreate unique index uk_projectIdEnvNameTag on nsf_label_info (label_key(128),label_value(256),project_id,env_name(64));\ncreate unique index uk_serviceIdTagId on nsf_label_service_relation (service_id,label_id,env_name);\ncreate unique index uk_serviceIdName on nsf_service_discovery_binding(service_id,env_name);\ncreate unique index uk_agentIdTagId on nsf_tag_instance_relation(agent_id,tag_id);\n\ncreate index agentId on nsf_error_log (agentId);\nalter table nsf_fail_policy add create_time timestamp not null default current_timestamp;\nupdate nsf_fail_policy set `create_time` = `update_time` where `create_time` is null;\nalter table nsf_fault_tolerance_policy add create_time timestamp not null default current_timestamp;\nupdate nsf_fault_tolerance_policy set `create_time` = `update_time` where `create_time` is null;\n\nALTER TABLE `nsf_service_discovery_binding` ADD COLUMN `registry` varchar(100) NULL DEFAULT NULL COMMENT '针对sidecar服务，nacos/eureka等注册中心';\n\ndelete from nsf_service_discovery_binding where env_name is null and service_id in (\n\tselect service_id from (\n\t\tselect service_id from nsf_service_discovery_binding group by service_id having(count(*))>1\n\t) a\n);\nalter table nsf_service_discovery_binding drop index uk_serviceIdName;\ncreate unique index uk_serviceId on nsf_service_discovery_binding(service_id);\n-- end of 2.9\n\nALTER TABLE nsf_service_auth DROP COLUMN version;\nALTER TABLE nsf_service_auth DROP COLUMN auth_on;\nALTER TABLE nsf_service_auth DROP COLUMN jwk;\nALTER TABLE nsf_service_auth DROP COLUMN access_jwk_set;\n\nALTER TABLE nsf_service_auth_rule DROP COLUMN version;\n\nALTER TABLE nsf_outer_service DROP COLUMN version;\nALTER TABLE nsf_outer_service DROP COLUMN public_key;\n\nCREATE TABLE `nsf_access_request`(\n  `id`              int(11) NOT NULL AUTO_INCREMENT,\n  `create_time`     timestamp   NOT NULL DEFAULT current_timestamp,\n  `update_time`     timestamp   NOT NULL DEFAULT current_timestamp ON UPDATE current_timestamp,\n  `expire_time`     timestamp   NOT NULL DEFAULT current_timestamp COMMENT '权限的过期时间',\n  `unit_name`       varchar(64) NOT NULL DEFAULT '' COMMENT '单元名',\n  `start_user`      varchar(64)          DEFAULT NULL COMMENT '内部申请人工号',\n  `ext_user_name`   varchar(64)          DEFAULT NULL COMMENT '外部人员姓名',\n  `ext_user_number` varchar(64)          DEFAULT NULL COMMENT '外部人员工号',\n  `valid_period`    int(1) NOT NULL COMMENT '所申请权限的有效期',\n  `status`          varchar(64) NOT NULL COMMENT '所申请权限的状态 0-申请成功 1-申请失败 2-申请中',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC;\ncreate unique index uk_uniName_startUser on nsf_access_request (unit_name, start_user);\ncreate unique index uk_uniName_extUserName_extUserNumber on nsf_access_request (unit_name, ext_user_name, ext_user_number);"
---
# Source: nsf-server/charts/nsf-agent-injecter-csr/templates/agent-csr-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: webhook-cert-setup
  namespace: skiff-nsf
  annotations:
    "helm.sh/hook": post-install
spec:
  template:
    spec:
      serviceAccountName: webhook-cert-sa
      containers:
        - name: webhook-cert-setup
          # This is a minimal kubectl image based on Alpine Linux that signs certificates using the k8s extension api server
          image: harbor.cloud.netease.com/qztest/k8s-webhook-cert-manager:0.13.22-220721-014e404-multi-arch
          command: ["./generate_certificate.sh"]
          args:
            - "--service"
            - "agent-injecter-svc"
            - "--webhook"
            - "agent-injecter"
            - "--secret"
            - "agent-injecter-certs"
            - "--namespace"
            - skiff-nsf
          resources:
            limits:
              cpu: "200m"
              memory: "256Mi"
            requests:
              cpu: "50m"
              memory: "64Mi"
      restartPolicy: OnFailure
      imagePullSecrets:
        - name: harbor-qingzhou
      tolerations:
        - key: "node-role.kubernetes.io/master"
          effect: NoSchedule
          operator: Exists
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/master
                    operator: In
                    values:
                      - ""
  backoffLimit: 3
---
# Source: nsf-server/templates/post-install-hooks/post-install-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sync-agent-image-job
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    #helm.sh/chart: 
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook-weight": "2"
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
      imagePullSecrets:
        - name: harbor-qingzhou
      containers:
        - name: job-done
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          command:
            - /bin/bash
            - -c
            - |-
              image-gripper sync --auth auth.yaml --images image_list --src registry --dest registry --src_path=harbor.cloud.netease.com --src_project=qztest --dest_path=harbor.cloud.netease.com --dest_project=library
              FAILED_IMAGE_LIST="failed_qztest_gen_image_list"
              FAILED_SYNC_IMAGE_LIST="failed_qztest_sync_image_list"
              if [ -f ${FAILED_IMAGE_LIST} ];then
                exit 1
              else
                if [ -f ${FAILED_SYNC_IMAGE_LIST} ];then
                  exit 1
                fi
              fi
          volumeMounts:
            - mountPath: /auth.yaml
              name: sync-agent-image-config
              subPath: auth.yaml
            - mountPath: /image_list
              name: sync-agent-image-config
              subPath: image_list
      restartPolicy: OnFailure
      volumes:
        - configMap:
            defaultMode: 420
            items:
              - key: auth.yaml
                path: auth.yaml
              - key: image_list
                path: image_list
            name: sync-agent-image-config
          name: sync-agent-image-config
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-server/templates/pre-install-hooks/nsf-config-portal-hooks-jobs.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-pre-install-hook
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    #helm.sh/chart: 
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook-weight": "2"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
      imagePullSecrets:
        - name: harbor-qingzhou
      containers:
        - name: job-done
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          command: ['sh', '-c', 'echo "all jobs completed"']
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
      volumes:
        - name: nsf-config-portal-createdb
          configMap:
            name: nsf-config-portal-createdb
        - name: nsf-config-portal
          configMap:
            name: nsf-config-portal
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: nsf-config-portal-createdb
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_portal.Users;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-config-portal-createdb.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-config-portal-createdb
        - name: nsf-config-portal
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_portal.Users;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-config-portal.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-config-portal
      restartPolicy: Never
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
  backoffLimit: 4
---
# Source: nsf-server/templates/pre-install-hooks/nsf-config-service-hooks-jobs.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-pre-install-nsf-config-service-hook
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    #helm.sh/chart: 
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook-weight": "2"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
      imagePullSecrets:
        - name: harbor-qingzhou
      containers:
        - name: job-done
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          command: ['sh', '-c', 'echo "all jobs completed"']
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
      volumes:
        - name: nsf-config-service-createdb
          configMap:
            name: nsf-config-service-createdb
        - name: nsf-config-service
          configMap:
            name: nsf-config-service
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: nsf-config-service-createdb
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_config.ServerConfig;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-config-service-createdb.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-config-service-createdb
        - name: nsf-config-service
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_config.ServerConfig;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-config-service.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-config-service
      restartPolicy: Never
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
  backoffLimit: 4
---
# Source: nsf-server/templates/pre-install-hooks/nsf-server-hooks-jobs.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-pre-install-nsf-server-hook
  namespace: skiff-nsf
  labels:
    app.kubernetes.io/name: release-name
    #helm.sh/chart: 
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook-weight": "2"
    "helm.sh/hook": pre-install
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  ttlSecondsAfterFinished: 600
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/nsf
                    operator: In
                    values:
                      - "true"
      imagePullSecrets:
        - name: harbor-qingzhou
      containers:
        - name: job-done
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          command: ['sh', '-c', 'echo "all jobs completed"']
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
      volumes:
        - name: nsf-server-createdb
          configMap:
            name: nsf-server-createdb
        - name: nsf-server
          configMap:
            name: nsf-server
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: nsf-server-createdb
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_server.nsf_label_service_relation;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-server-createdb.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-server-createdb
        - name: nsf-server
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          imagePullPolicy: IfNotPresent
          workingDir: /
          command:
            - bash
            - -c
            - "mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} -e 'select * from nsf_server.nsf_label_service_relation;' > /dev/null 2>&1 || mysql --default-character-set=utf8 -h ${MYSQL_HOST} -P ${MYSQL_PORT} -u${MYSQL_USER} -p${MYSQL_PASSWORD} < /tmp/nsf-server.sql"
          resources:
            limits:
              cpu: 200m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          env:
            - name: MYSQL_HOST
              value: "192.168.19.103"
            - name: MYSQL_PORT
              value: "3306"
            - name: MYSQL_USER
              value: "qzmysql"
            - name: MYSQL_PASSWORD
              value: "tOmkipoejd832k"
          volumeMounts:
            - mountPath: /tmp
              name: nsf-server
      restartPolicy: Never
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
  backoffLimit: 4
---

---
# Source: nsf-servicemesh/charts/kiali/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
imagePullSecrets:
  - name: harbor-qingzhou
metadata:
  name: kiali-service-account
  namespace: istio-system
  labels:
    app: kiali
    release: release-name
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/role.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: nsf-api-plane
    release: release-name
  name: nsf-api-plane-service-account
  namespace: istio-system
secrets:
  - name: nsf-api-plane-service-account-token
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: global-sidecar
  namespace: istio-operator
  labels:
    account: global-sidecar
---
# Source: nsf-servicemesh/charts/slime/templates/slime.yaml
# Source: slimeboot/templates/deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: slime
  namespace: istio-system
  labels:
    app: slime
---
# Source: nsf-servicemesh/charts/kiali/templates/demosecret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kiali
  namespace: istio-system
  labels:
    app: kiali
    release: release-name
type: Opaque
data:
  username: YWRtaW4= # admin
  passphrase: YWRtaW4= # admin
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/role.yaml
apiVersion: v1
kind: Secret
metadata:
  labels:
    release: release-name
  name: nsf-api-plane-service-account-token
  namespace: istio-system
---
# Source: nsf-servicemesh/charts/kiali/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kiali
  namespace: istio-system
  labels:
    app: kiali
    release: release-name
data:
  config.yaml: "graph:\n  clear_unknown_nodes: true\nistio_labels:\n  app_label_name: nsf.skiff.netease.com/app\n  version_label_name: nsf.skiff.netease.com/version\nistio_component_namespaces:\n  grafana: istio-system\n  tracing: istio-system\n  pilot: istio-system\n  prometheus: istio-system\nistio_namespace: istio-system\nauth:\n  strategy: anonymous\ndeployment:\n  accessible_namespaces: ['**']\nserver:\n  port: 20001\n  web_root: /kiali\nexternal_services:\n  istio:\n    url_service_version: http://istiod-qz112.istio-system:8080/version\n  tracing:\n    url: \n  grafana:\n    url: \n  prometheus:\n    url: http://thanos.test251-qingzhou.com\n"
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: api-plane-cm
  namespace: istio-system
  labels:
    release: release-name
data:
  k8s.yaml: |-
    k8s:
      clusters:
        # 单集群可不配相关信息
        default:
          k8s-api-server: ""
          cert-data: ""
          key-data: ""
  mesh-config.properties: |-
    meshProjectKey=nsf.skiff.netease.com/project
    meshVersionKey=nsf.skiff.netease.com/version
    meshAppKey=nsf.skiff.netease.com/app
    service.auth.url=http://platform-service-auth.skiff-platform.svc.cluster.local
    service.auth.ignore.paths=/healthz/ready
    service.auth.ignore.headers=x-nsf-auth-source|envoy-gateway
---
# Source: nsf-servicemesh/charts/rls/templates/configmap.yaml
apiVersion: v1
data:
  config.yaml: |
    ---
    domain: qingzhou
kind: ConfigMap
metadata:
  labels:
    app: rate-limit
  name: "rate-limit-config"
  namespace: istio-system
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: global-sidecar
  namespace: istio-operator
  labels:
    lazyload.slime.io/config: global-sidecar
data:
  cfg: |-
    wormholePorts:
    - 80
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: lazyload-accesslog-source
  namespace: istio-operator
data:
  custom_bootstrap.json: |
    {
      "static_resources": {
        "clusters": [{
          "name": "lazyload-accesslog-source",
          "type": "STRICT_DNS",
          "connect_timeout": "5s",
          "http2_protocol_options": {},
          "dns_lookup_family": "V4_ONLY",
          "load_assignment": {
            "cluster_name": "lazyload-accesslog-source",
            "endpoints": [{
              "lb_endpoints": [{
                "endpoint": {
                  "address": {
                    "socket_address": {
                      "address": "slime.istio-system",
                      "port_value": 8082
                    }
                  }
                }
              }]
            }]
          },
          "respect_dns_ttl": true
        }]
      }
    }
# Source: nsf-servicemesh/charts/slime/templates/slime.yaml
## bundle is deployed in istio-system
---
# Source: slimeboot/templates/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: slime
  namespace: istio-system
data:
  cfg: |
    bundle:
      modules:
      - name: lazyload
        kind: lazyload
      - name: limiter
        kind: limiter
      - name: plugin
        kind: plugin
      - name: rvs
        kind: rvs
      - name: sidecarmgr
        kind: sidecarmgr
      - name: tracetio
        kind: tracetio
      - name: meshregistry
        kind: meshregistry
    enable: true
    global:
      service: ""
      istioNamespace: "istio-system"
      slimeNamespace: "istio-system"
      istioRev: "stable,slime-stable"
      configRev: "mesh-reg"
      selfResourceRev: "slime-stable"
      istioConfigSource:
        address: 'xds://istiod-qz112:16010'
      configSources:
      - address: xds://localhost:16010
      log:
        klogLevel: 5
        logLevel: info
      clientGoTokenBucket:
        burst: 1000
        qps: 1000
      misc:
        enableLeaderElection: "on"
        passLabelRegex: ""
        pathRedirect: /ready->/meshregistry/ready,/pc->/meshregistry/pc,/nc->/meshregistry/nc,/zk->/meshregistry/zk,/zks->/meshregistry/zks,/dubboCallModel->/meshregistry/dubboCallModel,/xdsCache->/meshregistry/xdsCache,/eureka->/meshregistry/eureka,/nacos->/meshregistry/nacos
        seLabelSelectorKeys: nsf.skiff.netease.com/app
        xdsSourceEnableIncPush: "true"
    name: slime
  cfg_lazyload: |
    name: lazyload
    kind: lazyload
    enable: true
    global:
      log:
        logLevel: info
      clientGoTokenBucket:
        burst: 1000
        qps: 1000
      slimeNamespace: istio-system
    general:
      globalSidecarMode: cluster
      metricSourceType: accesslog
      enableShortDomain: true
      fenceLabelKeyAlias: nsf.skiff.netease.com/app:app
      clusterGsNamespace: istio-operator
      autoPort: true
      autoFence: true
      defaultFence: true
      wormholePort:
      - "9080"
    mode: BundleItem
  cfg_limiter: |
    name: limiter
    kind: limiter
    enable: true
    general:
      backend: 1
      disableGlobalRateLimit: false
      disableAdaptive: true
      disableInsertLocalRateLimit: true
      rlsConfigMap:
        name: rate-limit-config
        namespace: istio-system
      rls:
        service: rate-limit.istio-system.svc.cluster.local
        port: 18081
    mode: BundleItem
  cfg_plugin: |
    name: plugin
    kind: plugin
    enable: true
    mode: BundleItem
  cfg_rvs: |
    name: rvs
    kind: rvs
    enable: true
    mode: BundleItem
  cfg_sidecarmgr: |
    name: sidecarmgr
    kind: sidecarmgr
    enable: true
    mode: BundleItem
    general:
      kubeconfig: ""
      kubeResyncPeriod: "60s"
      versionManager:
        enableStatusUpdateTask: true
        enablePodsHashCheckTask: false
        enableWatchVersionManager: true
        statusUpdateIntervalSecond: 120
        podsHashCheckIntervalSecond: 15
        upgradeTimeoutSecond: 2
        statusUpdateDelayMillSecond: 2000
        defaultIptablesConfig:
          redirectDns: true
        deployedIstioRevision: qz112
  cfg_tracetio: |
    name: tracetio
    kind: tracetio
    enable: true
    mode: BundleItem
    general:
      project: ga
  cfg_meshregistry: |
    name: meshregistry
    kind: meshregistry
    enable: true
    mode: BundleItem
    general:
      LEGACY:
        MeshConfigFile: ""
        RevCrds: ""
        Mcp: {}
        K8SSource:
          Enabled: false
        EurekaSource:
          Enabled: false
          Address:
          - "http://nsf-registry.test251-qingzhou.com/eureka"
          RefreshPeriod: 15s
          SvcPort: 80
          NsHost: false
          MockServiceMergeServicePort: true
          MockServiceMergeInstancePort: true
          MockServiceEntryName: "qz-not-exist-svc-eureka"
          MockServiceName: "qz-not-exist-svc-eureka.qz"
        NacosSource:
          Enabled: false
          Address:
          - "http://nsf-nacos.test251-qingzhou.com"
          Mode: polling
          NsHost: false
          MockServiceMergeServicePort: true
          MockServiceMergeInstancePort: true
          MockServiceEntryName: "qz-not-exist-svc-nacos"
          MockServiceName: "qz-not-exist-svc-nacos.qz"
        ZookeeperSource:
          Enabled: true
          RefreshPeriod: 30s
          WaitTime: 10s
          Address:
          - zookeeper.apigw-demo.svc.cluster.local:2181
          DubboWorkloadAppLabel: qzdubboapp
          MockServiceMergeServicePort: true
          MockServiceEntryName: "qz-not-exist-svc-dubbo"
          MockServiceName: "qz-not-exist-svc-dubbo.qz"
---
# Source: nsf-servicemesh/charts/kiali/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kiali-istio-system
  labels:
    app: kiali
    release: release-name
rules:
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - namespaces
      - nodes
      - pods
      - pods/log
      - replicationcontrollers
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["extensions", "apps"]
    resources:
      - deployments
      - replicasets
      - statefulsets
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["autoscaling"]
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["batch"]
    resources:
      - cronjobs
      - jobs
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - config.istio.io
      - networking.istio.io
      - authentication.istio.io
      - rbac.istio.io
      - security.istio.io
    resources: ["*"]
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - watch
  - apiGroups: ["monitoring.kiali.io"]
    resources:
      - monitoringdashboards
    verbs:
      - get
      - list
---
# Source: nsf-servicemesh/charts/kiali/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kiali-viewer-istio-system
  labels:
    app: kiali
    release: release-name
rules:
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - namespaces
      - nodes
      - pods
      - pods/log
      - replicationcontrollers
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["extensions", "apps"]
    resources:
      - deployments
      - replicasets
      - statefulsets
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["autoscaling"]
    resources:
      - horizontalpodautoscalers
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["batch"]
    resources:
      - cronjobs
      - jobs
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - config.istio.io
      - networking.istio.io
      - authentication.istio.io
      - rbac.istio.io
      - security.istio.io
    resources: ["*"]
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["monitoring.kiali.io"]
    resources:
      - monitoringdashboards
    verbs:
      - get
      - list
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nsf-api-plane
rules:
  - apiGroups: ["config.istio.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["rbac.istio.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["security.istio.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["networking.istio.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["authentication.istio.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["microservice.slime.io"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["microservice.netease.com"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["config.netease.com"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["skiff.netease.com"]
    resources: ["*"]
    verbs: ["*"]
  - apiGroups: ["*"]
    resources: ["configmaps", "services", "statefulsets", "deployments", "daemonsets"]
    verbs: ["create", "get", "list", "watch", "update", "patch", "delete"]
  - apiGroups: ["*"]
    resources: ["pods", "pods/log", "endpoints", "serviceaccounts", "namespaces", "replicasets", "customresourcedefinitions"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["monitoring.coreos.com"]
    resources: ["*"]
    verbs: ["*"]
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: global-sidecar
rules:
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - get
      - list
      - watch
---
# Source: nsf-servicemesh/charts/kiali/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kiali-istio-system
  labels:
    app: kiali
    release: release-name
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kiali-istio-system
subjects:
  - kind: ServiceAccount
    name: kiali-service-account
    namespace: istio-system
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: nsf-api-plane
    release: release-name
  name: nsf-api-plane-istio-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nsf-api-plane
subjects:
  - kind: ServiceAccount
    name: nsf-api-plane-service-account
    namespace: istio-system
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: global-sidecar
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: global-sidecar
subjects:
  - kind: ServiceAccount
    name: global-sidecar
    namespace: istio-operator
---
# Source: nsf-servicemesh/charts/slime/templates/slime.yaml
# Source: slimeboot/templates/deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: slime-istio-system
subjects:
  - kind: ServiceAccount
    name: slime
    namespace: istio-system
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: global-sidecar
  namespace: istio-operator
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: global-sidecar
  namespace: istio-operator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: global-sidecar
subjects:
  - kind: ServiceAccount
    name: global-sidecar
    namespace: istio-operator
---
# Source: nsf-servicemesh/charts/kiali/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: kiali
  namespace: istio-system
  labels:
    app: kiali
    release: release-name
spec:
  ports:
    - name: http-kiali
      protocol: TCP
      port: 20001
  selector:
    app: kiali
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nsf-api-plane
  namespace: istio-system
  labels:
    app: nsf-api-plane
    release: release-name
spec:
  ports:
    - name: http
      port: 10880
      targetPort: 10880
    - name: grpc
      port: 9091
      targetPort: 9091
  selector:
    app: nsf-api-plane
---
# Source: nsf-servicemesh/charts/rls/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: rate-limit
  name: rate-limit
  namespace: istio-system
spec:
  ports:
    - name: grpc
      port: 18081
      protocol: TCP
      targetPort: 8081
    - name: config-grpc
      port: 16071
      protocol: TCP
      targetPort: 6071
  selector:
    app: rate-limit
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: global-sidecar
    service: global-sidecar
    slime.io/serviceFenced: "false"
  name: global-sidecar
  namespace: istio-operator
spec:
  ports:
    - name: http-80
      port: 80
      protocol: TCP
      targetPort: 80
  selector:
    app: global-sidecar
  sessionAffinity: None
  type: ClusterIP
---
# Source: nsf-servicemesh/charts/slime/templates/slime.yaml
# Source: slimeboot/templates/deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: slime
  namespace: istio-system
  labels:
    app: slime
spec:
  type: ClusterIP
  ports:
    - port: 16010
      targetPort: 16010
      protocol: TCP
      name: mcp-over-xds
    - port: 8081
      targetPort: 8081
      protocol: TCP
      name: aux-port
    - name: log-source-port
      targetPort: 8082
      protocol: TCP
      port: 8082
  selector:
    app: slime
---
# Source: nsf-servicemesh/charts/nsf-api-plane-daemon/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nsf-api-plane-daemon
  namespace: istio-system
  labels:
    release: release-name
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      name: nsf-api-plane-daemon
  template:
    metadata:
      labels:
        name: nsf-api-plane-daemon
        release: release-name
    spec:
      containers:
        - env:
            - name: NCE_PORT
              value: "9050"
          image: "harbor.cloud.netease.com/qztest/istio/api-plane-daemon:release-1.0-9109a01-multi"
          imagePullPolicy: IfNotPresent
          name: nsf-api-plane-daemon
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: 9050
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            httpGet:
              path: /health
              port: 9050
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 500m
              memory: 500Mi
            requests:
              cpu: 50m
              memory: 100Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /usr/local/tomcat/logs
              name: log
            - mountPath: /usr/local/envoy
              name: envoy
      dnsPolicy: ClusterFirstWithHostNet
      imagePullSecrets:
        - name: harbor-qingzhou
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
          operator: Exists
      volumes:
        - hostPath:
            path: "/data/log/nsf-api-plane-daemon"
            type: ""
          name: log
        - hostPath:
            path: "/data/envoy"
            type: ""
          name: envoy
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
---
# Source: nsf-servicemesh/charts/kiali/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kiali
  namespace: istio-system
  labels:
    app: kiali
    release: release-name
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kiali
  template:
    metadata:
      name: kiali
      labels:
        app: kiali
        release: release-name
      annotations:
        sidecar.istio.io/inject: "false"
        scheduler.alpha.kubernetes.io/critical-pod: ""
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        kiali.io/runtimes: go,kiali
    spec:
      serviceAccountName: kiali-service-account
      containers:
        - name: kiali
          image: "harbor.cloud.netease.com/qztest/istio/kiali:3.1.15"
          imagePullPolicy: Always
          command:
            - "/opt/kiali/kiali"
            - "-config"
            - "/kiali-configuration/config.yaml"
            - "-v"
            - "3"
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /kiali/api/namespaces
              port: 20001
              scheme: 'HTTP'
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /kiali/api/namespaces
              port: 20001
              scheme: 'HTTP'
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 3
          env:
            - name: ACTIVE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: kiali-configuration
              mountPath: "/kiali-configuration"
            - name: kiali-cert
              mountPath: "/kiali-cert"
            - name: kiali-secret
              mountPath: "/kiali-secret"
          resources:
            limits:
              cpu: "2"
              memory: 4Gi
            requests:
              cpu: 100m
              memory: 2Gi
      volumes:
        - name: kiali-configuration
          configMap:
            name: kiali
        - name: kiali-cert
          secret:
            secretName: istio.kiali-service-account
            optional: true
        - name: kiali-secret
          secret:
            secretName: kiali
            optional: true
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/servicemesh
                    operator: In
                    values:
                      - "true"
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    nce-app: nsf-api-plane
    app: nsf-api-plane
    release: release-name
  name: nsf-api-plane
  namespace: istio-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nsf-api-plane
  template:
    metadata:
      labels:
        app: nsf-api-plane
        release: release-name
    spec:
      serviceAccountName: nsf-api-plane-service-account
      containers:
        - env:
            - name: NCE_PORT
              value: "10880"
            - name: NCE_JAVA_OPTS
              value: "-Dspring.profiles.active=sm -DprometheusUrl=thanos.test251-qingzhou.com -DistioNamespace=istio-system -DkialiNamespace=istio-system -DstartInformer=true  -DrbacVersion=v1beta1 -DskiffVersion=2.x"
          image: "harbor.cloud.netease.com/qztest/istio/nsf-api-plane-server:ga-v2.10.2-e74066af"
          name: tomcat
          resources:
            limits:
              cpu: "1"
              memory: 4Gi
            requests:
              cpu: 200m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /api/health?Action=Health&Version=2019-07-25
              port: 10880
              scheme: HTTP
            initialDelaySeconds: 15
            timeoutSeconds: 15
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /api/health?Action=Health&Version=2019-07-25
              port: 10880
              scheme: HTTP
            initialDelaySeconds: 15
            timeoutSeconds: 1
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - mountPath: /usr/local/tomcat/webapps/ROOT/WEB-INF/classes/k8s.yaml
              name: k8s-conf
              subPath: k8s.yaml
            - mountPath: "/usr/local/tomcat/logs"
              name: log
      affinity:
      imagePullSecrets:
        - name: harbor-qingzhou
      volumes:
        - name: k8s-conf
          configMap:
            defaultMode: 420
            items:
              - key: k8s.yaml
                path: k8s.yaml
            name: api-plane-cm
        - name: log
          hostPath:
            path: "/data/log/api-plane"
      tolerations:
        - key: node-role.kubernetes.io/skiff
          effect: NoSchedule
          operator: Exists
---
# Source: nsf-servicemesh/charts/rls/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: rate-limit
  name: rate-limit
  namespace: istio-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: rate-limit
  template:
    metadata:
      labels:
        app: rate-limit
    spec:
      containers:
        - image: harbor.cloud.netease.com/qztest/ratelimit:v0.2.1-dff6014e
          imagePullPolicy: Always
          name: rate-limit
          command:
            - /bin/ratelimit
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOG_LEVEL
              value: info
            - name: USE_STATSD
              value: "false"
            - name: REDIS_URL
              value: "ctrl-redis-haproxy.skiff-platform:26587"
            - name: REDIS_AUTH
              value: "dfd2gdD8"
            - name: REDIS_SOCKET_TYPE
              value: tcp
            - name: RUNTIME_ROOT
              value: /data
            - name: RUNTIME_SUBDIRECTORY
              value: ratelimit
            - name: RUNTIME_IGNOREDOTFILES
              value: "true"
            - name: RUNTIME_WATCH_ROOT
              value: "false"
          resources:
            limits:
              cpu: "2"
              memory: "2Gi"
            requests:
              cpu: "100m"
              memory: "1Gi"
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /data/ratelimit/config
              name: rate-limit-config
      volumes:
        - configMap:
            defaultMode: 420
            name: "rate-limit-config"
          name: rate-limit-config
      restartPolicy: Always
      dnsPolicy: ClusterFirstWithHostNet
      imagePullSecrets:
        - name: harbor-qingzhou
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: global-sidecar
  namespace: istio-operator
  labels:
    app: global-sidecar
spec:
  replicas: 2
  selector:
    matchLabels:
      app: global-sidecar
  template:
    metadata:
      annotations:
        proxy.istio.io/config: |
          proxyMetadata:
            ISTIO_META_SLIME_APP:
              LAZYLOAD_GLOBAL_SIDECAR
            ISTIO_META_ISTIO_VERSION:
              "999.0.0"
        sidecar.istio.io/bootstrapOverride: "lazyload-accesslog-source"
        traffic.sidecar.istio.io/qzIncludeInboundPorts: '*'
      labels:
        app: global-sidecar
        istio.io/rev: stable
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      serviceAccountName: global-sidecar
      containers:
        - name: global-sidecar
          env:
            - name: PROBE_PORT
              value: "20000"
            - name: LOG_LEVEL
              value: info
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: WORMHOLE_PORT_PRIOR_TO_HOST_PORT
              value: "true"
          image: harbor.cloud.netease.com/qztest/slime/slime-global-sidecar:nsm-2.10.0-rc2
          imagePullPolicy: Always
          ports:
            - containerPort: 80
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz/live
              port: 20000
              scheme: HTTP
            initialDelaySeconds: 600
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 15
          readinessProbe:
            failureThreshold: 30
            httpGet:
              path: /healthz/ready
              port: 20000
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: "0.5"
              memory: 0.5Gi
          securityContext:
            privileged: true
---
# Source: nsf-servicemesh/charts/slime/templates/slime.yaml
# Source: slimeboot/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: slime
  namespace: istio-system
  labels:
    app: slime
spec:
  replicas: 2
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: slime
  template:
    metadata:
      labels:
        app: slime
      annotations:
        kubectl.kubernetes.io/default-logs-container: slime
        kubectl.kubernetes.io/default-container: slime
    spec:
      imagePullSecrets:
        - name: harbor-qingzhou
      serviceAccountName: slime
      containers:
        - name: slime
          image: "harbor.cloud.netease.com/qztest/slime/slime-bundle-qz-all:nsm-2.10.0-rc2"
          imagePullPolicy: Always
          env:
            - name: WATCH_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPERATOR_NAME
              value: "slime"
            - name: ENABLE_INC_PUSH
              value: "true"
            # START mesh-registry envs
            - name: LOCALITY_LABELS
              value: "system.msha/region,system.msha/zone,system.msha/cluster"
            # istio-mcp
            - name: XDS_SEND_TIMEOUT
              value: 40s
            - name: MCP_XDS_GPRC_MAXRECVMSGSIZE
              value: "104857600"
            # istio-mcp
            - name: SENT_NONCE_RECORD_NUM
              value: "10"
            - name: MESH_REG_ISTIO_REVISION
              value: mesh-reg
            - name: ENDPOINT_RELABEL_ITEMS
              value: "mark=nsf.skiff.netease.com/mark"
            # END mesh-registry envs
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            # limiter/plugin
            - name: SLIME_PASS_LBL_REG
              value:
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - name: aux-port
              containerPort: 8081
              protocol: TCP
            - name: log-source-port
              containerPort: 8082
              protocol: TCP
            # START mesh-registry ports
            # debug port 8080 -> slime 8081
            - containerPort: 16010
              name: mcp-over-xds
              protocol: TCP
              # END mesh-registry ports
          resources:
            limits:
              cpu: 4
              memory: 8Gi
            requests:
              cpu: 4
              memory: 4Gi
          readinessProbe:
            httpGet:
              path: "/modules/readyz"
              port: aux-port
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 2
          livenessProbe:
            httpGet:
              path: "/modules/livez"
              port: aux-port
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 2
          volumeMounts:
            - mountPath: /etc/slime/config
              name: config-volume
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: skiff/servicemesh
                    operator: In
                    values:
                      - "true"
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - slime
              topologyKey: kubernetes.io/hostname
      tolerations:
        - key: "node-role.kubernetes.io/skiff"
          effect: NoSchedule
          operator: Exists
      volumes:
        - name: config-volume
          configMap:
            name: slime
---
# Source: nsf-servicemesh/charts/nsf-api-plane/templates/k8singress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  labels:
    release: release-name
  name: nsf-api-plane
  namespace: istio-system
  annotations:
    nginx.ingress.kubernetes.io/use-regex: "true"
spec:
  rules:
    - host: sm-api-plane.test251-qingzhou.com
      http:
        paths:
          - backend:
              service:
                name: nsf-api-plane
                port:
                  number: 10880
            pathType: ImplementationSpecific
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
# Source: global-sidecar/templates/cluster-global-sidecar.yaml
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: global-sidecar-accesslog
  namespace: istio-operator
  labels:
    istio.io/rev: qz112
spec:
  workloadSelector:
    labels:
      app: global-sidecar
  configPatches:
    - applyTo: NETWORK_FILTER
      match:
        listener:
          filterChain:
            filter:
              name: "envoy.filters.network.http_connection_manager"
      patch:
        operation: MERGE
        value:
          typed_config:
            "@type": "type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager"
            access_log:
              - name: envoy.access_loggers.http_grpc
                typed_config:
                  "@type": type.googleapis.com/envoy.extensions.access_loggers.grpc.v3.HttpGrpcAccessLogConfig
                  common_config:
                    log_name: http_envoy_accesslog
                    transport_api_version: "V3"
                    grpc_service:
                      envoy_grpc:
                        cluster_name: lazyload-accesslog-source
---
# Source: nsf-servicemesh/charts/slime/templates/cluster-gloabal-sidecar.yaml
apiVersion: networking.istio.io/v1alpha3
kind: EnvoyFilter
metadata:
  name: to-global-sidecar
  namespace: istio-system
  labels:
    istio.io/rev: qz112
spec:
  configPatches:
    - applyTo: VIRTUAL_HOST
      match:
        context: SIDECAR_OUTBOUND
        routeConfiguration:
          name: "80"
          vhost:
            name: allow_any
      patch:
        operation: REMOVE
    - applyTo: ROUTE_CONFIGURATION
      match:
        context: SIDECAR_OUTBOUND
        routeConfiguration:
          name: "80"
      patch:
        operation: MERGE
        value:
          request_headers_to_add:
            - append: true
              header:
                key: Slime-Orig-Dest
                value: '%DOWNSTREAM_LOCAL_ADDRESS%'
          virtual_hosts:
            - domains:
                - '*'
              name: to_global_sidecar
              routes:
                - match:
                    prefix: /
                  route:
                    cluster: outbound|80||global-sidecar.istio-operator.svc.cluster.local
                    timeout: 0s
    - applyTo: HTTP_FILTER
      match:
        context: SIDECAR_OUTBOUND
        listener:
          filterChain:
            filter:
              name: envoy.filters.network.http_connection_manager
              subFilter:
                name: envoy.filters.http.router
          name: 0.0.0.0_80
      patch:
        operation: INSERT_BEFORE
        value:
          name: envoy.filters.http.lua
          typed_config:
            '@type': type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
            inline_code: |
              -- place holder
            source_codes:
              add.lua:
                inline_string: |
                  function envoy_on_request(request_handle)
                    request_handle:headers():replace("Slime-Source-Ns", os.getenv("POD_NAMESPACE"))
                  end
    - applyTo: HTTP_ROUTE
      match:
        context: SIDECAR_OUTBOUND
        routeConfiguration:
          name: "80"
          vhost:
            name: to_global_sidecar
      patch:
        operation: MERGE
        value:
          typed_per_filter_config:
            envoy.filters.http.lua:
              '@type': type.googleapis.com/envoy.extensions.filters.http.lua.v3.LuaPerRoute
              name: add.lua
    - applyTo: VIRTUAL_HOST
      match:
        context: SIDECAR_OUTBOUND
        proxy:
          metadata:
            SLIME_APP: LAZYLOAD_GLOBAL_SIDECAR
        routeConfiguration:
          name: "80"
          vhost:
            name: to_global_sidecar
      patch:
        operation: REMOVE
    - applyTo: ROUTE_CONFIGURATION
      match:
        context: SIDECAR_OUTBOUND
        proxy:
          metadata:
            SLIME_APP: LAZYLOAD_GLOBAL_SIDECAR
        routeConfiguration:
          name: "80"
      patch:
        operation: MERGE
        value:
          virtual_hosts:
            - domains:
                - '*'
              name: allow_any_new
              routes:
                - match:
                    prefix: /
                  route:
                    cluster: PassthroughCluster
                    timeout: 0s
---
# Source: nsf-servicemesh/charts/slime/templates/lazyload.yaml
apiVersion: config.netease.com/v1alpha1
kind: SlimeBoot
metadata:
  name: lazyload
  namespace: istio-system
  labels:
    slime.io/slimeboot: slime
spec:
  imagePullSecrets:
    - name: harbor-qingzhou
  image:
    pullPolicy: Always
    repository: ""
    tag: ""
  namespace: istio-operator
  #istioNamespace: istio-system
  resources:
    limits:
      cpu: "1"
      memory: 1Gi
    requests:
      cpu: "0.5"
      memory: 0.5Gi
  module:
    - name: slime
      kind: lazyload
      enable: true
      general:
        globalSidecarMode: cluster
        metricSourceType: accesslog
        clusterGsNamespace: istio-operator
        autoPort: true
        autoFence: true
        defaultFence: true
        fenceLabelKeyAlias: nsf.skiff.netease.com/app:app
        enableShortDomain: true
      global:
        log:
          logLevel: info
        clientGoTokenBucket:
          burst: 500
          qps: 500
        slimeNamespace: istio-system
  component:
    globalSidecar:
      replicas: 1
      enable: true
      sidecarInject:
        enable: true # should be true
        # mode definition:
        # "pod": sidecar auto-inject on pod level, need provide labels for injection
        # "namespace": sidecar auto-inject on namespace level, no need to provide labels for injection
        # if globalSidecarMode is cluster, global-sidecar will be deployed in slime namespace, which does not enable auto-inject on namespace level, mode can only be "pod".
        # if globalSidecarMode is namespace, depending on the namespace definition, mode can be "pod" or "namespace".
        mode: pod
        annotations:
          traffic.sidecar.istio.io/qzIncludeInboundPorts: '*'
        labels:
          istio.io/rev: stable
      resources:
        limits:
          cpu: "1"
          memory: 1Gi
        requests:
          cpu: "0.5"
          memory: 0.5Gi
      image:
        repository: ""
        tag: ""
      probePort: 20000 # health probe port
      port: 80 # global-sidecar default svc port
---
# Source: nsf-servicemesh/charts/common/templates/image-pull-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: harbor-qingzhou
  namespace: istio-system
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "1"
data:
  .dockerconfigjson: eyJhdXRocyI6IHsiaGFyYm9yLmNsb3VkLm5ldGVhc2UuY29tIjogeyJ1c2VybmFtZSI6ICJza2lmZiIsInBhc3N3b3JkIjogIkpERWF3MjNAamZkVyM3IiwgImF1dGgiOiAiYzJ0cFptWTZTa1JGWVhjeU0wQnFabVJYSXpjPSJ9fX0=
type: kubernetes.io/dockerconfigjson
---
# Source: nsf-servicemesh/charts/common/templates/image-pull-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: harbor-qingzhou
  namespace: istio-operator
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "1"
data:
  .dockerconfigjson: eyJhdXRocyI6IHsiaGFyYm9yLmNsb3VkLm5ldGVhc2UuY29tIjogeyJ1c2VybmFtZSI6ICJza2lmZiIsInBhc3N3b3JkIjogIkpERWF3MjNAamZkVyM3IiwgImF1dGgiOiAiYzJ0cFptWTZTa1JGWVhjeU0wQnFabVJYSXpjPSJ9fX0=
type: kubernetes.io/dockerconfigjson
---

---
# Source: nsf-istiod/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: istiod-installer
  namespace: istio-system
---
# Source: nsf-istiod/templates/postinstall.yaml
apiVersion: v1
data:
  auth.yaml: |
    ## 依赖的远程仓库地址
    harbor.cloud.netease.com:
      ## 仓库用户名，如果不需要用户名可以随便填写
      username: skiff
      ## 仓库密码，如果不需要可以随便填写
      password: JDEaw23@jfdW#7
      ## 是否需要安全验证，如果未使用https则设置为true，反之为false
      insecure: true
    ## 依赖的远程仓库地址
    harbor.cloud.netease.com:
      ## 仓库用户名，如果不需要用户名可以随便填写
      username: skiff
      ## 仓库密码，如果不需要可以随便填写
      password: JDEaw23@jfdW#7
      ## 是否需要安全验证，如果未使用https则设置为true，反之为false
      insecure: true
  image_list: |
    istio/envoy-proxy:v2.24.0-rc6-91743b1-unstripped-Ansm-2.10.0-rc4
kind: ConfigMap
metadata:
  name: sync-sidecar-image-config
  namespace: istio-system
---
# Source: nsf-istiod/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: istiod-installer
rules:
  - apiGroups:
      - config.istio.io
      - security.istio.io
      - networking.istio.io
      - authentication.istio.io
      - rbac.istio.io
      - telemetry.istio.io
      - extensions.istio.io
      - microservice.slime.io
      - install.istio.io
    resources: ['*']
    verbs: ['*']
  - apiGroups: ["admissionregistration.k8s.io"]
    resources: ["mutatingwebhookconfigurations", "validatingwebhookconfigurations"]
    verbs: ['*']
  - apiGroups: ["apiextensions.k8s.io"]
    resources: ["customresourcedefinitions.apiextensions.k8s.io", "customresourcedefinitions"]
    verbs: ['*']
  - apiGroups: ["apps", "extensions"]
    resources: ["daemonsets", "deployments", "deployments/finalizers", "replicasets"]
    verbs: ['*']
  - apiGroups: ["autoscaling"]
    resources: ["horizontalpodautoscalers"]
    verbs: ['*']
  - apiGroups: ["monitoring.coreos.com"]
    resources: ["servicemonitors"]
    verbs: ["get", "create", "update"]
  - apiGroups: ["policy"]
    resources: ["poddisruptionbudgets"]
    verbs: ['*']
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources: ["clusterrolebindings", "clusterroles", "roles", "rolebindings"]
    verbs: ['*']
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "create", "update"]
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - events
      - namespaces
      - pods
      - pods/proxy
      - pods/portforward
      - persistentvolumeclaims
      - secrets
      - services
      - serviceaccounts
    verbs: ['*']
---
# Source: nsf-istiod/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: istiod-installer
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: istiod-installer
subjects:
  - kind: ServiceAccount
    name: istiod-installer
    namespace: istio-system
---
# Source: nsf-istiod/templates/config.yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: qz112
  namespace: istio-system
spec:
  meshConfig:
    managementSelectors:
      - matchExpressions:
          - key: qz-apigw/namespace
            operator: "NotIn"
            values:
              - "true"
    accessLogFile: ""
    tcpAccessLog:
      file: /dev/stdout
    serviceSettings:
      - settings:
          clusterLocal: true
        hosts:
          - "global-sidecar.istio-operator.svc.cluster.local"
          - "lazyload.istio-system.svc.cluster.local"
    defaultConfig:
      proxyMetadata:
        ENABLE_SVC_REG: "true"
        DEFAULT_SERVICE_NAME_TPL: "<label:nsf.skiff.netease.com/app>"
        SVC_REG_META_LABELS: "*,:nsf.skiff.netease.com/mode:sidecar,:nsf.skiff.netease.com/auto_registry:eureka"
        SIDECAR_DEFAULT_SERVICE_REGISTRY: "eureka"
        SIDECAR_ISTIO_EUREKA: |-
          server:
            heartbeatinterval: 20000000000
            machines:
            - "http://nsf-registry.test251-qingzhou.com/eureka"
        CLEAN_IPTABLSES_BEFORE_SIDECAR_EXIT: "true"
        MCP_SERVER_URL: xds://istiod-qz112.istio-system.svc:16010
        SIDECAR_DNS_SERVER_PORT: "15153"
  revision: qz112
  profile: qz
  hub: harbor.cloud.netease.com/qztest/istio
  components:
    pilot:
      k8s:
        replicaCount: 2
        resources:
          limits:
            cpu: "4"
            memory: "8Gi"
          requests:
            cpu: "2"
            memory: "2Gi"
        # tolerations:
        # - effect: NoSchedule
        #   key: node-role.kubernetes.io/skiff
        #   operator: Exists
        # nodeSelector:
        #   "skiff/servicemesh": "true"            
        hpaSpec:
          minReplicas: 2
  values:
    revisionTags:
      - stable
    global:
      defaultPodDisruptionBudget:
        enabled: false
      qzCustomSettings:
        locality:
          labels:
            region: system.msha/region
            subzone: system.msha/cluster
            zone: system.msha/zone
        configRevision: "slime-stable,mesh-reg"
        # labelsToEnv: {}
        enableNetworkGatewayHttp: true
        standaloneEastwestGw: true
        # TODO 把非模板的部分直接从values渲染 
        holdAppTimeoutSeconds: 120
        configSources:
          - xds://slime.istio-system.svc:16010?types=serviceentry&types=sidecar
          - k8s://
        customInjectLabels:
          overrideOriginalLabel: false
          labels:
        enablePatchHttpHost: true
        proxyPreStopHook:
          exec:
            command:
              - pilot-agent
              - prestop
              - --sleep=20s
        extraResources:
          - apiVersion: networking.istio.io/v1alpha3
            kind: EnvoyFilter
            metadata:
              name: accesslog-filter-qz112
              namespace: istio-system
              labels:
                istio.io/rev: qz112
                release: istio
            spec:
              configPatches:
                - applyTo: NETWORK_FILTER
                  match:
                    listener:
                      filterChain:
                        filter:
                          name: envoy.http_connection_manager
                  patch:
                    operation: MERGE
                    value:
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                        access_log:
                          - name: envoy.access_loggers.file
                            filter:
                              extension_filter:
                                name: proxy.http.accesslog.abnormal
                                typed_config:
                                  "@type": type.googleapis.com/udpa.type.v1.TypedStruct
                                  type_url: type.googleapis.com/proxy.filters.access_log.abnormal_filter.v2.ProtoConfig
                                  value:
                                    duration_threshold: 10s
                                    percent_sampled:
                                      denominator: HUNDRED
                                      numerator: 100
                            typed_config:
                              "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                              format: |
                                {"start_time":"%START_TIME%","method":"%REQ(:METHOD)%","x-envoy-origin-path":"%REQ(X-ENVOY-ORIGINAL-PATH?:PATH)%","protocol":"%PROTOCOL%","response_code":"%RESPONSE_CODE%","response_flags":"%RESPONSE_FLAGS%","response_code_details":"%RESPONSE_CODE_DETAILS%","connection_termination_details":"%CONNECTION_TERMINATION_DETAILS%","upstream_transport_failure_reason":"%UPSTREAM_TRANSPORT_FAILURE_REASON%","bytes_received":"%BYTES_RECEIVED%","bytes_sent":"%BYTES_SENT%","duration":"%DURATION%","x-envoy-upstream-service-time":"%RESP(X-ENVOY-UPSTREAM-SERVICE-TIME)%","x-forwarded-for":"%REQ(X-FORWARDED-FOR)%","user-agent":"%REQ(USER-AGENT)%","x-request-id":"%REQ(X-REQUEST-ID)%","htdubboTag":"%REQ(htdubboTag)%",":authority":"%REQ(:AUTHORITY)%","upstream_host":"%UPSTREAM_HOST%","upstream_cluster":"%UPSTREAM_CLUSTER%","upstream_local_address":"%UPSTREAM_LOCAL_ADDRESS%","downstream_local_address":"%DOWNSTREAM_LOCAL_ADDRESS%","downstream_remote_address":"%DOWNSTREAM_REMOTE_ADDRESS%","requested_server_name":"%REQUESTED_SERVER_NAME%","route_name":"%ROUTE_NAME%","instance_ip": "%ENVIRONMENT(INSTANCE_IP)%","namespace":"%ENVIRONMENT(POD_NAMESPACE)%","pod_name":"%ENVIRONMENT(POD_NAME)%"}
                              path: /dev/stdout
                - applyTo: NETWORK_FILTER
                  match:
                    listener:
                      filterChain:
                        filter:
                          name: envoy.filters.network.dubbo_proxy
                  patch:
                    operation: MERGE
                    value:
                      typed_config:
                        "@type": type.googleapis.com/envoy.extensions.filters.network.dubbo_proxy.v3.DubboProxy
                        access_log:
                          - name: envoy.file_access_log.extensions
                            filter:
                              extension_filter:
                                name: proxy.dubbo.accesslog.abnormal
                                typed_config:
                                  "@type": type.googleapis.com/udpa.type.v1.TypedStruct
                                  type_url: type.googleapis.com/proxy.filters.dubbo.access_log.abnormal_filter.v2.ProtoConfig
                                  value:
                                    duration_threshold: 2s
                                    percent_sampled:
                                      numerator: 100
                                      denominator: HUNDRED
                            typed_config:
                              "@type": type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog
                              format: |
                                {"start_time":"%START_TIME%","protocol":"%PROTOCOL%","messageType":"%MESSAGE_TYPE(ENCODE)%","requestId":"%REQUEST_ID%","service":"%SERVICE%","method":"%METHOD%","version":"%VERSION%","group":"%GROUP%","downstream_remote_address":"%DOWNSTREAM_REMOTE_ADDRESS%","downstream_local_address":"%DOWNSTREAM_LOCAL_ADDRESS%","upstream_cluster":"%UPSTREAM_CLUSTER%","upstream_host":"%UPSTREAM_HOST%","response_code_details":"%RESPONSE_CODE_DETAILS%","instance_ip": "%ENVIRONMENT(INSTANCE_IP)%","namespace":"%ENVIRONMENT(POD_NAMESPACE)%","pod_name":"%ENVIRONMENT(POD_NAME)%"}
                              path: /dev/stdout
      proxy:
        holdApplicationUntilProxyStarts: true
        autoInject: enabled
        image: harbor.cloud.netease.com/library/istio/envoy-proxy:v2.24.0-rc6-91743b1-unstripped-Ansm-2.10.0-rc4
      imagePullSecrets:
        - harbor-qingzhou
    pilot:
      enableProtocolSniffingForOutbound: true
      enableProtocolSniffingForInbound: true
      env:
        # 暂时先保留该配置
        KUBE_NAMESPACE_BLACKLIST: "gateway-system,gateway-v112,gateway-system-v112"
        ENABLE_SVC_REG: "true"
        MCP_XDS_GPRC_MAXRECVMSGSIZE: "104857600"
        ISTIO_GPRC_MAXRECVMSGSIZE: "10485760"
        LOCALITY_LABELS: "system.msha/region,system.msha/zone,system.msha/cluster"
        PROXY_FEATURE_LIST: ""
        PILOT_INBOUND_PROTOCOL_DETECTION_CONTINUE_ON_TIMEOUT: "false"
        PILOT_PROTOCOL_DETECTION_CONTINUE_ON_TIMEOUT: "false"
        STRICT_ISTIO_REV: "true"
        XDS_SEQ_HANDLE_REQS: "0"
        PILOT_HTTP10: "true"
        USE_LEGACY_VM_API: "false"
      image: pilot:nsm-2.10.0-rc4
      autoscaleEnabled: false
---
# Source: nsf-istiod/templates/postinstall.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: istiod-install-qz112
  namespace: istio-system
  annotations:
    "helm.sh/hook": post-install,post-upgrade
spec:
  template:
    metadata:
      labels:
        revision: qz112
    spec:
      imagePullSecrets:
        - name: "harbor-qingzhou"
      serviceAccountName: istiod-installer
      containers:
        - name: job
          image: harbor.cloud.netease.com/qztest/istio/tools:nsm-2.10.0-rc4
          command:
            - /bin/bash
            - -c
            - |-
              config="$(kubectl -n istio-system get IstioOperator qz112 -oyaml | yq '.metadata = null')" || exit 1
              echo "$config"
              echo "$config" | cmd.sh istio-gen > result.yaml || exit 1
              cat result.yaml
              kubectl apply -f result.yaml
      restartPolicy: OnFailure
---
# Source: nsf-istiod/templates/postinstall.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sync-sidecar-image-qz112
  namespace: istio-system
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        revision: qz112
    spec:
      imagePullSecrets:
        - name: "harbor-qingzhou"
      serviceAccountName: istiod-installer
      containers:
        - name: job
          image: harbor.cloud.netease.com/qztest/skiff-tools:v3.4-20230210-multi
          command:
            - /bin/bash
            - -c
            - |-
              image-gripper sync --auth auth.yaml --images image_list --src registry --dest registry --src_path=harbor.cloud.netease.com --src_project=qztest --dest_path=harbor.cloud.netease.com --dest_project=library
              FAILED_IMAGE_LIST="failed_qztest_gen_image_list"
              FAILED_SYNC_IMAGE_LIST="failed_qztest_sync_image_list"
              if [ -f ${FAILED_IMAGE_LIST} ];then
                exit 1
              else
                if [ -f ${FAILED_SYNC_IMAGE_LIST} ];then
                  exit 1
                fi
              fi
          volumeMounts:
            - mountPath: /auth.yaml
              name: sync-sidecar-image-config
              subPath: auth.yaml
            - mountPath: /image_list
              name: sync-sidecar-image-config
              subPath: image_list
      restartPolicy: OnFailure
      volumes:
        - configMap:
            defaultMode: 420
            items:
              - key: auth.yaml
                path: auth.yaml
              - key: image_list
                path: image_list
            name: sync-sidecar-image-config
          name: sync-sidecar-image-config
---
# Source: nsf-istiod/templates/predelete.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: istiod-delete-qz112
  namespace: istio-system
  annotations:
    "helm.sh/hook": pre-delete
spec:
  template:
    metadata:
      labels:
        revision: qz112
    spec:
      imagePullSecrets:
        - name: "harbor-qingzhou"
      serviceAccountName: istiod-installer
      containers:
        - name: job
          image: harbor.cloud.netease.com/qztest/istio/tools:nsm-2.10.0-rc4
          command:
            - /bin/bash
            - -c
            - |-
              config="$(kubectl -n istio-system get IstioOperator qz112 -oyaml | yq '.metadata = null')"
              echo "$config"
              echo "$config" | cmd.sh istio-gen > result.yaml
              kubectl delete -f result.yaml
      restartPolicy: OnFailure
---

